{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SQF_RNN_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyj19/TS/blob/master/SQF_RNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPtSnNPJ7eTH",
        "colab_type": "code",
        "outputId": "2dab12f4-cc43-4def-8961-0481e1cf6ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rl6TAk4HBLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1092
        },
        "outputId": "47351a66-412a-4736-f57a-13d186006292"
      },
      "source": [
        "pip install gluonts"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/4a/f736941b23d639270121f0db30e2f1eed8d6986be5dd7166d396eecfd6ea/gluonts-0.1.4-py3-none-any.whl (222kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib==3.* in /usr/local/lib/python3.6/dist-packages (from gluonts) (3.0.3)\n",
            "Requirement already satisfied: boto3==1.* in /usr/local/lib/python3.6/dist-packages (from gluonts) (1.9.167)\n",
            "Collecting mxnet>=1.3.1 (from gluonts)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/f4/bc147a1ba7175f9890523ff8f1a928a43ac8a79d5897a067158cac4d092f/mxnet-1.4.1-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\n",
            "\u001b[K     |████████████████████████████████| 28.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (0.24.2)\n",
            "Requirement already satisfied: holidays==0.9.* in /usr/local/lib/python3.6/dist-packages (from gluonts) (0.9.10)\n",
            "Collecting pydantic==0.28.* (from gluonts)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/bc/fe7d98f0b4b1e72d0c444f343a798461c1f9d8656fb1c335416dbb8b7976/pydantic-0.28-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8MB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from gluonts) (4.28.1)\n",
            "Collecting numpy==1.14.* (from gluonts)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8MB 47.1MB/s \n",
            "\u001b[?25hCollecting ujson>=1.35 (from gluonts)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.*->gluonts) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.*->gluonts) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.*->gluonts) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.*->gluonts) (2.4.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.167 in /usr/local/lib/python3.6/dist-packages (from boto3==1.*->gluonts) (1.12.167)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3==1.*->gluonts) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3==1.*->gluonts) (0.9.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet>=1.3.1->gluonts)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet>=1.3.1->gluonts) (2.21.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->gluonts) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays==0.9.*->gluonts) (1.12.0)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==0.28.*->gluonts) (0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.*->gluonts) (41.0.1)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3==1.*->gluonts) (0.14)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3==1.*->gluonts) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet>=1.3.1->gluonts) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet>=1.3.1->gluonts) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet>=1.3.1->gluonts) (3.0.4)\n",
            "Building wheels for collected packages: ujson\n",
            "  Building wheel for ujson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "Successfully built ujson\n",
            "\u001b[31mERROR: spacy 2.1.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.53.post2 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: graphviz, numpy, mxnet, pydantic, ujson, gluonts\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed gluonts-0.1.4 graphviz-0.8.4 mxnet-1.4.1 numpy-1.14.6 pydantic-0.28 ujson-1.35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScIt9ImB8cav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZvoZxQX7-G1",
        "colab_type": "code",
        "outputId": "0f1d2c9b-f1ea-4cd4-8d9d-847f248135eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTbcnwJm7_lD",
        "colab_type": "code",
        "outputId": "a42a4be1-c97a-4520-f6f6-aa7084d4da5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_path = 'gdrive/My Drive/FinancialTS/JPmarket_dataset.npz' \n",
        "data = np.load(root_path)\n",
        "data.files"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_ratios', 'test_ratios', 'train_volumes', 'test_volumes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8SDMHW78HXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratios = data['train_ratios']\n",
        "test_ratios = data['test_ratios']\n",
        "train_vols = data['train_volumes']\n",
        "test_vols = data['test_volumes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI540y0JQBpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mini_train_ratios = train_ratios[0:50]\n",
        "mini_test_ratios = test_ratios[0:50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fItoKOzL8K-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#need to change this to create windows for all stocks \n",
        "\n",
        "def split_data(n_days, data): #data for one stock in the form [days, bins]\n",
        "  no_ts = data.shape[0]-n_days\n",
        "  length_ts = n_days*data.shape[1]\n",
        "  new_data = np.zeros((no_ts,length_ts))\n",
        "  for j in range(no_ts):\n",
        "    for i in range(n_days): \n",
        "      new_data[j,64*i:64*i + 64] = data[j+i,:]\n",
        "  \n",
        "  return new_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73_oSS9u8N8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_test_data(train_data, test_data, n_days, stock_index):\n",
        "  all_data = np.concatenate((train_data, test_data), axis = 1)\n",
        "  \n",
        "  one_data = all_data[stock_index]\n",
        "  \n",
        "  #now want to take only sets of n_days which contain the test data too \n",
        "  no_ts = test_data.shape[1]\n",
        "  length_ts = n_days*one_data.shape[1]\n",
        "  new_data = np.zeros((no_ts, length_ts))\n",
        "  \n",
        "  for j in range(no_ts): \n",
        "    for i in range(n_days): \n",
        "      new_data[j, 64*i:64*i + 64] = one_data[train_data.shape[1]+j-180+i+1,:]\n",
        "      \n",
        "  return new_data\n",
        "\n",
        "\n",
        "testing_ratios = make_test_data(train_ratios, test_ratios, 180, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvkSNm358o4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getbd_from_theta(theta): \n",
        "  gamma, beta, delta = theta\n",
        "  \n",
        "  L = len(beta)\n",
        "  \n",
        "  b = torch.zeros(L)\n",
        "  for l in range(L): \n",
        "    if l == 0 : \n",
        "      b[l] = beta[l]\n",
        "    else: \n",
        "      b[l] = beta[l]-beta[l-1]\n",
        "  d = torch.zeros(L)\n",
        "  for l in range(1,L): \n",
        "    d[l] = torch.sum(delta[:l])\n",
        "    \n",
        "  return b, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Q5oJFh2igo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crps_loss(theta, z):\n",
        "  gamma, beta, delta = theta\n",
        "  \n",
        "  L = len(beta)\n",
        "  \n",
        "  b, d = getbd_from_theta(theta)\n",
        "  \n",
        "  lo = 0 \n",
        "    \n",
        "  for l in range(L-1, -1, -1): \n",
        "    val = sqf(theta, d[l])\n",
        "    if val < z:\n",
        "      lo = l\n",
        "      break \n",
        "  \n",
        "  a_tilde = (z-gamma + torch.sum(b[:lo]*d[:lo]))/torch.sum(b[:lo])\n",
        "  \n",
        "  max_ = torch.max(torch.zeros(L)+a_tilde, d)\n",
        "  \n",
        "  bracket = (1/3)*(1-torch.pow(d, 3)) - d - torch.pow(max_,2) + 2*max_*d\n",
        "  \n",
        "  loss = (2*a_tilde - 1)*z + (1-2*a_tilde)*gamma + torch.sum(b*bracket)\n",
        "  \n",
        "  return loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7byuacN2kW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sqf(theta, quantile): \n",
        "  \n",
        "  #would expect beta and delta to be vectors length hidden_units\n",
        "  \n",
        "  gamma, beta, delta = theta\n",
        "  L = len(beta)\n",
        "  \n",
        "  b,d = getbd_from_theta(theta)\n",
        "  \n",
        "  max_ = torch.max(quantile-d, torch.zeros(L))\n",
        "  \n",
        "  qf = gamma + torch.sum(b*max_)\n",
        "  \n",
        "  return qf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtpFnvDpUf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module): \n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, batch_size, output_size, num_layers):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.lstm = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.dense = nn.Linear(self.hidden_size, 1)\n",
        "    self.softmax = nn.functional.softmax\n",
        "    self.softplus = nn.functional.softplus\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)\n",
        "  \n",
        "  def forward(self, data, hidden):\n",
        "    lstm_out, hidden = self.lstm(data.view(1, 1, -1))\n",
        "    fc_layer = self.linear(lstm_out.view(-1)) \n",
        "    delta = self.softmax(fc_layer)\n",
        "    beta = self.softmax(fc_layer)\n",
        "    gamma = self.dense(fc_layer)\n",
        "    \n",
        "    theta = (gamma, beta, delta)\n",
        "    #print('theta', theta)\n",
        "    #print('delta', delta)\n",
        "    #print('beta', beta)\n",
        "    \n",
        "    return theta, hidden \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKoU7fYqvbLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0005\n",
        "#learning_rate_decay = \n",
        "num_epochs = 50\n",
        "T = 60*64\n",
        "num_paths = 50\n",
        "pred_length = 64\n",
        "num_lstm_layers = 2\n",
        "hidden_units = 80\n",
        "batch_size = 250\n",
        "\n",
        "training_data = split_data(int(T/64), train_ratios[0])\n",
        "training_data.shape\n",
        "\n",
        "small_data = np.zeros((250, training_data.shape[1]))\n",
        "for i in range(small_data.shape[0]): \n",
        "  index = np.random.randint(0, training_data.shape[0])\n",
        "  small_data[i,:] = training_data[index]\n",
        "  \n",
        "small_data_new = torch.FloatTensor(small_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2CJzS-EWKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2bcb1b18-b96b-4160-bc31-995448df7640"
      },
      "source": [
        "encoder = Encoder(1, hidden_units, batch_size, 1, num_lstm_layers)\n",
        "print(encoder)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (lstm): LSTM(1, 80, num_layers=2)\n",
            "  (linear): Linear(in_features=80, out_features=80, bias=True)\n",
            "  (dense): Linear(in_features=80, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIa10RoikYuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TRAINING the encoder###\n",
        "\n",
        "##Question: should optimization be done on each time series or over loss for all TS?\n",
        "loss_function = crps_loss\n",
        "encoder_optimiser = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "train_loss = []\n",
        "\n",
        "for i in range(num_epochs): \n",
        "  encoder.zero_grad()\n",
        "  encoder_hidden = encoder.init_hidden()\n",
        "  \n",
        "  batch_loss = 0\n",
        "  \n",
        "  data_batch = small_data_new\n",
        "  \n",
        "  for j in range(batch_size):\n",
        "    loss_t = 0 \n",
        "    input_data = data_batch[j]\n",
        "    \n",
        "    for t in range(T): \n",
        "      theta, encoder_hidden = encoder(input_data[t:t+1], encoder_hidden)\n",
        "      loss_t += loss_function(theta, input_data[t+1:t+2])\n",
        "      print(loss_t)\n",
        "    \n",
        "    batch_loss+= loss_t\n",
        "    \n",
        "  batch_loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "\n",
        "  train_loss.append(batch_loss.item())\n",
        "  \n",
        "  if i % 10 == 0:\n",
        "      print(\"Epoch \", t, \"CRPS \", batch_loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIPzPlCFq468",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## PREDICTION ##\n",
        "decoder = Encoder()\n",
        "\n",
        "with torch.no_grad(): \n",
        "  for t in range(T): \n",
        "    theta, encoder_hidden = encoder(input_data[t], encoder_hidden)\n",
        "    \n",
        "  for n in range(num_paths): \n",
        "  \n",
        "    decoder_input = input_data[T]\n",
        "    decoder_hidden = encoder_hidden \n",
        "    alpha = torch.distributions.uniform.Uniform(0,1)\n",
        "    sample_path = []\n",
        "\n",
        "    for i in range(pred_length): \n",
        "      theta, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      z_hat = sqf(theta, alpha)\n",
        "      sample_path.append(z_hat)\n",
        "      decoder_input = z_hat\n",
        "      \n",
        "    path = input_data.append(sample_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}