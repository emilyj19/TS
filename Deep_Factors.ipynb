{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Factors.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyj19/TS/blob/master/Deep_Factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxHpi6CjWlg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "470f7932-d314-42de-b419-193e729264d9"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63MFgpVHUb5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_-DYtEUfH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e2e42ff6-6770-4202-a22f-93388bc8575f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAw0rtMUhZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f1755a-f458-41cc-fcb4-f09f97f343ad"
      },
      "source": [
        "root_path = 'gdrive/My Drive/FinancialTS/JPmarket_dataset.npz' \n",
        "data = np.load(root_path)\n",
        "data.files"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_ratios', 'test_ratios', 'train_volumes', 'test_volumes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIcj78GVk8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratios = data['train_ratios']\n",
        "test_ratios = data['test_ratios']\n",
        "train_vols = data['train_volumes']\n",
        "test_vols = data['test_volumes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvUKXNgmCdYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inputs: data of shape (num_series, num_days, num_bins), num_series = number of time series to use, len_series = length of series,  num_windows = number of series to create from each \n",
        "#output: data of shape (num_series, num_windows, len_series*bins)\n",
        "\n",
        "def create_train_vols_data(data, num_series, len_series, num_windows): \n",
        "  total_num_series, num_days, num_bins = data.shape \n",
        "  days_series = int(len_series/num_bins)\n",
        "  \n",
        "  train_data = np.zeros((num_series, num_windows, len_series))\n",
        "  \n",
        "  for i in range(num_series): \n",
        "    series_i = data[i]\n",
        "    norm_series_i = series_i/np.amax(series_i) #normalise series\n",
        "    for j in range(num_windows):\n",
        "      start_index = np.random.randint(0,num_days-days_series)\n",
        "      train_data[i,j] = norm_series_i[start_index:start_index + days_series].flatten()\n",
        " \n",
        "  return train_data\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opSiJuoDPB4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#alternative covariate function \n",
        "#inputs - input_data of shape [number of time series, length of each time series], freq of data i.e. number of bins per day, and position of special bins as a vector\n",
        "#returns - data and covariate vector of shape [number of series, length of series, number of special bins + 2] where covariate_vectors[:,:,0] is the input data, \n",
        "#covariate_vectors[:,:,1] is the scaled time of day and covariate_vectors[:,:,2:] is the one hot vector for the special bins\n",
        "#therefore covariate_vectors[:,:,0] is the data and covariate_vectors[:,:,1:] is the actual covariate vector \n",
        "\n",
        "def new_create_covariate_data(input_data, freq, pos_of_special_bins): \n",
        "  num_series, len_series = input_data.shape\n",
        "  days = int(len_series/freq)\n",
        "  num_special_bins = len(pos_of_special_bins)\n",
        "  covariate_vectors = np.zeros((num_series, len_series, num_special_bins+2))\n",
        "  \n",
        "  for n in range(num_series): \n",
        "    for d in range(days): \n",
        "      for t in range(freq): \n",
        "        x = np.zeros(num_special_bins + 1)\n",
        "        #x[0] is the scaled time of day \n",
        "        x[0] = t/freq\n",
        "        \n",
        "        check = t in pos_of_special_bins\n",
        "        \n",
        "        if check == True: \n",
        "          index = pos_of_special_bins.index(t)\n",
        "          x[index+1] = 1\n",
        "          \n",
        "        covariate_vectors[n, d*freq + t, 0] = input_data[n, d*freq + t]\n",
        "        covariate_vectors[n, d*freq + t, 1:] = x\n",
        "        \n",
        "  return covariate_vectors\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz94MokCRKiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_series = 20\n",
        "number_windows = 100\n",
        "T = 3*64\n",
        "special_bins = [0,31,32,63]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqYtYOLRRUur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_vol = create_train_vols_data(train_vols, number_series, T, number_windows)\n",
        "covars_training_data = np.zeros((number_series, number_windows, T, len(special_bins)+2))\n",
        "\n",
        "for i in range(number_series): \n",
        "  covars = new_create_covariate_data(training_vol[i], 64, special_bins)\n",
        "  covars_training_data[i] = covars\n",
        "  \n",
        "  \n",
        "covars_train_data = torch.FloatTensor(covars_training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1O5qrgbY_f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_volume = train_vols[0:number_series].reshape((number_series,-1))\n",
        "\n",
        "norm_test_vols = np.zeros(test_volume.shape)\n",
        "for i in range(number_series): \n",
        "  norm_test_vols[i] = test_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "new_test_data = norm_test_vols[:,T:2*T]\n",
        "\n",
        "covars_test_data = new_create_covariate_data(new_test_data, 64, [0,31,32,63])\n",
        "\n",
        "covars_test_data = torch.FloatTensor(covars_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKdgN_J2QQq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class for the global model \n",
        "#forward pass - input data of shape [num_series, length of each series, length of covariate vector + 1]\n",
        "#forward pass outputs fixed effects of shape [num_series, len_series]\n",
        "\n",
        "class GlobalEffects(nn.Module): \n",
        "  def __init__(self, input_size, num_factors, hidden_size, batch_size, output_size = 1, num_layers = 1): \n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_factors = num_factors\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.linears = nn.ModuleList([nn.Linear(self.hidden_size, self.output_size, bias = False) for i in range(self.num_factors)])\n",
        "    self.lstms = nn.ModuleList([nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers) for i in range(self.num_factors)])\n",
        "    \n",
        "    self.w = torch.nn.Parameter(torch.zeros(batch_size, num_factors))\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    hidden = [torch.zeros(self.num_layers, self.batch_size, self.hidden_size) for i in range(self.num_factors)]\n",
        "    return hidden\n",
        "    \n",
        "  def forward(self, input_data, hidden): \n",
        "    x = input_data[:,:,1:]\n",
        "    for i in range(self.num_factors): \n",
        "      lstm_out, hidden[i] = self.lstms[i](x.view(x.shape[1], self.batch_size, -1))\n",
        "      g_i = self.linears[i](lstm_out).view(1, self.batch_size, -1) #shape of g_i = [1, batch_size, seq_len]\n",
        "      \n",
        "      if i == 0: \n",
        "        g = g_i\n",
        "      else:\n",
        "        g = torch.cat((g,g_i), dim=0)\n",
        "\n",
        "    fixed_effects = torch.zeros((self.batch_size, g.shape[2]))\n",
        "    \n",
        "    for i in range(self.batch_size): \n",
        "      for j in range(g.shape[2]): \n",
        "        fixed_effects[i,j] = torch.dot(self.w[i], g[:,i,j])\n",
        "      \n",
        "    return fixed_effects\n",
        "     \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ZvLZ9aUqw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class for the DF-RNN local model \n",
        "#parameters to define: input_size = number of elements in covariates vector, num_series = number of time series in the data\n",
        "#forward pass inputs: fixed effects output from global model, input data of shape [num_series, length of each series, length of covariate vector + 1] and whether or not to assume a gaussian likelihood \n",
        "#forward pass outputs total log likelihood for the given data and sigma of shape [num_series, len_series]\n",
        "\n",
        "class DF_RNN(nn.Module): \n",
        "  def __init__(self, input_size, hidden_size, batch_size, num_series, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_series = num_series\n",
        "    \n",
        "    self.rnns = nn.ModuleList([nn.RNN(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = 1) for i in range(self.num_series)])\n",
        "    self.linears = nn.ModuleList([nn.Linear(self.hidden_size, self.output_size) for i in range(self.num_series)])\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    hidden = [torch.zeros(1, self.batch_size, self.hidden_size) for i in range(self.num_series)]\n",
        "    return hidden\n",
        "    \n",
        "  def forward(self, input_data, hidden, fixed_effects, gaussian_likelihood, prediction): \n",
        "    z = input_data[:,:,0]\n",
        "    x = input_data[:,:,1:]\n",
        "    \n",
        "    sigma = torch.zeros((self.num_series, x.shape[1]))\n",
        "    r = torch.zeros(sigma.shape)\n",
        "    \n",
        "    for i in range(self.num_series): \n",
        "      data = x[i]\n",
        "      rnn_out, hidden[i] = self.rnns[i](data.view(data.shape[0], self.batch_size, -1))\n",
        "      sig = self.linears[i](rnn_out).view(-1)\n",
        "      \n",
        "      sigma[i] = torch.abs(sig)\n",
        "      \n",
        "      for j in range(sigma.shape[1]):\n",
        "        r[i,j] = torch.distributions.normal.Normal(0, sigma[i,j]).rsample()\n",
        "        \n",
        "    u = fixed_effects + r\n",
        "        \n",
        "    if prediction == False: \n",
        "    \n",
        "      if gaussian_likelihood == True: \n",
        "        log_lik = self.log_likelihood_Gaussian(z, fixed_effects, sigma)\n",
        "\n",
        "      else: \n",
        "        pass\n",
        "      \n",
        "      return log_lik, sigma\n",
        "    \n",
        "    else: \n",
        "      return sigma\n",
        "   \n",
        "  \n",
        "  def log_likelihood_Gaussian(self, z, f, sigma):\n",
        "    log_p = torch.zeros(sigma.shape)\n",
        "    \n",
        "    for i in range(sigma.shape[0]):\n",
        "      for j in range(sigma.shape[1]): \n",
        "        log_pdf = torch.distributions.normal.Normal(0, sigma[i,j]).log_prob(z[i,j] - f[i,j])    #CHANGED THIS LINE AND NEXT TO HAVE FIXED EFFECTS AS MEAN \n",
        "        #scale the likelihood to 0-1\n",
        "        log_norm_constant = torch.distributions.normal.Normal(0, sigma[i,j]).log_prob(0)\n",
        "        log_p[i,j] = log_pdf - log_norm_constant\n",
        "    \n",
        "    log_lik = torch.sum(log_p)\n",
        "\n",
        "    return log_lik\n",
        "  \n",
        "  \n",
        "  def log_likelihood_nonGaussian(self, ): #to do \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGd_qELTtqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = number_series\n",
        "num_epochs = 1000\n",
        "hidden_units_global = 50\n",
        "hidden_units_local = 5\n",
        "n_factors = 10 \n",
        "early_stop_patience = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnaiB4RyWtVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_model = GlobalEffects(input_size = 5, num_factors = n_factors , hidden_size = hidden_units_global, batch_size= number_series)  \n",
        "local_model = DF_RNN(5, hidden_size = hidden_units_local, batch_size = 1, num_series = number_series, output_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZumPtm7ZCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b2eaba0-8202-401d-ec34-641b0ec1067d"
      },
      "source": [
        "## TRAINING ##\n",
        "\n",
        "optimiser = torch.optim.SGD(list(global_model.parameters()) + list(local_model.parameters()), lr = learning_rate)\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "early_stop_count = 0\n",
        " \n",
        "for t in range(num_epochs): \n",
        "  global_model.zero_grad()\n",
        "  global_hidden = global_model.init_hidden()\n",
        "  \n",
        "  local_model.zero_grad()\n",
        "  local_hidden = local_model.init_hidden()\n",
        "  \n",
        "  #data_batch = covars_data\n",
        "  #print(data_batch.shape)\n",
        "  \n",
        "  batch_index = np.random.randint(0,number_windows)\n",
        "  data_batch = covars_train_data[:,batch_index,:,:].contiguous()\n",
        "  \n",
        "  fixed_effects = global_model(data_batch, global_hidden)\n",
        "\n",
        "  log_lik, sigma = local_model(data_batch, local_hidden, fixed_effects, gaussian_likelihood = True, prediction = False)\n",
        "\n",
        "  batch_loss = -1*log_lik\n",
        "    \n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "  batch_loss.backward()\n",
        "\n",
        "  optimiser.step()\n",
        "  \n",
        "  train_loss.append(batch_loss.item())\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    test_data_batch = covars_test_data\n",
        "    fixed_effects = global_model(test_data_batch, global_hidden)\n",
        "    \n",
        "    data = test_data_batch\n",
        "    log_lik, sigma = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True, prediction = False)\n",
        "      \n",
        "    test_batch_loss = -1*log_lik\n",
        "      \n",
        "    test_loss.append(test_batch_loss.item())\n",
        "    \n",
        "    if t%100 == 0: \n",
        "      print('sigma', sigma)\n",
        "      print('fixed effects', fixed_effects)\n",
        "      \n",
        "  #early stopping\n",
        "  if test_loss[t] > test_loss[t-1]: \n",
        "    early_stop_count += 1\n",
        "    if early_stop_count == early_stop_patience:\n",
        "      break\n",
        "  else: \n",
        "    early_stop_count = 0 \n",
        "  \n",
        "  print(\"Epoch: \", t, \"loss: \", batch_loss.item(), \"test loss: \", test_batch_loss.item())"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sigma tensor([[5.1484e-01, 4.1710e-01, 3.6031e-01,  ..., 3.2857e-01, 3.2971e-01,\n",
            "         4.1782e-01],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [4.0815e-01, 4.2150e-01, 4.6111e-01,  ..., 4.1607e-01, 4.1503e-01,\n",
            "         3.1157e-01],\n",
            "        ...,\n",
            "        [2.0368e-01, 4.6534e-02, 4.1005e-02,  ..., 3.4726e-01, 3.5206e-01,\n",
            "         2.8546e-01],\n",
            "        [2.7380e-01, 6.0654e-01, 7.2713e-01,  ..., 6.0675e-01, 6.0457e-01,\n",
            "         6.5303e-01],\n",
            "        [1.4311e+01, 4.4390e+00, 3.6773e+01,  ..., 1.3181e+01, 3.6773e+01,\n",
            "         1.3883e+01]])\n",
            "fixed effects tensor([[1.3729e-03, 1.1467e-03, 1.1472e-03,  ..., 2.4912e-03, 2.4933e-03,\n",
            "         2.7050e-03],\n",
            "        [2.3006e+01, 2.1512e+01, 2.1532e+01,  ..., 2.1669e+01, 2.1686e+01,\n",
            "         2.3283e+01],\n",
            "        [3.6673e-03, 3.4018e-03, 3.4044e-03,  ..., 3.4302e-03, 3.4326e-03,\n",
            "         3.7489e-03],\n",
            "        ...,\n",
            "        [8.1066e-03, 7.4959e-03, 7.5009e-03,  ..., 7.5264e-03, 7.5307e-03,\n",
            "         8.1812e-03],\n",
            "        [2.1600e-03, 2.0031e-03, 2.0047e-03,  ..., 2.0186e-03, 2.0200e-03,\n",
            "         2.1946e-03],\n",
            "        [4.6419e-01, 4.2833e-01, 4.2857e-01,  ..., 4.2904e-01, 4.2925e-01,\n",
            "         4.6734e-01]])\n",
            "Epoch:  0 loss:  1066.413330078125 test loss:  6.81099271774292\n",
            "Epoch:  1 loss:  61.55538558959961 test loss:  5.521987438201904\n",
            "Epoch:  2 loss:  4.257598876953125 test loss:  4.221065521240234\n",
            "Epoch:  3 loss:  2.375579833984375 test loss:  3.7527613639831543\n",
            "Epoch:  4 loss:  2.3085336685180664 test loss:  3.4382238388061523\n",
            "Epoch:  5 loss:  3.815560817718506 test loss:  2.7958321571350098\n",
            "Epoch:  6 loss:  1.7048993110656738 test loss:  2.649217367172241\n",
            "Epoch:  7 loss:  1.8666455745697021 test loss:  2.4996259212493896\n",
            "Epoch:  8 loss:  2.363689422607422 test loss:  2.376802444458008\n",
            "Epoch:  9 loss:  1.4249213933944702 test loss:  2.2818379402160645\n",
            "Epoch:  10 loss:  1.4639943838119507 test loss:  2.206531524658203\n",
            "Epoch:  11 loss:  1.366032600402832 test loss:  2.1274490356445312\n",
            "Epoch:  12 loss:  1.228564739227295 test loss:  2.0511746406555176\n",
            "Epoch:  13 loss:  1.1699566841125488 test loss:  1.9865143299102783\n",
            "Epoch:  14 loss:  1.1456027030944824 test loss:  1.9272494316101074\n",
            "Epoch:  15 loss:  1.2846776247024536 test loss:  1.8707976341247559\n",
            "Epoch:  16 loss:  1.1406145095825195 test loss:  1.8293876647949219\n",
            "Epoch:  17 loss:  1.051371693611145 test loss:  1.7858989238739014\n",
            "Epoch:  18 loss:  1.0563892126083374 test loss:  1.7504284381866455\n",
            "Epoch:  19 loss:  1.575722098350525 test loss:  1.689284324645996\n",
            "Epoch:  20 loss:  0.7123443484306335 test loss:  1.677893877029419\n",
            "Epoch:  21 loss:  1.4447873830795288 test loss:  1.6362015008926392\n",
            "Epoch:  22 loss:  1.2155673503875732 test loss:  1.6133826971054077\n",
            "Epoch:  23 loss:  0.8727521300315857 test loss:  1.5871953964233398\n",
            "Epoch:  24 loss:  1.148590326309204 test loss:  1.5545085668563843\n",
            "Epoch:  25 loss:  1.0559576749801636 test loss:  1.5241811275482178\n",
            "Epoch:  26 loss:  1.7355880737304688 test loss:  1.452718734741211\n",
            "Epoch:  27 loss:  0.9166279435157776 test loss:  1.435569167137146\n",
            "Epoch:  28 loss:  0.8889462947845459 test loss:  1.4210224151611328\n",
            "Epoch:  29 loss:  0.6050750017166138 test loss:  1.4093225002288818\n",
            "Epoch:  30 loss:  0.7439221143722534 test loss:  1.3929024934768677\n",
            "Epoch:  31 loss:  1.215036392211914 test loss:  1.3632501363754272\n",
            "Epoch:  32 loss:  1.2570998668670654 test loss:  1.3335909843444824\n",
            "Epoch:  33 loss:  0.8132738471031189 test loss:  1.3200275897979736\n",
            "Epoch:  34 loss:  0.6701140999794006 test loss:  1.3180058002471924\n",
            "Epoch:  35 loss:  1.3009893894195557 test loss:  1.2830835580825806\n",
            "Epoch:  36 loss:  0.8387106657028198 test loss:  1.2668989896774292\n",
            "Epoch:  37 loss:  1.0560657978057861 test loss:  1.2508156299591064\n",
            "Epoch:  38 loss:  0.8889889717102051 test loss:  1.236791968345642\n",
            "Epoch:  39 loss:  1.339591145515442 test loss:  1.2127861976623535\n",
            "Epoch:  40 loss:  0.747126579284668 test loss:  1.1995967626571655\n",
            "Epoch:  41 loss:  0.5494276285171509 test loss:  1.1965726613998413\n",
            "Epoch:  42 loss:  0.6364700794219971 test loss:  1.1901731491088867\n",
            "Epoch:  43 loss:  0.7657110095024109 test loss:  1.1781890392303467\n",
            "Epoch:  44 loss:  0.7110389471054077 test loss:  1.1676201820373535\n",
            "Epoch:  45 loss:  0.6049219369888306 test loss:  1.1572444438934326\n",
            "Epoch:  46 loss:  0.5218086242675781 test loss:  1.1510590314865112\n",
            "Epoch:  47 loss:  0.5816277861595154 test loss:  1.1488089561462402\n",
            "Epoch:  48 loss:  0.5580543279647827 test loss:  1.1401379108428955\n",
            "Epoch:  49 loss:  1.0564801692962646 test loss:  1.1146790981292725\n",
            "Epoch:  50 loss:  0.7017992734909058 test loss:  1.0995937585830688\n",
            "Epoch:  51 loss:  1.0321555137634277 test loss:  1.0897670984268188\n",
            "Epoch:  52 loss:  0.7845331430435181 test loss:  1.076654076576233\n",
            "Epoch:  53 loss:  0.854141116142273 test loss:  1.0551328659057617\n",
            "Epoch:  54 loss:  0.6186478137969971 test loss:  1.0505421161651611\n",
            "Epoch:  55 loss:  0.6395725607872009 test loss:  1.0443565845489502\n",
            "Epoch:  56 loss:  0.7794216275215149 test loss:  1.0405948162078857\n",
            "Epoch:  57 loss:  0.8028037548065186 test loss:  1.0232924222946167\n",
            "Epoch:  58 loss:  0.597224771976471 test loss:  1.0178345441818237\n",
            "Epoch:  59 loss:  0.9689386487007141 test loss:  1.0085117816925049\n",
            "Epoch:  60 loss:  0.5801947116851807 test loss:  1.0033581256866455\n",
            "Epoch:  61 loss:  0.6451556086540222 test loss:  0.9921481013298035\n",
            "Epoch:  62 loss:  0.8605769276618958 test loss:  0.9759082198143005\n",
            "Epoch:  63 loss:  0.7625048756599426 test loss:  0.9593902230262756\n",
            "Epoch:  64 loss:  0.5616673231124878 test loss:  0.95660001039505\n",
            "Epoch:  65 loss:  0.7492185235023499 test loss:  0.9486280083656311\n",
            "Epoch:  66 loss:  0.9435385465621948 test loss:  0.9324753880500793\n",
            "Epoch:  67 loss:  0.8944168090820312 test loss:  0.9201890230178833\n",
            "Epoch:  68 loss:  0.8944836258888245 test loss:  0.9073678851127625\n",
            "Epoch:  69 loss:  0.47303855419158936 test loss:  0.9037721753120422\n",
            "Epoch:  70 loss:  0.4916769564151764 test loss:  0.8996646404266357\n",
            "Epoch:  71 loss:  0.7155890464782715 test loss:  0.8918293714523315\n",
            "Epoch:  72 loss:  0.37863126397132874 test loss:  0.8905233144760132\n",
            "Epoch:  73 loss:  0.6876199841499329 test loss:  0.8834349513053894\n",
            "Epoch:  74 loss:  0.4685765206813812 test loss:  0.8853874206542969\n",
            "Epoch:  75 loss:  0.691451907157898 test loss:  0.8771364688873291\n",
            "Epoch:  76 loss:  0.7777565717697144 test loss:  0.8664554357528687\n",
            "Epoch:  77 loss:  0.45377203822135925 test loss:  0.8681278228759766\n",
            "Epoch:  78 loss:  0.45040810108184814 test loss:  0.8634374141693115\n",
            "Epoch:  79 loss:  1.0843483209609985 test loss:  0.8508917093276978\n",
            "Epoch:  80 loss:  0.5493647456169128 test loss:  0.8433266878128052\n",
            "Epoch:  81 loss:  0.4405283033847809 test loss:  0.8398352265357971\n",
            "Epoch:  82 loss:  0.5418194532394409 test loss:  0.8352900147438049\n",
            "Epoch:  83 loss:  0.6966111063957214 test loss:  0.8268387317657471\n",
            "Epoch:  84 loss:  0.5071580410003662 test loss:  0.8244743347167969\n",
            "Epoch:  85 loss:  0.4945337474346161 test loss:  0.8201186656951904\n",
            "Epoch:  86 loss:  0.4597170650959015 test loss:  0.8180586099624634\n",
            "Epoch:  87 loss:  0.6063615083694458 test loss:  0.8090426921844482\n",
            "Epoch:  88 loss:  0.4641890823841095 test loss:  0.8048868179321289\n",
            "Epoch:  89 loss:  0.3318781554698944 test loss:  0.8044862151145935\n",
            "Epoch:  90 loss:  0.7534753680229187 test loss:  0.7967042326927185\n",
            "Epoch:  91 loss:  0.5082677602767944 test loss:  0.7945595383644104\n",
            "Epoch:  92 loss:  0.45090773701667786 test loss:  0.7922227382659912\n",
            "Epoch:  93 loss:  0.5170843005180359 test loss:  0.7861224412918091\n",
            "Epoch:  94 loss:  0.4714389741420746 test loss:  0.7827286124229431\n",
            "Epoch:  95 loss:  0.49278560280799866 test loss:  0.7794814109802246\n",
            "Epoch:  96 loss:  0.42876362800598145 test loss:  0.7763146758079529\n",
            "Epoch:  97 loss:  0.7544763088226318 test loss:  0.7613351345062256\n",
            "Epoch:  98 loss:  0.40283888578414917 test loss:  0.7565031051635742\n",
            "Epoch:  99 loss:  0.3309755027294159 test loss:  0.7569288611412048\n",
            "sigma tensor([[1.0482e+00, 1.0328e+00, 1.0265e+00,  ..., 1.0125e+00, 1.0121e+00,\n",
            "         1.1074e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [7.6058e-01, 8.4168e-01, 9.0210e-01,  ..., 9.2419e-01, 9.2380e-01,\n",
            "         8.2659e-01],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [7.4715e-01, 1.2403e+00, 1.3695e+00,  ..., 1.3550e+00, 1.3542e+00,\n",
            "         1.4480e+00],\n",
            "        [1.4289e+01, 5.2996e+00, 3.6761e+01,  ..., 1.3220e+01, 3.6761e+01,\n",
            "         1.3926e+01]])\n",
            "fixed effects tensor([[7.1703e-03, 5.9476e-03, 5.9397e-03,  ..., 1.1982e-02, 1.1973e-02,\n",
            "         1.5860e-02],\n",
            "        [1.1962e+01, 1.0406e+01, 1.0382e+01,  ..., 9.4312e+00, 9.4061e+00,\n",
            "         1.3573e+01],\n",
            "        [1.2421e-02, 1.1448e-02, 1.1437e-02,  ..., 1.1011e-02, 1.1000e-02,\n",
            "         1.4887e-02],\n",
            "        ...,\n",
            "        [6.9216e-02, 6.0801e-02, 6.0595e-02,  ..., 5.3551e-02, 5.3342e-02,\n",
            "         7.8620e-02],\n",
            "        [1.3504e-02, 1.2683e-02, 1.2674e-02,  ..., 1.2233e-02, 1.2224e-02,\n",
            "         1.6054e-02],\n",
            "        [2.1551e-01, 1.7909e-01, 1.7836e-01,  ..., 1.5501e-01, 1.5427e-01,\n",
            "         2.4256e-01]])\n",
            "Epoch:  100 loss:  0.5900628566741943 test loss:  0.750554084777832\n",
            "Epoch:  101 loss:  0.47304487228393555 test loss:  0.7467410564422607\n",
            "Epoch:  102 loss:  0.37897101044654846 test loss:  0.7443313598632812\n",
            "Epoch:  103 loss:  0.4572952091693878 test loss:  0.7380112409591675\n",
            "Epoch:  104 loss:  0.46986305713653564 test loss:  0.7369942665100098\n",
            "Epoch:  105 loss:  0.6652989387512207 test loss:  0.7262200117111206\n",
            "Epoch:  106 loss:  0.4122872054576874 test loss:  0.7239931225776672\n",
            "Epoch:  107 loss:  0.3598293364048004 test loss:  0.7235711812973022\n",
            "Epoch:  108 loss:  0.4542691111564636 test loss:  0.7220419645309448\n",
            "Epoch:  109 loss:  0.457442969083786 test loss:  0.7157161235809326\n",
            "Epoch:  110 loss:  0.6082127690315247 test loss:  0.709441065788269\n",
            "Epoch:  111 loss:  0.4324071407318115 test loss:  0.7043546438217163\n",
            "Epoch:  112 loss:  0.3789812922477722 test loss:  0.7021523714065552\n",
            "Epoch:  113 loss:  0.696592390537262 test loss:  0.6930942535400391\n",
            "Epoch:  114 loss:  0.3897097408771515 test loss:  0.6899368166923523\n",
            "Epoch:  115 loss:  0.42930343747138977 test loss:  0.6853646636009216\n",
            "Epoch:  116 loss:  0.46229955554008484 test loss:  0.6811367869377136\n",
            "Epoch:  117 loss:  0.5834388732910156 test loss:  0.6777710318565369\n",
            "Epoch:  118 loss:  0.41891467571258545 test loss:  0.677186131477356\n",
            "Epoch:  119 loss:  0.3373461961746216 test loss:  0.6775842905044556\n",
            "Epoch:  120 loss:  0.37760522961616516 test loss:  0.6757042407989502\n",
            "Epoch:  121 loss:  0.6523799896240234 test loss:  0.6665600538253784\n",
            "Epoch:  122 loss:  0.4527874290943146 test loss:  0.6691434383392334\n",
            "Epoch:  123 loss:  0.7707077264785767 test loss:  0.6606003046035767\n",
            "Epoch:  124 loss:  0.4598977267742157 test loss:  0.6557867527008057\n",
            "Epoch:  125 loss:  0.45288601517677307 test loss:  0.6511026620864868\n",
            "Epoch:  126 loss:  0.5001416206359863 test loss:  0.6485714316368103\n",
            "Epoch:  127 loss:  0.3360726535320282 test loss:  0.6482112407684326\n",
            "Epoch:  128 loss:  0.5108503699302673 test loss:  0.6407067775726318\n",
            "Epoch:  129 loss:  0.39848393201828003 test loss:  0.6376584768295288\n",
            "Epoch:  130 loss:  0.45318132638931274 test loss:  0.6382777094841003\n",
            "Epoch:  131 loss:  0.4848977029323578 test loss:  0.6356582045555115\n",
            "Epoch:  132 loss:  0.6037615537643433 test loss:  0.6286284923553467\n",
            "Epoch:  133 loss:  0.29235759377479553 test loss:  0.6311740875244141\n",
            "Epoch:  134 loss:  0.6513200998306274 test loss:  0.6243242621421814\n",
            "Epoch:  135 loss:  0.5350732803344727 test loss:  0.6214292049407959\n",
            "Epoch:  136 loss:  0.4973788261413574 test loss:  0.621082067489624\n",
            "Epoch:  137 loss:  0.42375048995018005 test loss:  0.6168413162231445\n",
            "Epoch:  138 loss:  0.4088955819606781 test loss:  0.6143326759338379\n",
            "Epoch:  139 loss:  0.48546549677848816 test loss:  0.6095601320266724\n",
            "Epoch:  140 loss:  0.3740154206752777 test loss:  0.6103025674819946\n",
            "Epoch:  141 loss:  0.8142486214637756 test loss:  0.6052017211914062\n",
            "Epoch:  142 loss:  0.31602171063423157 test loss:  0.6042081117630005\n",
            "Epoch:  143 loss:  0.3812761902809143 test loss:  0.6009951829910278\n",
            "Epoch:  144 loss:  0.3400856852531433 test loss:  0.6013604998588562\n",
            "Epoch:  145 loss:  0.3077843189239502 test loss:  0.6000092029571533\n",
            "Epoch:  146 loss:  0.383523166179657 test loss:  0.5962994694709778\n",
            "Epoch:  147 loss:  0.24295267462730408 test loss:  0.5976170897483826\n",
            "Epoch:  148 loss:  0.3753804564476013 test loss:  0.5936511754989624\n",
            "Epoch:  149 loss:  0.26106658577919006 test loss:  0.5946332216262817\n",
            "Epoch:  150 loss:  0.2692463994026184 test loss:  0.5955830216407776\n",
            "Epoch:  151 loss:  0.45401039719581604 test loss:  0.5879521369934082\n",
            "Epoch:  152 loss:  0.5156973600387573 test loss:  0.5835335850715637\n",
            "Epoch:  153 loss:  0.44219085574150085 test loss:  0.5807558298110962\n",
            "Epoch:  154 loss:  0.3855602741241455 test loss:  0.576423704624176\n",
            "Epoch:  155 loss:  0.4221116304397583 test loss:  0.5730172395706177\n",
            "Epoch:  156 loss:  0.4868928790092468 test loss:  0.5689817667007446\n",
            "Epoch:  157 loss:  0.5458756685256958 test loss:  0.5644631385803223\n",
            "Epoch:  158 loss:  0.3093990683555603 test loss:  0.566826343536377\n",
            "Epoch:  159 loss:  0.23481181263923645 test loss:  0.5687391757965088\n",
            "Epoch:  160 loss:  0.3462652564048767 test loss:  0.5689663887023926\n",
            "Epoch:  161 loss:  0.6074942350387573 test loss:  0.5657345056533813\n",
            "Epoch:  162 loss:  0.3909974992275238 test loss:  0.5636531114578247\n",
            "Epoch:  163 loss:  0.34828218817710876 test loss:  0.5597256422042847\n",
            "Epoch:  164 loss:  0.29280832409858704 test loss:  0.5591063499450684\n",
            "Epoch:  165 loss:  0.3140002489089966 test loss:  0.5582480430603027\n",
            "Epoch:  166 loss:  0.3138434886932373 test loss:  0.5609252452850342\n",
            "Epoch:  167 loss:  0.3355753421783447 test loss:  0.5603467226028442\n",
            "Epoch:  168 loss:  0.45240408182144165 test loss:  0.5551008582115173\n",
            "Epoch:  169 loss:  0.48785078525543213 test loss:  0.5509165525436401\n",
            "Epoch:  170 loss:  0.36524370312690735 test loss:  0.5489291548728943\n",
            "Epoch:  171 loss:  0.24854952096939087 test loss:  0.5486425757408142\n",
            "Epoch:  172 loss:  0.24693933129310608 test loss:  0.5481998920440674\n",
            "Epoch:  173 loss:  0.5570027828216553 test loss:  0.5424072742462158\n",
            "Epoch:  174 loss:  0.38560280203819275 test loss:  0.5399810075759888\n",
            "Epoch:  175 loss:  0.5612133741378784 test loss:  0.5344164371490479\n",
            "Epoch:  176 loss:  0.301925927400589 test loss:  0.5367881059646606\n",
            "Epoch:  177 loss:  0.3760965168476105 test loss:  0.5335291624069214\n",
            "Epoch:  178 loss:  0.34213003516197205 test loss:  0.5346701741218567\n",
            "Epoch:  179 loss:  0.5629050731658936 test loss:  0.5314217209815979\n",
            "Epoch:  180 loss:  0.3266734182834625 test loss:  0.5304720401763916\n",
            "Epoch:  181 loss:  0.3775160014629364 test loss:  0.5280600786209106\n",
            "Epoch:  182 loss:  0.2998768091201782 test loss:  0.5266834497451782\n",
            "Epoch:  183 loss:  0.35130104422569275 test loss:  0.5232049226760864\n",
            "Epoch:  184 loss:  0.4435321092605591 test loss:  0.5196951627731323\n",
            "Epoch:  185 loss:  0.6401390433311462 test loss:  0.5148423314094543\n",
            "Epoch:  186 loss:  0.5230211019515991 test loss:  0.5122255682945251\n",
            "Epoch:  187 loss:  0.42372575402259827 test loss:  0.5130107402801514\n",
            "Epoch:  188 loss:  0.3460965156555176 test loss:  0.5108274221420288\n",
            "Epoch:  189 loss:  0.35655489563941956 test loss:  0.5104799270629883\n",
            "Epoch:  190 loss:  0.25978127121925354 test loss:  0.5110766887664795\n",
            "Epoch:  191 loss:  0.26063570380210876 test loss:  0.5122863054275513\n",
            "Epoch:  192 loss:  0.3472377359867096 test loss:  0.5108928680419922\n",
            "Epoch:  193 loss:  0.31333547830581665 test loss:  0.5097310543060303\n",
            "Epoch:  194 loss:  0.33223757147789 test loss:  0.5070290565490723\n",
            "Epoch:  195 loss:  0.25312644243240356 test loss:  0.5078860521316528\n",
            "Epoch:  196 loss:  0.31492477655410767 test loss:  0.504271388053894\n",
            "Epoch:  197 loss:  0.3026488125324249 test loss:  0.5036826133728027\n",
            "Epoch:  198 loss:  0.32642462849617004 test loss:  0.5051199197769165\n",
            "Epoch:  199 loss:  0.33543261885643005 test loss:  0.5051859617233276\n",
            "sigma tensor([[1.2302e+00, 1.2362e+00, 1.2443e+00,  ..., 1.2479e+00, 1.2473e+00,\n",
            "         1.3471e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [8.5743e-01, 9.6344e-01, 1.0320e+00,  ..., 1.0668e+00, 1.0665e+00,\n",
            "         9.6985e-01],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [9.0779e-01, 1.4583e+00, 1.5906e+00,  ..., 1.6058e+00, 1.6053e+00,\n",
            "         1.7066e+00],\n",
            "        [1.4287e+01, 5.3508e+00, 3.6760e+01,  ..., 1.3223e+01, 3.6760e+01,\n",
            "         1.3929e+01]])\n",
            "fixed effects tensor([[8.2208e-03, 6.9591e-03, 6.9715e-03,  ..., 1.5906e-02, 1.5938e-02,\n",
            "         2.2676e-02],\n",
            "        [6.6238e+00, 4.8275e+00, 4.8173e+00,  ..., 4.2906e+00, 4.2806e+00,\n",
            "         1.0596e+01],\n",
            "        [1.1674e-02, 1.0436e-02, 1.0449e-02,  ..., 1.0752e-02, 1.0766e-02,\n",
            "         1.7145e-02],\n",
            "        ...,\n",
            "        [3.7387e-02, 2.7544e-02, 2.7417e-02,  ..., 2.2838e-02, 2.2714e-02,\n",
            "         6.0397e-02],\n",
            "        [1.5523e-02, 1.4648e-02, 1.4674e-02,  ..., 1.5218e-02, 1.5245e-02,\n",
            "         2.1851e-02],\n",
            "        [9.3935e-02, 5.2933e-02, 5.2422e-02,  ..., 3.6194e-02, 3.5693e-02,\n",
            "         1.6554e-01]])\n",
            "Epoch:  200 loss:  0.22950398921966553 test loss:  0.5066078305244446\n",
            "Epoch:  201 loss:  0.3594767451286316 test loss:  0.5025656223297119\n",
            "Epoch:  202 loss:  0.24717095494270325 test loss:  0.5026243925094604\n",
            "Epoch:  203 loss:  0.40895602107048035 test loss:  0.4988553822040558\n",
            "Epoch:  204 loss:  0.29376402497291565 test loss:  0.4980529546737671\n",
            "Epoch:  205 loss:  0.22779116034507751 test loss:  0.49738267064094543\n",
            "Epoch:  206 loss:  0.4835561215877533 test loss:  0.4911535978317261\n",
            "Epoch:  207 loss:  0.2583625912666321 test loss:  0.4913860559463501\n",
            "Epoch:  208 loss:  0.48151129484176636 test loss:  0.4867098331451416\n",
            "Epoch:  209 loss:  0.3424367308616638 test loss:  0.4867379069328308\n",
            "Epoch:  210 loss:  0.430698037147522 test loss:  0.48524945974349976\n",
            "Epoch:  211 loss:  0.4854621887207031 test loss:  0.4814079999923706\n",
            "Epoch:  212 loss:  0.2834344506263733 test loss:  0.48428404331207275\n",
            "Epoch:  213 loss:  0.5866210460662842 test loss:  0.4788547158241272\n",
            "Epoch:  214 loss:  0.3454539179801941 test loss:  0.48003512620925903\n",
            "Epoch:  215 loss:  0.24808889627456665 test loss:  0.47897595167160034\n",
            "Epoch:  216 loss:  0.30011141300201416 test loss:  0.47629570960998535\n",
            "Epoch:  217 loss:  0.39427638053894043 test loss:  0.47438377141952515\n",
            "Epoch:  218 loss:  0.3149852752685547 test loss:  0.47251999378204346\n",
            "Epoch:  219 loss:  0.24093079566955566 test loss:  0.4740062355995178\n",
            "Epoch:  220 loss:  0.19023209810256958 test loss:  0.47470909357070923\n",
            "Epoch:  221 loss:  0.27424895763397217 test loss:  0.47399622201919556\n",
            "Epoch:  222 loss:  0.3131251931190491 test loss:  0.47142738103866577\n",
            "Epoch:  223 loss:  0.293084979057312 test loss:  0.46902626752853394\n",
            "Epoch:  224 loss:  0.4645194411277771 test loss:  0.46453583240509033\n",
            "Epoch:  225 loss:  0.25704485177993774 test loss:  0.46679526567459106\n",
            "Epoch:  226 loss:  0.28707748651504517 test loss:  0.4678652286529541\n",
            "Epoch:  227 loss:  0.5234362483024597 test loss:  0.4660643935203552\n",
            "Epoch:  228 loss:  0.32953542470932007 test loss:  0.468641996383667\n",
            "Epoch:  229 loss:  0.21473562717437744 test loss:  0.47012561559677124\n",
            "Epoch:  230 loss:  0.2968757748603821 test loss:  0.4699931740760803\n",
            "Epoch:  231 loss:  0.29006654024124146 test loss:  0.4655300974845886\n",
            "Epoch:  232 loss:  0.23826467990875244 test loss:  0.4650871157646179\n",
            "Epoch:  233 loss:  0.23076152801513672 test loss:  0.4653323292732239\n",
            "Epoch:  234 loss:  0.2629319429397583 test loss:  0.4635096788406372\n",
            "Epoch:  235 loss:  0.2861788868904114 test loss:  0.4600924849510193\n",
            "Epoch:  236 loss:  0.43902838230133057 test loss:  0.45581114292144775\n",
            "Epoch:  237 loss:  0.30541878938674927 test loss:  0.4540078639984131\n",
            "Epoch:  238 loss:  0.30721908807754517 test loss:  0.45512574911117554\n",
            "Epoch:  239 loss:  0.38037705421447754 test loss:  0.45260584354400635\n",
            "Epoch:  240 loss:  0.3496840000152588 test loss:  0.451850950717926\n",
            "Epoch:  241 loss:  0.447338342666626 test loss:  0.448559045791626\n",
            "Epoch:  242 loss:  0.370710551738739 test loss:  0.44722574949264526\n",
            "Epoch:  243 loss:  0.28994566202163696 test loss:  0.4485679864883423\n",
            "Epoch:  244 loss:  0.4005395174026489 test loss:  0.44670212268829346\n",
            "Epoch:  245 loss:  0.37234675884246826 test loss:  0.444587767124176\n",
            "Epoch:  246 loss:  0.37875795364379883 test loss:  0.4417686462402344\n",
            "Epoch:  247 loss:  0.2271386981010437 test loss:  0.44343018531799316\n",
            "Epoch:  248 loss:  0.2670931816101074 test loss:  0.44454455375671387\n",
            "Epoch:  249 loss:  0.22820228338241577 test loss:  0.44357526302337646\n",
            "Epoch:  250 loss:  0.35370105504989624 test loss:  0.4404134750366211\n",
            "Epoch:  251 loss:  0.49994879961013794 test loss:  0.43936842679977417\n",
            "Epoch:  252 loss:  0.36163127422332764 test loss:  0.43808794021606445\n",
            "Epoch:  253 loss:  0.2732446789741516 test loss:  0.43630725145339966\n",
            "Epoch:  254 loss:  0.26452237367630005 test loss:  0.43651652336120605\n",
            "Epoch:  255 loss:  0.3616718053817749 test loss:  0.4353156089782715\n",
            "Epoch:  256 loss:  0.2343706488609314 test loss:  0.43565618991851807\n",
            "Epoch:  257 loss:  0.26664721965789795 test loss:  0.43673956394195557\n",
            "Epoch:  258 loss:  0.27760541439056396 test loss:  0.43518388271331787\n",
            "Epoch:  259 loss:  0.21176165342330933 test loss:  0.4358054995536804\n",
            "Epoch:  260 loss:  0.2962082028388977 test loss:  0.43374258279800415\n",
            "Epoch:  261 loss:  0.3351282477378845 test loss:  0.43007898330688477\n",
            "Epoch:  262 loss:  0.2255757451057434 test loss:  0.4304758906364441\n",
            "Epoch:  263 loss:  0.2935715317726135 test loss:  0.4302402138710022\n",
            "Epoch:  264 loss:  0.3040578365325928 test loss:  0.42964422702789307\n",
            "Epoch:  265 loss:  0.31192290782928467 test loss:  0.4279298186302185\n",
            "Epoch:  266 loss:  0.2527827024459839 test loss:  0.4272608160972595\n",
            "Epoch:  267 loss:  0.259257435798645 test loss:  0.42709535360336304\n",
            "Epoch:  268 loss:  0.2509324550628662 test loss:  0.42634665966033936\n",
            "Epoch:  269 loss:  0.2647492289543152 test loss:  0.4248965382575989\n",
            "Epoch:  270 loss:  0.43715935945510864 test loss:  0.4243093729019165\n",
            "Epoch:  271 loss:  0.25680601596832275 test loss:  0.4241766333580017\n",
            "Epoch:  272 loss:  0.2147749662399292 test loss:  0.4255111813545227\n",
            "Epoch:  273 loss:  0.3591402769088745 test loss:  0.4222819209098816\n",
            "Epoch:  274 loss:  0.4175744652748108 test loss:  0.41910332441329956\n",
            "Epoch:  275 loss:  0.5128430724143982 test loss:  0.4163840413093567\n",
            "Epoch:  276 loss:  0.2774040102958679 test loss:  0.4158055782318115\n",
            "Epoch:  277 loss:  0.21753311157226562 test loss:  0.41605526208877563\n",
            "Epoch:  278 loss:  0.4062013030052185 test loss:  0.4137178063392639\n",
            "Epoch:  279 loss:  0.3016384243965149 test loss:  0.41305655241012573\n",
            "Epoch:  280 loss:  0.26647448539733887 test loss:  0.4128163456916809\n",
            "Epoch:  281 loss:  0.28224050998687744 test loss:  0.4131370186805725\n",
            "Epoch:  282 loss:  0.2991429567337036 test loss:  0.4117875099182129\n",
            "Epoch:  283 loss:  0.583669900894165 test loss:  0.410422146320343\n",
            "Epoch:  284 loss:  0.2325226068496704 test loss:  0.41095906496047974\n",
            "Epoch:  285 loss:  0.2495160698890686 test loss:  0.4103913903236389\n",
            "Epoch:  286 loss:  0.3428739309310913 test loss:  0.40897297859191895\n",
            "Epoch:  287 loss:  0.2508661150932312 test loss:  0.41030383110046387\n",
            "Epoch:  288 loss:  0.2250739336013794 test loss:  0.4102330207824707\n",
            "Epoch:  289 loss:  0.27405667304992676 test loss:  0.4097388982772827\n",
            "Epoch:  290 loss:  0.24244433641433716 test loss:  0.4117467403411865\n",
            "Epoch:  291 loss:  0.4121097922325134 test loss:  0.40668588876724243\n",
            "Epoch:  292 loss:  0.27673864364624023 test loss:  0.40577173233032227\n",
            "Epoch:  293 loss:  0.33373576402664185 test loss:  0.40393710136413574\n",
            "Epoch:  294 loss:  0.25510066747665405 test loss:  0.4041202664375305\n",
            "Epoch:  295 loss:  0.2522169351577759 test loss:  0.4028361439704895\n",
            "Epoch:  296 loss:  0.2512463927268982 test loss:  0.4017651677131653\n",
            "Epoch:  297 loss:  0.2600725293159485 test loss:  0.4031904339790344\n",
            "Epoch:  298 loss:  0.2389388084411621 test loss:  0.4039962887763977\n",
            "Epoch:  299 loss:  0.22411388158798218 test loss:  0.40596282482147217\n",
            "sigma tensor([[1.3135e+00, 1.3303e+00, 1.3459e+00,  ..., 1.3573e+00, 1.3566e+00,\n",
            "         1.4589e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [9.2637e-01, 1.0513e+00, 1.1261e+00,  ..., 1.1683e+00, 1.1681e+00,\n",
            "         1.0718e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.0198e+00, 1.6120e+00, 1.7465e+00,  ..., 1.7808e+00, 1.7805e+00,\n",
            "         1.8848e+00],\n",
            "        [1.4287e+01, 5.3560e+00, 3.6760e+01,  ..., 1.3223e+01, 3.6760e+01,\n",
            "         1.3930e+01]])\n",
            "fixed effects tensor([[8.1168e-03, 6.3249e-03, 6.3493e-03,  ..., 1.5492e-02, 1.5547e-02,\n",
            "         2.4429e-02],\n",
            "        [5.9483e+00, 3.8212e+00, 3.8333e+00,  ..., 3.9580e+00, 3.9705e+00,\n",
            "         1.2013e+01],\n",
            "        [1.2125e-02, 1.0416e-02, 1.0453e-02,  ..., 1.1508e-02, 1.1547e-02,\n",
            "         2.0166e-02],\n",
            "        ...,\n",
            "        [3.3142e-02, 2.1380e-02, 2.1381e-02,  ..., 2.0565e-02, 2.0569e-02,\n",
            "         6.8249e-02],\n",
            "        [1.6353e-02, 1.5022e-02, 1.5076e-02,  ..., 1.6453e-02, 1.6508e-02,\n",
            "         2.5486e-02],\n",
            "        [7.7736e-02, 3.0370e-02, 3.0279e-02,  ..., 2.6530e-02, 2.6453e-02,\n",
            "         1.8973e-01]])\n",
            "Epoch:  300 loss:  0.2363795042037964 test loss:  0.40496915578842163\n",
            "Epoch:  301 loss:  0.20180779695510864 test loss:  0.405609130859375\n",
            "Epoch:  302 loss:  0.21653705835342407 test loss:  0.40472811460494995\n",
            "Epoch:  303 loss:  0.28293824195861816 test loss:  0.4050726890563965\n",
            "Epoch:  304 loss:  0.18119269609451294 test loss:  0.4057326316833496\n",
            "Epoch:  305 loss:  0.44065749645233154 test loss:  0.4033443331718445\n",
            "Epoch:  306 loss:  0.24881619215011597 test loss:  0.4003077745437622\n",
            "Epoch:  307 loss:  0.22972166538238525 test loss:  0.4012424945831299\n",
            "Epoch:  308 loss:  0.35339444875717163 test loss:  0.39750605821609497\n",
            "Epoch:  309 loss:  0.39139705896377563 test loss:  0.394774854183197\n",
            "Epoch:  310 loss:  0.34862983226776123 test loss:  0.392367959022522\n",
            "Epoch:  311 loss:  0.26021867990493774 test loss:  0.3927261233329773\n",
            "Epoch:  312 loss:  0.22618764638900757 test loss:  0.39249467849731445\n",
            "Epoch:  313 loss:  0.3021193742752075 test loss:  0.3919820785522461\n",
            "Epoch:  314 loss:  0.23974609375 test loss:  0.39197081327438354\n",
            "Epoch:  315 loss:  0.38305962085723877 test loss:  0.3888857364654541\n",
            "Epoch:  316 loss:  0.2379794716835022 test loss:  0.389562726020813\n",
            "Epoch:  317 loss:  0.23647916316986084 test loss:  0.3900623321533203\n",
            "Epoch:  318 loss:  0.26905298233032227 test loss:  0.38962364196777344\n",
            "Epoch:  319 loss:  0.20097070932388306 test loss:  0.39015650749206543\n",
            "Epoch:  320 loss:  0.156019926071167 test loss:  0.3908390402793884\n",
            "Epoch:  321 loss:  0.3587251305580139 test loss:  0.3885834813117981\n",
            "Epoch:  322 loss:  0.26009511947631836 test loss:  0.38824957609176636\n",
            "Epoch:  323 loss:  0.42988353967666626 test loss:  0.38652926683425903\n",
            "Epoch:  324 loss:  0.19679105281829834 test loss:  0.3873099684715271\n",
            "Epoch:  325 loss:  0.4242313504219055 test loss:  0.3861576318740845\n",
            "Epoch:  326 loss:  0.29441702365875244 test loss:  0.3831271529197693\n",
            "Epoch:  327 loss:  0.23187267780303955 test loss:  0.38301175832748413\n",
            "Epoch:  328 loss:  0.43994373083114624 test loss:  0.3823556900024414\n",
            "Epoch:  329 loss:  0.22536587715148926 test loss:  0.38321101665496826\n",
            "Epoch:  330 loss:  0.3981141448020935 test loss:  0.3806709051132202\n",
            "Epoch:  331 loss:  0.25591009855270386 test loss:  0.3805786371231079\n",
            "Epoch:  332 loss:  0.311803936958313 test loss:  0.37966465950012207\n",
            "Epoch:  333 loss:  0.4401955008506775 test loss:  0.3775938153266907\n",
            "Epoch:  334 loss:  0.22252631187438965 test loss:  0.3784668445587158\n",
            "Epoch:  335 loss:  0.26342636346817017 test loss:  0.37807559967041016\n",
            "Epoch:  336 loss:  0.3928133249282837 test loss:  0.37706589698791504\n",
            "Epoch:  337 loss:  0.25992757081985474 test loss:  0.3766266703605652\n",
            "Epoch:  338 loss:  0.2474350929260254 test loss:  0.3756559491157532\n",
            "Epoch:  339 loss:  0.2551543712615967 test loss:  0.37436407804489136\n",
            "Epoch:  340 loss:  0.30653250217437744 test loss:  0.37646156549453735\n",
            "Epoch:  341 loss:  0.255218505859375 test loss:  0.37493282556533813\n",
            "Epoch:  342 loss:  0.453432559967041 test loss:  0.3716605305671692\n",
            "Epoch:  343 loss:  0.21315163373947144 test loss:  0.37144529819488525\n",
            "Epoch:  344 loss:  0.25294584035873413 test loss:  0.37118107080459595\n",
            "Epoch:  345 loss:  0.1488695740699768 test loss:  0.37191861867904663\n",
            "Epoch:  346 loss:  0.23531097173690796 test loss:  0.3708432912826538\n",
            "Epoch:  347 loss:  0.19974738359451294 test loss:  0.3721300959587097\n",
            "Epoch:  348 loss:  0.19013941287994385 test loss:  0.37105125188827515\n",
            "Epoch:  349 loss:  0.2443738579750061 test loss:  0.37052804231643677\n",
            "Epoch:  350 loss:  0.2220391035079956 test loss:  0.369681179523468\n",
            "Epoch:  351 loss:  0.23034095764160156 test loss:  0.3676602244377136\n",
            "Epoch:  352 loss:  0.19219368696212769 test loss:  0.3679925203323364\n",
            "Epoch:  353 loss:  0.25395113229751587 test loss:  0.36733007431030273\n",
            "Epoch:  354 loss:  0.4427461624145508 test loss:  0.36451685428619385\n",
            "Epoch:  355 loss:  0.2744731903076172 test loss:  0.3633303642272949\n",
            "Epoch:  356 loss:  0.26537322998046875 test loss:  0.36279386281967163\n",
            "Epoch:  357 loss:  0.3030385971069336 test loss:  0.361716628074646\n",
            "Epoch:  358 loss:  0.27997535467147827 test loss:  0.3616842031478882\n",
            "Epoch:  359 loss:  0.22356832027435303 test loss:  0.3619305491447449\n",
            "Epoch:  360 loss:  0.17208874225616455 test loss:  0.36365389823913574\n",
            "Epoch:  361 loss:  0.2268679141998291 test loss:  0.36184436082839966\n",
            "Epoch:  362 loss:  0.23865652084350586 test loss:  0.36077308654785156\n",
            "Epoch:  363 loss:  0.24686086177825928 test loss:  0.36001646518707275\n",
            "Epoch:  364 loss:  0.2644805312156677 test loss:  0.35868602991104126\n",
            "Epoch:  365 loss:  0.24983274936676025 test loss:  0.35762423276901245\n",
            "Epoch:  366 loss:  0.1506587266921997 test loss:  0.3590337038040161\n",
            "Epoch:  367 loss:  0.24263566732406616 test loss:  0.35903704166412354\n",
            "Epoch:  368 loss:  0.4310431480407715 test loss:  0.3564227223396301\n",
            "Epoch:  369 loss:  0.32382428646087646 test loss:  0.3553363084793091\n",
            "Epoch:  370 loss:  0.21743565797805786 test loss:  0.35570114850997925\n",
            "Epoch:  371 loss:  0.18480050563812256 test loss:  0.35596710443496704\n",
            "Epoch:  372 loss:  0.2920878529548645 test loss:  0.35604166984558105\n",
            "Epoch:  373 loss:  0.40816420316696167 test loss:  0.3539748787879944\n",
            "Epoch:  374 loss:  0.18088150024414062 test loss:  0.35495370626449585\n",
            "Epoch:  375 loss:  0.2896946668624878 test loss:  0.35379743576049805\n",
            "Epoch:  376 loss:  0.23469918966293335 test loss:  0.3535914421081543\n",
            "Epoch:  377 loss:  0.20130103826522827 test loss:  0.35318416357040405\n",
            "Epoch:  378 loss:  0.3150494694709778 test loss:  0.3520055413246155\n",
            "Epoch:  379 loss:  0.2222234606742859 test loss:  0.3512195348739624\n",
            "Epoch:  380 loss:  0.21354681253433228 test loss:  0.3510451912879944\n",
            "Epoch:  381 loss:  0.3497844338417053 test loss:  0.3481748104095459\n",
            "Epoch:  382 loss:  0.3104288578033447 test loss:  0.3473605513572693\n",
            "Epoch:  383 loss:  0.178561270236969 test loss:  0.3485550880432129\n",
            "Epoch:  384 loss:  0.21131175756454468 test loss:  0.350180447101593\n",
            "Epoch:  385 loss:  0.30913907289505005 test loss:  0.34890252351760864\n",
            "Epoch:  386 loss:  0.22817164659500122 test loss:  0.34868091344833374\n",
            "Epoch:  387 loss:  0.2429237961769104 test loss:  0.34785449504852295\n",
            "Epoch:  388 loss:  0.19091802835464478 test loss:  0.347210168838501\n",
            "Epoch:  389 loss:  0.22730040550231934 test loss:  0.3464752435684204\n",
            "Epoch:  390 loss:  0.16323578357696533 test loss:  0.3467012047767639\n",
            "Epoch:  391 loss:  0.2253395915031433 test loss:  0.3467200994491577\n",
            "Epoch:  392 loss:  0.23946738243103027 test loss:  0.3451142907142639\n",
            "Epoch:  393 loss:  0.3174227476119995 test loss:  0.34393948316574097\n",
            "Epoch:  394 loss:  0.2843238115310669 test loss:  0.34441548585891724\n",
            "Epoch:  395 loss:  0.1697477102279663 test loss:  0.34522223472595215\n",
            "Epoch:  396 loss:  0.3751511573791504 test loss:  0.34427136182785034\n",
            "Epoch:  397 loss:  0.3881939649581909 test loss:  0.34206485748291016\n",
            "Epoch:  398 loss:  0.2118910551071167 test loss:  0.34190666675567627\n",
            "Epoch:  399 loss:  0.2460947036743164 test loss:  0.3416261672973633\n",
            "sigma tensor([[1.4368e+00, 1.4718e+00, 1.5003e+00,  ..., 1.5251e+00, 1.5243e+00,\n",
            "         1.6294e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [9.8274e-01, 1.1240e+00, 1.2038e+00,  ..., 1.2513e+00, 1.2511e+00,\n",
            "         1.1554e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.1155e+00, 1.7364e+00, 1.8707e+00,  ..., 1.9161e+00, 1.9160e+00,\n",
            "         2.0205e+00],\n",
            "        [1.4287e+01, 5.3572e+00, 3.6760e+01,  ..., 1.3224e+01, 3.6760e+01,\n",
            "         1.3930e+01]])\n",
            "fixed effects tensor([[9.7458e-03, 7.6896e-03, 7.7322e-03,  ..., 1.9934e-02, 2.0024e-02,\n",
            "         3.1247e-02],\n",
            "        [6.3305e+00, 3.9025e+00, 3.9327e+00,  ..., 4.6007e+00, 4.6313e+00,\n",
            "         1.4112e+01],\n",
            "        [1.4230e-02, 1.2127e-02, 1.2191e-02,  ..., 1.4044e-02, 1.4109e-02,\n",
            "         2.4989e-02],\n",
            "        ...,\n",
            "        [3.5182e-02, 2.1680e-02, 2.1784e-02,  ..., 2.4111e-02, 2.4220e-02,\n",
            "         8.0220e-02],\n",
            "        [1.7885e-02, 1.6132e-02, 1.6211e-02,  ..., 1.8342e-02, 1.8421e-02,\n",
            "         2.9642e-02],\n",
            "        [8.5504e-02, 3.2341e-02, 3.2600e-02,  ..., 3.9488e-02, 3.9763e-02,\n",
            "         2.3088e-01]])\n",
            "Epoch:  400 loss:  0.24972915649414062 test loss:  0.34116625785827637\n",
            "Epoch:  401 loss:  0.21109968423843384 test loss:  0.34218424558639526\n",
            "Epoch:  402 loss:  0.24142903089523315 test loss:  0.34194111824035645\n",
            "Epoch:  403 loss:  0.23345357179641724 test loss:  0.3417530059814453\n",
            "Epoch:  404 loss:  0.18709367513656616 test loss:  0.341205894947052\n",
            "Epoch:  405 loss:  0.2154756784439087 test loss:  0.33980321884155273\n",
            "Epoch:  406 loss:  0.27813297510147095 test loss:  0.339210569858551\n",
            "Epoch:  407 loss:  0.23121142387390137 test loss:  0.33813631534576416\n",
            "Epoch:  408 loss:  0.1733180284500122 test loss:  0.3391447067260742\n",
            "Epoch:  409 loss:  0.24568849802017212 test loss:  0.33813631534576416\n",
            "Epoch:  410 loss:  0.1569039225578308 test loss:  0.3394310474395752\n",
            "Epoch:  411 loss:  0.1577897071838379 test loss:  0.34086763858795166\n",
            "Epoch:  412 loss:  0.19193124771118164 test loss:  0.339313805103302\n",
            "Epoch:  413 loss:  0.2562985420227051 test loss:  0.3369460701942444\n",
            "Epoch:  414 loss:  0.30616527795791626 test loss:  0.3360048532485962\n",
            "Epoch:  415 loss:  0.17669332027435303 test loss:  0.3366663455963135\n",
            "Epoch:  416 loss:  0.33644241094589233 test loss:  0.3345138430595398\n",
            "Epoch:  417 loss:  0.22408044338226318 test loss:  0.33420872688293457\n",
            "Epoch:  418 loss:  0.23401272296905518 test loss:  0.3352189064025879\n",
            "Epoch:  419 loss:  0.1524444818496704 test loss:  0.33676838874816895\n",
            "Epoch:  420 loss:  0.22944658994674683 test loss:  0.33633458614349365\n",
            "Epoch:  421 loss:  0.17454642057418823 test loss:  0.3365967273712158\n",
            "Epoch:  422 loss:  0.22283709049224854 test loss:  0.3354480266571045\n",
            "Epoch:  423 loss:  0.22786349058151245 test loss:  0.33516883850097656\n",
            "Epoch:  424 loss:  0.19273912906646729 test loss:  0.3349360227584839\n",
            "Epoch:  425 loss:  0.2102952003479004 test loss:  0.3335375189781189\n",
            "Epoch:  426 loss:  0.358586847782135 test loss:  0.33287692070007324\n",
            "Epoch:  427 loss:  0.15426087379455566 test loss:  0.33449888229370117\n",
            "Epoch:  428 loss:  0.25932741165161133 test loss:  0.33136481046676636\n",
            "Epoch:  429 loss:  0.25585657358169556 test loss:  0.33118653297424316\n",
            "Epoch:  430 loss:  0.2990533709526062 test loss:  0.3302069306373596\n",
            "Epoch:  431 loss:  0.1898411512374878 test loss:  0.3305355906486511\n",
            "Epoch:  432 loss:  0.16287720203399658 test loss:  0.33124053478240967\n",
            "Epoch:  433 loss:  0.20061886310577393 test loss:  0.3326212763786316\n",
            "Epoch:  434 loss:  0.29368531703948975 test loss:  0.33133041858673096\n",
            "Epoch:  435 loss:  0.2918884754180908 test loss:  0.3303777575492859\n",
            "Epoch:  436 loss:  0.17723137140274048 test loss:  0.33161991834640503\n",
            "Epoch:  437 loss:  0.2916058301925659 test loss:  0.33013564348220825\n",
            "Epoch:  438 loss:  0.2229798436164856 test loss:  0.3296120762825012\n",
            "Epoch:  439 loss:  0.3363919258117676 test loss:  0.32668477296829224\n",
            "Epoch:  440 loss:  0.1526685357093811 test loss:  0.32834863662719727\n",
            "Epoch:  441 loss:  0.22684919834136963 test loss:  0.32894599437713623\n",
            "Epoch:  442 loss:  0.20387470722198486 test loss:  0.32842588424682617\n",
            "Epoch:  443 loss:  0.20604515075683594 test loss:  0.3268370032310486\n",
            "Epoch:  444 loss:  0.22667014598846436 test loss:  0.3255912661552429\n",
            "Epoch:  445 loss:  0.20979416370391846 test loss:  0.32654786109924316\n",
            "Epoch:  446 loss:  0.28721821308135986 test loss:  0.32537853717803955\n",
            "Epoch:  447 loss:  0.22470688819885254 test loss:  0.325982928276062\n",
            "Epoch:  448 loss:  0.23819202184677124 test loss:  0.3242846131324768\n",
            "Epoch:  449 loss:  0.17791283130645752 test loss:  0.3258933424949646\n",
            "Epoch:  450 loss:  0.22294116020202637 test loss:  0.32457101345062256\n",
            "Epoch:  451 loss:  0.26580458879470825 test loss:  0.32354068756103516\n",
            "Epoch:  452 loss:  0.17999142408370972 test loss:  0.32244324684143066\n",
            "Epoch:  453 loss:  0.2654775381088257 test loss:  0.32134610414505005\n",
            "Epoch:  454 loss:  0.21320343017578125 test loss:  0.3206403851509094\n",
            "Epoch:  455 loss:  0.22181850671768188 test loss:  0.32014769315719604\n",
            "Epoch:  456 loss:  0.3765218257904053 test loss:  0.3197166323661804\n",
            "Epoch:  457 loss:  0.2633016109466553 test loss:  0.3189621567726135\n",
            "Epoch:  458 loss:  0.2119356393814087 test loss:  0.31848448514938354\n",
            "Epoch:  459 loss:  0.23251181840896606 test loss:  0.3178519010543823\n",
            "Epoch:  460 loss:  0.3636873960494995 test loss:  0.3163703680038452\n",
            "Epoch:  461 loss:  0.32308489084243774 test loss:  0.31484222412109375\n",
            "Epoch:  462 loss:  0.19459640979766846 test loss:  0.3152540922164917\n",
            "Epoch:  463 loss:  0.22678101062774658 test loss:  0.31550532579421997\n",
            "Epoch:  464 loss:  0.1664852499961853 test loss:  0.31609928607940674\n",
            "Epoch:  465 loss:  0.27958524227142334 test loss:  0.3154836893081665\n",
            "Epoch:  466 loss:  0.3182474970817566 test loss:  0.31436800956726074\n",
            "Epoch:  467 loss:  0.24475103616714478 test loss:  0.31438207626342773\n",
            "Epoch:  468 loss:  0.2797771096229553 test loss:  0.3140718340873718\n",
            "Epoch:  469 loss:  0.3831979036331177 test loss:  0.3121463656425476\n",
            "Epoch:  470 loss:  0.17595279216766357 test loss:  0.31395357847213745\n",
            "Epoch:  471 loss:  0.20906919240951538 test loss:  0.3133545517921448\n",
            "Epoch:  472 loss:  0.19688713550567627 test loss:  0.31342363357543945\n",
            "Epoch:  473 loss:  0.19828230142593384 test loss:  0.3131486177444458\n",
            "Epoch:  474 loss:  0.2294861078262329 test loss:  0.3120797276496887\n",
            "Epoch:  475 loss:  0.19415682554244995 test loss:  0.3129989504814148\n",
            "Epoch:  476 loss:  0.15931189060211182 test loss:  0.31362491846084595\n",
            "Epoch:  477 loss:  0.21288472414016724 test loss:  0.31342828273773193\n",
            "Epoch:  478 loss:  0.22259128093719482 test loss:  0.3126526474952698\n",
            "Epoch:  479 loss:  0.20246481895446777 test loss:  0.3136950731277466\n",
            "Epoch:  480 loss:  0.2166488766670227 test loss:  0.3119502663612366\n",
            "Epoch:  481 loss:  0.1618899703025818 test loss:  0.3120167851448059\n",
            "Epoch:  482 loss:  0.1609235405921936 test loss:  0.31144630908966064\n",
            "Epoch:  483 loss:  0.26094430685043335 test loss:  0.3104310631752014\n",
            "Epoch:  484 loss:  0.2047332525253296 test loss:  0.3095560669898987\n",
            "Epoch:  485 loss:  0.1869942545890808 test loss:  0.3094169497489929\n",
            "Epoch:  486 loss:  0.23416197299957275 test loss:  0.3085355758666992\n",
            "Epoch:  487 loss:  0.14541471004486084 test loss:  0.31002533435821533\n",
            "Epoch:  488 loss:  0.19273215532302856 test loss:  0.30963587760925293\n",
            "Epoch:  489 loss:  0.25992900133132935 test loss:  0.30799371004104614\n",
            "Epoch:  490 loss:  0.2437623143196106 test loss:  0.3067970871925354\n",
            "Epoch:  491 loss:  0.19998681545257568 test loss:  0.3078122138977051\n",
            "Epoch:  492 loss:  0.446647584438324 test loss:  0.3066359758377075\n",
            "Epoch:  493 loss:  0.1436520218849182 test loss:  0.30810266733169556\n",
            "Epoch:  494 loss:  0.19862300157546997 test loss:  0.3090694546699524\n",
            "Epoch:  495 loss:  0.2432234287261963 test loss:  0.30707019567489624\n",
            "Epoch:  496 loss:  0.3746914863586426 test loss:  0.3042965531349182\n",
            "Epoch:  497 loss:  0.21635138988494873 test loss:  0.30451714992523193\n",
            "Epoch:  498 loss:  0.18416595458984375 test loss:  0.3045075535774231\n",
            "Epoch:  499 loss:  0.18826276063919067 test loss:  0.30529922246932983\n",
            "sigma tensor([[1.5086e+00, 1.5549e+00, 1.5912e+00,  ..., 1.6230e+00, 1.6222e+00,\n",
            "         1.7287e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [1.0259e+00, 1.1801e+00, 1.2637e+00,  ..., 1.3147e+00, 1.3144e+00,\n",
            "         1.2192e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.1851e+00, 1.8318e+00, 1.9672e+00,  ..., 2.0222e+00, 2.0223e+00,\n",
            "         2.1274e+00],\n",
            "        [1.4287e+01, 5.3581e+00, 3.6760e+01,  ..., 1.3224e+01, 3.6760e+01,\n",
            "         1.3931e+01]])\n",
            "fixed effects tensor([[9.3369e-03, 6.8009e-03, 6.8498e-03,  ..., 1.8385e-02, 1.8486e-02,\n",
            "         3.1418e-02],\n",
            "        [5.8467e+00, 3.1555e+00, 3.1982e+00,  ..., 4.2561e+00, 4.2993e+00,\n",
            "         1.5025e+01],\n",
            "        [1.2480e-02, 9.7943e-03, 9.8662e-03,  ..., 1.2044e-02, 1.2117e-02,\n",
            "         2.4813e-02],\n",
            "        ...,\n",
            "        [3.2193e-02, 1.7168e-02, 1.7344e-02,  ..., 2.1932e-02, 2.2113e-02,\n",
            "         8.5315e-02],\n",
            "        [1.7078e-02, 1.4812e-02, 1.4904e-02,  ..., 1.7511e-02, 1.7604e-02,\n",
            "         3.0846e-02],\n",
            "        [7.5978e-02, 1.7756e-02, 1.8253e-02,  ..., 3.2729e-02, 3.3245e-02,\n",
            "         2.4843e-01]])\n",
            "Epoch:  500 loss:  0.1555982232093811 test loss:  0.3049464225769043\n",
            "Epoch:  501 loss:  0.15466523170471191 test loss:  0.3056780695915222\n",
            "Epoch:  502 loss:  0.3508470058441162 test loss:  0.3032665252685547\n",
            "Epoch:  503 loss:  0.32281774282455444 test loss:  0.30276191234588623\n",
            "Epoch:  504 loss:  0.2347637414932251 test loss:  0.3025628328323364\n",
            "Epoch:  505 loss:  0.2132057547569275 test loss:  0.30264395475387573\n",
            "Epoch:  506 loss:  0.20518428087234497 test loss:  0.3025813698768616\n",
            "Epoch:  507 loss:  0.2043604850769043 test loss:  0.30250173807144165\n",
            "Epoch:  508 loss:  0.2995176315307617 test loss:  0.30059677362442017\n",
            "Epoch:  509 loss:  0.18899428844451904 test loss:  0.29991358518600464\n",
            "Epoch:  510 loss:  0.16157746315002441 test loss:  0.30039113759994507\n",
            "Epoch:  511 loss:  0.22162514925003052 test loss:  0.29957109689712524\n",
            "Epoch:  512 loss:  0.18129241466522217 test loss:  0.3000059723854065\n",
            "Epoch:  513 loss:  0.1687726378440857 test loss:  0.30031412839889526\n",
            "Epoch:  514 loss:  0.23099541664123535 test loss:  0.30002129077911377\n",
            "Epoch:  515 loss:  0.3629491329193115 test loss:  0.2983158230781555\n",
            "Epoch:  516 loss:  0.20438915491104126 test loss:  0.29760420322418213\n",
            "Epoch:  517 loss:  0.1885243058204651 test loss:  0.2975804805755615\n",
            "Epoch:  518 loss:  0.2639482617378235 test loss:  0.2970693111419678\n",
            "Epoch:  519 loss:  0.3319648504257202 test loss:  0.2962501049041748\n",
            "Epoch:  520 loss:  0.1960027813911438 test loss:  0.2958180904388428\n",
            "Epoch:  521 loss:  0.18130522966384888 test loss:  0.296095073223114\n",
            "Epoch:  522 loss:  0.2061861753463745 test loss:  0.2952669858932495\n",
            "Epoch:  523 loss:  0.22751057147979736 test loss:  0.2952817678451538\n",
            "Epoch:  524 loss:  0.1804661750793457 test loss:  0.2961377501487732\n",
            "Epoch:  525 loss:  0.18651509284973145 test loss:  0.2950921058654785\n",
            "Epoch:  526 loss:  0.23606157302856445 test loss:  0.2968481183052063\n",
            "Epoch:  527 loss:  0.187114417552948 test loss:  0.29632800817489624\n",
            "Epoch:  528 loss:  0.15090912580490112 test loss:  0.2967381477355957\n",
            "Epoch:  529 loss:  0.18196171522140503 test loss:  0.29581862688064575\n",
            "Epoch:  530 loss:  0.16610801219940186 test loss:  0.2948541045188904\n",
            "Epoch:  531 loss:  0.17941433191299438 test loss:  0.2951713800430298\n",
            "Epoch:  532 loss:  0.24818432331085205 test loss:  0.29438918828964233\n",
            "Epoch:  533 loss:  0.1703168749809265 test loss:  0.29525989294052124\n",
            "Epoch:  534 loss:  0.2399461269378662 test loss:  0.2941337823867798\n",
            "Epoch:  535 loss:  0.195021390914917 test loss:  0.2942086458206177\n",
            "Epoch:  536 loss:  0.11757773160934448 test loss:  0.2948007583618164\n",
            "Epoch:  537 loss:  0.20836299657821655 test loss:  0.2944364547729492\n",
            "Epoch:  538 loss:  0.2216120958328247 test loss:  0.29344499111175537\n",
            "Epoch:  539 loss:  0.2900458574295044 test loss:  0.29203277826309204\n",
            "Epoch:  540 loss:  0.2084118127822876 test loss:  0.2917781472206116\n",
            "Epoch:  541 loss:  0.23222047090530396 test loss:  0.2934795618057251\n",
            "Epoch:  542 loss:  0.2922816872596741 test loss:  0.2918285131454468\n",
            "Epoch:  543 loss:  0.19855695962905884 test loss:  0.2915685772895813\n",
            "Epoch:  544 loss:  0.20156747102737427 test loss:  0.2912227511405945\n",
            "Epoch:  545 loss:  0.28937244415283203 test loss:  0.28950804471969604\n",
            "Epoch:  546 loss:  0.20073586702346802 test loss:  0.2895529270172119\n",
            "Epoch:  547 loss:  0.1476726531982422 test loss:  0.29051101207733154\n",
            "Epoch:  548 loss:  0.28646320104599 test loss:  0.28919416666030884\n",
            "Epoch:  549 loss:  0.19926565885543823 test loss:  0.28846049308776855\n",
            "Epoch:  550 loss:  0.308702290058136 test loss:  0.2881048917770386\n",
            "Epoch:  551 loss:  0.2214822769165039 test loss:  0.2879897952079773\n",
            "Epoch:  552 loss:  0.20429116487503052 test loss:  0.28805726766586304\n",
            "Epoch:  553 loss:  0.24878191947937012 test loss:  0.2868483066558838\n",
            "Epoch:  554 loss:  0.14961111545562744 test loss:  0.2872975468635559\n",
            "Epoch:  555 loss:  0.1545754075050354 test loss:  0.28848814964294434\n",
            "Epoch:  556 loss:  0.1884945034980774 test loss:  0.287818968296051\n",
            "Epoch:  557 loss:  0.29692167043685913 test loss:  0.2855512499809265\n",
            "Epoch:  558 loss:  0.31733351945877075 test loss:  0.2854308485984802\n",
            "Epoch:  559 loss:  0.23468464612960815 test loss:  0.28576987981796265\n",
            "Epoch:  560 loss:  0.28096526861190796 test loss:  0.28461742401123047\n",
            "Epoch:  561 loss:  0.2831844091415405 test loss:  0.2831886410713196\n",
            "Epoch:  562 loss:  0.19590437412261963 test loss:  0.2830570340156555\n",
            "Epoch:  563 loss:  0.13063699007034302 test loss:  0.2844034433364868\n",
            "Epoch:  564 loss:  0.24992769956588745 test loss:  0.28378498554229736\n",
            "Epoch:  565 loss:  0.16848695278167725 test loss:  0.28382551670074463\n",
            "Epoch:  566 loss:  0.23681193590164185 test loss:  0.2827545404434204\n",
            "Epoch:  567 loss:  0.2460063099861145 test loss:  0.2826734781265259\n",
            "Epoch:  568 loss:  0.19505822658538818 test loss:  0.2823517918586731\n",
            "Epoch:  569 loss:  0.24421197175979614 test loss:  0.28131192922592163\n",
            "Epoch:  570 loss:  0.1747491955757141 test loss:  0.2821885347366333\n",
            "Epoch:  571 loss:  0.23213118314743042 test loss:  0.2817689776420593\n",
            "Epoch:  572 loss:  0.11685293912887573 test loss:  0.2826727032661438\n",
            "Epoch:  573 loss:  0.17754346132278442 test loss:  0.28239375352859497\n",
            "Epoch:  574 loss:  0.15455889701843262 test loss:  0.28372883796691895\n",
            "Epoch:  575 loss:  0.17787182331085205 test loss:  0.28220999240875244\n",
            "Epoch:  576 loss:  0.17632371187210083 test loss:  0.281028151512146\n",
            "Epoch:  577 loss:  0.19479042291641235 test loss:  0.28079408407211304\n",
            "Epoch:  578 loss:  0.2002345323562622 test loss:  0.2804551124572754\n",
            "Epoch:  579 loss:  0.23697853088378906 test loss:  0.27913618087768555\n",
            "Epoch:  580 loss:  0.24331200122833252 test loss:  0.2790868282318115\n",
            "Epoch:  581 loss:  0.2764391303062439 test loss:  0.2777865529060364\n",
            "Epoch:  582 loss:  0.14817267656326294 test loss:  0.2783445715904236\n",
            "Epoch:  583 loss:  0.16340899467468262 test loss:  0.2792994976043701\n",
            "Epoch:  584 loss:  0.27528923749923706 test loss:  0.27780991792678833\n",
            "Epoch:  585 loss:  0.23020964860916138 test loss:  0.27711427211761475\n",
            "Epoch:  586 loss:  0.24114853143692017 test loss:  0.27719056606292725\n",
            "Epoch:  587 loss:  0.4094235897064209 test loss:  0.2766387462615967\n",
            "Epoch:  588 loss:  0.14102858304977417 test loss:  0.27758896350860596\n",
            "Epoch:  589 loss:  0.2125299572944641 test loss:  0.2774258255958557\n",
            "Epoch:  590 loss:  0.19236284494400024 test loss:  0.27697277069091797\n",
            "Epoch:  591 loss:  0.14072781801223755 test loss:  0.27740752696990967\n",
            "Epoch:  592 loss:  0.18817561864852905 test loss:  0.27742117643356323\n",
            "Epoch:  593 loss:  0.12603068351745605 test loss:  0.278469443321228\n",
            "Epoch:  594 loss:  0.2718295454978943 test loss:  0.2769177556037903\n",
            "Epoch:  595 loss:  0.18708735704421997 test loss:  0.27688539028167725\n",
            "Epoch:  596 loss:  0.16850805282592773 test loss:  0.2763087749481201\n",
            "Epoch:  597 loss:  0.191001296043396 test loss:  0.2753649353981018\n",
            "Epoch:  598 loss:  0.17037272453308105 test loss:  0.2765403389930725\n",
            "Epoch:  599 loss:  0.15399271249771118 test loss:  0.27652639150619507\n",
            "sigma tensor([[1.5817e+00, 1.6399e+00, 1.6844e+00,  ..., 1.7236e+00, 1.7228e+00,\n",
            "         1.8314e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [1.0677e+00, 1.2345e+00, 1.3219e+00,  ..., 1.3760e+00, 1.3758e+00,\n",
            "         1.2811e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.2493e+00, 1.9171e+00, 2.0528e+00,  ..., 2.1152e+00, 2.1153e+00,\n",
            "         2.2204e+00],\n",
            "        [1.4286e+01, 5.3591e+00, 3.6760e+01,  ..., 1.3225e+01, 3.6760e+01,\n",
            "         1.3932e+01]])\n",
            "fixed effects tensor([[9.3515e-03, 6.2971e-03, 6.3518e-03,  ..., 1.7640e-02, 1.7750e-02,\n",
            "         3.2406e-02],\n",
            "        [5.4885e+00, 2.4785e+00, 2.5288e+00,  ..., 3.8439e+00, 3.8949e+00,\n",
            "         1.5736e+01],\n",
            "        [1.2732e-02, 9.5021e-03, 9.5870e-03,  ..., 1.2220e-02, 1.2306e-02,\n",
            "         2.7053e-02],\n",
            "        ...,\n",
            "        [2.9960e-02, 1.3092e-02, 1.3311e-02,  ..., 1.9389e-02, 1.9615e-02,\n",
            "         8.9260e-02],\n",
            "        [1.7005e-02, 1.4185e-02, 1.4289e-02,  ..., 1.7325e-02, 1.7430e-02,\n",
            "         3.2700e-02],\n",
            "        [6.9019e-02, 4.6549e-03, 5.2971e-03,  ..., 2.4760e-02, 2.5423e-02,\n",
            "         2.6214e-01]])\n",
            "Epoch:  600 loss:  0.12933093309402466 test loss:  0.27755850553512573\n",
            "Epoch:  601 loss:  0.1860383152961731 test loss:  0.27698981761932373\n",
            "Epoch:  602 loss:  0.21594256162643433 test loss:  0.2754693031311035\n",
            "Epoch:  603 loss:  0.16615575551986694 test loss:  0.2759888172149658\n",
            "Epoch:  604 loss:  0.3030407428741455 test loss:  0.27471333742141724\n",
            "Epoch:  605 loss:  0.11244088411331177 test loss:  0.2753806710243225\n",
            "Epoch:  606 loss:  0.18950140476226807 test loss:  0.27508431673049927\n",
            "Epoch:  607 loss:  0.12343704700469971 test loss:  0.27592355012893677\n",
            "Epoch:  608 loss:  0.19509094953536987 test loss:  0.275251567363739\n",
            "Epoch:  609 loss:  0.23007631301879883 test loss:  0.2741716504096985\n",
            "Epoch:  610 loss:  0.18037313222885132 test loss:  0.2732000946998596\n",
            "Epoch:  611 loss:  0.13829493522644043 test loss:  0.2734344005584717\n",
            "Epoch:  612 loss:  0.14431047439575195 test loss:  0.2734367251396179\n",
            "Epoch:  613 loss:  0.24113118648529053 test loss:  0.2726786732673645\n",
            "Epoch:  614 loss:  0.2677605152130127 test loss:  0.2711018919944763\n",
            "Epoch:  615 loss:  0.15769731998443604 test loss:  0.27199190855026245\n",
            "Epoch:  616 loss:  0.23468017578125 test loss:  0.2717263698577881\n",
            "Epoch:  617 loss:  0.15865403413772583 test loss:  0.2722470760345459\n",
            "Epoch:  618 loss:  0.14704692363739014 test loss:  0.27225351333618164\n",
            "Epoch:  619 loss:  0.16408991813659668 test loss:  0.2720882296562195\n",
            "Epoch:  620 loss:  0.2010093331336975 test loss:  0.27117109298706055\n",
            "Epoch:  621 loss:  0.27147525548934937 test loss:  0.2692950367927551\n",
            "Epoch:  622 loss:  0.18287062644958496 test loss:  0.268735408782959\n",
            "Epoch:  623 loss:  0.14008718729019165 test loss:  0.26920628547668457\n",
            "Epoch:  624 loss:  0.13506561517715454 test loss:  0.2700604796409607\n",
            "Epoch:  625 loss:  0.17719709873199463 test loss:  0.27071356773376465\n",
            "Epoch:  626 loss:  0.17015588283538818 test loss:  0.26953768730163574\n",
            "Epoch:  627 loss:  0.19767940044403076 test loss:  0.26898616552352905\n",
            "Epoch:  628 loss:  0.2970541715621948 test loss:  0.2686617374420166\n",
            "Epoch:  629 loss:  0.28941935300827026 test loss:  0.2681705355644226\n",
            "Epoch:  630 loss:  0.18732303380966187 test loss:  0.268795907497406\n",
            "Epoch:  631 loss:  0.17578846216201782 test loss:  0.2682350277900696\n",
            "Epoch:  632 loss:  0.16189652681350708 test loss:  0.26835858821868896\n",
            "Epoch:  633 loss:  0.14930659532546997 test loss:  0.2683945298194885\n",
            "Epoch:  634 loss:  0.1687910556793213 test loss:  0.26728951930999756\n",
            "Epoch:  635 loss:  0.19791662693023682 test loss:  0.26638340950012207\n",
            "Epoch:  636 loss:  0.2891976237297058 test loss:  0.26600515842437744\n",
            "Epoch:  637 loss:  0.22366875410079956 test loss:  0.265605092048645\n",
            "Epoch:  638 loss:  0.16283923387527466 test loss:  0.26538753509521484\n",
            "Epoch:  639 loss:  0.16109180450439453 test loss:  0.26560264825820923\n",
            "Epoch:  640 loss:  0.1371215581893921 test loss:  0.2659339904785156\n",
            "Epoch:  641 loss:  0.23578041791915894 test loss:  0.26539963483810425\n",
            "Epoch:  642 loss:  0.19394874572753906 test loss:  0.2649857997894287\n",
            "Epoch:  643 loss:  0.16092950105667114 test loss:  0.26570457220077515\n",
            "Epoch:  644 loss:  0.1765255331993103 test loss:  0.2656501531600952\n",
            "Epoch:  645 loss:  0.186262309551239 test loss:  0.26618748903274536\n",
            "Epoch:  646 loss:  0.1828210949897766 test loss:  0.26536810398101807\n",
            "Epoch:  647 loss:  0.1671065092086792 test loss:  0.26427292823791504\n",
            "Epoch:  648 loss:  0.3305830955505371 test loss:  0.26232481002807617\n",
            "Epoch:  649 loss:  0.2224002480506897 test loss:  0.26152777671813965\n",
            "Epoch:  650 loss:  0.14377325773239136 test loss:  0.26201140880584717\n",
            "Epoch:  651 loss:  0.31177574396133423 test loss:  0.26096588373184204\n",
            "Epoch:  652 loss:  0.12833458185195923 test loss:  0.26175618171691895\n",
            "Epoch:  653 loss:  0.32672685384750366 test loss:  0.2602604627609253\n",
            "Epoch:  654 loss:  0.26174455881118774 test loss:  0.2598680257797241\n",
            "Epoch:  655 loss:  0.10940784215927124 test loss:  0.2609105706214905\n",
            "Epoch:  656 loss:  0.2042657732963562 test loss:  0.2594742774963379\n",
            "Epoch:  657 loss:  0.25669342279434204 test loss:  0.25865626335144043\n",
            "Epoch:  658 loss:  0.18673968315124512 test loss:  0.25906825065612793\n",
            "Epoch:  659 loss:  0.1353449821472168 test loss:  0.2596169710159302\n",
            "Epoch:  660 loss:  0.2546001672744751 test loss:  0.25887441635131836\n",
            "Epoch:  661 loss:  0.31362318992614746 test loss:  0.2579140067100525\n",
            "Epoch:  662 loss:  0.1831243634223938 test loss:  0.2587627172470093\n",
            "Epoch:  663 loss:  0.1302078366279602 test loss:  0.2596029043197632\n",
            "Epoch:  664 loss:  0.2596249580383301 test loss:  0.2585407495498657\n",
            "Epoch:  665 loss:  0.16745638847351074 test loss:  0.259590744972229\n",
            "Epoch:  666 loss:  0.16328543424606323 test loss:  0.25848913192749023\n",
            "Epoch:  667 loss:  0.20070046186447144 test loss:  0.2567681670188904\n",
            "Epoch:  668 loss:  0.28454500436782837 test loss:  0.2562742829322815\n",
            "Epoch:  669 loss:  0.1793634295463562 test loss:  0.2557751536369324\n",
            "Epoch:  670 loss:  0.19840234518051147 test loss:  0.25448882579803467\n",
            "Epoch:  671 loss:  0.12696218490600586 test loss:  0.2552754878997803\n",
            "Epoch:  672 loss:  0.14468425512313843 test loss:  0.2556911110877991\n",
            "Epoch:  673 loss:  0.21910279989242554 test loss:  0.2553405165672302\n",
            "Epoch:  674 loss:  0.14589351415634155 test loss:  0.25491100549697876\n",
            "Epoch:  675 loss:  0.1790366768836975 test loss:  0.2546207904815674\n",
            "Epoch:  676 loss:  0.2096197009086609 test loss:  0.2545340657234192\n",
            "Epoch:  677 loss:  0.17697161436080933 test loss:  0.2543494701385498\n",
            "Epoch:  678 loss:  0.17034393548965454 test loss:  0.2540658116340637\n",
            "Epoch:  679 loss:  0.21738290786743164 test loss:  0.2538525462150574\n",
            "Epoch:  680 loss:  0.15702301263809204 test loss:  0.2541831135749817\n",
            "Epoch:  681 loss:  0.19619238376617432 test loss:  0.2526887059211731\n",
            "Epoch:  682 loss:  0.18213123083114624 test loss:  0.2527080178260803\n",
            "Epoch:  683 loss:  0.12220799922943115 test loss:  0.2539917826652527\n",
            "Epoch:  684 loss:  0.14419090747833252 test loss:  0.2533801794052124\n",
            "Epoch:  685 loss:  0.1684187650680542 test loss:  0.25313764810562134\n",
            "Epoch:  686 loss:  0.18122512102127075 test loss:  0.2538801431655884\n",
            "Epoch:  687 loss:  0.21577537059783936 test loss:  0.25260627269744873\n",
            "Epoch:  688 loss:  0.2278340458869934 test loss:  0.252332866191864\n",
            "Epoch:  689 loss:  0.14877158403396606 test loss:  0.2530413269996643\n",
            "Epoch:  690 loss:  0.2204250693321228 test loss:  0.2519696354866028\n",
            "Epoch:  691 loss:  0.30380791425704956 test loss:  0.25086092948913574\n",
            "Epoch:  692 loss:  0.19391298294067383 test loss:  0.25009793043136597\n",
            "Epoch:  693 loss:  0.2210078239440918 test loss:  0.250324547290802\n",
            "Epoch:  694 loss:  0.3738952875137329 test loss:  0.2500714063644409\n",
            "Epoch:  695 loss:  0.25197291374206543 test loss:  0.2496250867843628\n",
            "Epoch:  696 loss:  0.1740667223930359 test loss:  0.24940848350524902\n",
            "Epoch:  697 loss:  0.14777147769927979 test loss:  0.25035566091537476\n",
            "Epoch:  698 loss:  0.13680177927017212 test loss:  0.2507026791572571\n",
            "Epoch:  699 loss:  0.37141311168670654 test loss:  0.2500707507133484\n",
            "sigma tensor([[1.6458e+00, 1.7152e+00, 1.7672e+00,  ..., 1.8116e+00, 1.8108e+00,\n",
            "         1.9205e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [1.1053e+00, 1.2837e+00, 1.3744e+00,  ..., 1.4310e+00, 1.4308e+00,\n",
            "         1.3368e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.3070e+00, 1.9938e+00, 2.1298e+00,  ..., 2.1981e+00, 2.1983e+00,\n",
            "         2.3029e+00],\n",
            "        [1.4286e+01, 5.3609e+00, 3.6760e+01,  ..., 1.3225e+01, 3.6760e+01,\n",
            "         1.3934e+01]])\n",
            "fixed effects tensor([[1.0085e-02, 6.6301e-03, 6.6929e-03,  ..., 1.8990e-02, 1.9115e-02,\n",
            "         3.5468e-02],\n",
            "        [6.0978e+00, 2.8380e+00, 2.8973e+00,  ..., 4.4972e+00, 4.5572e+00,\n",
            "         1.7401e+01],\n",
            "        [1.4334e-02, 1.0620e-02, 1.0722e-02,  ..., 1.3907e-02, 1.4011e-02,\n",
            "         3.0852e-02],\n",
            "        ...,\n",
            "        [3.3360e-02, 1.5048e-02, 1.5318e-02,  ..., 2.3023e-02, 2.3299e-02,\n",
            "         9.8728e-02],\n",
            "        [1.8571e-02, 1.5282e-02, 1.5404e-02,  ..., 1.8988e-02, 1.9111e-02,\n",
            "         3.6440e-02],\n",
            "        [8.0499e-02, 1.1299e-02, 1.2111e-02,  ..., 3.7010e-02, 3.7844e-02,\n",
            "         2.9389e-01]])\n",
            "Epoch:  700 loss:  0.30358970165252686 test loss:  0.2490156888961792\n",
            "Epoch:  701 loss:  0.1567668318748474 test loss:  0.24851351976394653\n",
            "Epoch:  702 loss:  0.18718940019607544 test loss:  0.24830877780914307\n",
            "Epoch:  703 loss:  0.2049430012702942 test loss:  0.2482624053955078\n",
            "Epoch:  704 loss:  0.20699316263198853 test loss:  0.2486439347267151\n",
            "Epoch:  705 loss:  0.3129316568374634 test loss:  0.24713408946990967\n",
            "Epoch:  706 loss:  0.13620388507843018 test loss:  0.24763727188110352\n",
            "Epoch:  707 loss:  0.17106950283050537 test loss:  0.24736154079437256\n",
            "Epoch:  708 loss:  0.19586646556854248 test loss:  0.24682974815368652\n",
            "Epoch:  709 loss:  0.15529179573059082 test loss:  0.2480211853981018\n",
            "Epoch:  710 loss:  0.13726794719696045 test loss:  0.2478817105293274\n",
            "Epoch:  711 loss:  0.29962193965911865 test loss:  0.24674546718597412\n",
            "Epoch:  712 loss:  0.11453026533126831 test loss:  0.24784398078918457\n",
            "Epoch:  713 loss:  0.20444393157958984 test loss:  0.24708235263824463\n",
            "Epoch:  714 loss:  0.13204485177993774 test loss:  0.24733787775039673\n",
            "Epoch:  715 loss:  0.15709048509597778 test loss:  0.24727720022201538\n",
            "Epoch:  716 loss:  0.2081890106201172 test loss:  0.24683469533920288\n",
            "Epoch:  717 loss:  0.12504559755325317 test loss:  0.24758166074752808\n",
            "Epoch:  718 loss:  0.14170986413955688 test loss:  0.2475382685661316\n",
            "Epoch:  719 loss:  0.16716432571411133 test loss:  0.2473975419998169\n",
            "Epoch:  720 loss:  0.1915714144706726 test loss:  0.24698108434677124\n",
            "Epoch:  721 loss:  0.27444988489151 test loss:  0.24661648273468018\n",
            "Epoch:  722 loss:  0.1802923083305359 test loss:  0.2478587031364441\n",
            "Epoch:  723 loss:  0.1118929386138916 test loss:  0.24856889247894287\n",
            "Epoch:  724 loss:  0.11680591106414795 test loss:  0.2482016682624817\n",
            "Epoch:  725 loss:  0.1504998803138733 test loss:  0.24788302183151245\n",
            "Epoch:  726 loss:  0.17050540447235107 test loss:  0.2469724416732788\n",
            "Epoch:  727 loss:  0.1766219139099121 test loss:  0.24661171436309814\n",
            "Epoch:  728 loss:  0.17888331413269043 test loss:  0.2460322380065918\n",
            "Epoch:  729 loss:  0.17941200733184814 test loss:  0.2452334761619568\n",
            "Epoch:  730 loss:  0.245557963848114 test loss:  0.24439281225204468\n",
            "Epoch:  731 loss:  0.1611117124557495 test loss:  0.24407660961151123\n",
            "Epoch:  732 loss:  0.20553594827651978 test loss:  0.24379503726959229\n",
            "Epoch:  733 loss:  0.1891409158706665 test loss:  0.24373126029968262\n",
            "Epoch:  734 loss:  0.12546002864837646 test loss:  0.2443515658378601\n",
            "Epoch:  735 loss:  0.12971562147140503 test loss:  0.2445155382156372\n",
            "Epoch:  736 loss:  0.09755361080169678 test loss:  0.24505752325057983\n",
            "Epoch:  737 loss:  0.2375730276107788 test loss:  0.24398082494735718\n",
            "Epoch:  738 loss:  0.20452344417572021 test loss:  0.2434958815574646\n",
            "Epoch:  739 loss:  0.1804777979850769 test loss:  0.2427414059638977\n",
            "Epoch:  740 loss:  0.12936943769454956 test loss:  0.243086576461792\n",
            "Epoch:  741 loss:  0.14998018741607666 test loss:  0.24336397647857666\n",
            "Epoch:  742 loss:  0.13355767726898193 test loss:  0.24313098192214966\n",
            "Epoch:  743 loss:  0.1619701385498047 test loss:  0.24255502223968506\n",
            "Epoch:  744 loss:  0.14104998111724854 test loss:  0.24323415756225586\n",
            "Epoch:  745 loss:  0.15461689233779907 test loss:  0.24238723516464233\n",
            "Epoch:  746 loss:  0.12431752681732178 test loss:  0.24293702840805054\n",
            "Epoch:  747 loss:  0.17794477939605713 test loss:  0.24248480796813965\n",
            "Epoch:  748 loss:  0.13935285806655884 test loss:  0.2425520420074463\n",
            "Epoch:  749 loss:  0.30499565601348877 test loss:  0.24067473411560059\n",
            "Epoch:  750 loss:  0.16806381940841675 test loss:  0.24055248498916626\n",
            "Epoch:  751 loss:  0.10014128684997559 test loss:  0.24141758680343628\n",
            "Epoch:  752 loss:  0.16097593307495117 test loss:  0.24212002754211426\n",
            "Epoch:  753 loss:  0.18269532918930054 test loss:  0.24144673347473145\n",
            "Epoch:  754 loss:  0.19027554988861084 test loss:  0.24058449268341064\n",
            "Epoch:  755 loss:  0.1223863959312439 test loss:  0.24098289012908936\n",
            "Epoch:  756 loss:  0.149478018283844 test loss:  0.24060475826263428\n",
            "Epoch:  757 loss:  0.14894133806228638 test loss:  0.24162328243255615\n",
            "Epoch:  758 loss:  0.13226842880249023 test loss:  0.24125856161117554\n",
            "Epoch:  759 loss:  0.11644548177719116 test loss:  0.2415594458580017\n",
            "Epoch:  760 loss:  0.16701197624206543 test loss:  0.2405163049697876\n",
            "Epoch:  761 loss:  0.10901927947998047 test loss:  0.24144679307937622\n",
            "Epoch:  762 loss:  0.12738913297653198 test loss:  0.2413354516029358\n",
            "Epoch:  763 loss:  0.10852664709091187 test loss:  0.24212157726287842\n",
            "Epoch:  764 loss:  0.11186766624450684 test loss:  0.24291777610778809\n",
            "Epoch:  765 loss:  0.17203295230865479 test loss:  0.24224317073822021\n",
            "Epoch:  766 loss:  0.2406020164489746 test loss:  0.24084073305130005\n",
            "Epoch:  767 loss:  0.1608533263206482 test loss:  0.24069029092788696\n",
            "Epoch:  768 loss:  0.25137627124786377 test loss:  0.23879319429397583\n",
            "Epoch:  769 loss:  0.1290658712387085 test loss:  0.23907798528671265\n",
            "Epoch:  770 loss:  0.14695322513580322 test loss:  0.2400793433189392\n",
            "Epoch:  771 loss:  0.14952737092971802 test loss:  0.2397071123123169\n",
            "Epoch:  772 loss:  0.226906418800354 test loss:  0.23837065696716309\n",
            "Epoch:  773 loss:  0.17068767547607422 test loss:  0.2383900284767151\n",
            "Epoch:  774 loss:  0.1448957324028015 test loss:  0.23835831880569458\n",
            "Epoch:  775 loss:  0.2375279664993286 test loss:  0.237542986869812\n",
            "Epoch:  776 loss:  0.2559380531311035 test loss:  0.23734718561172485\n",
            "Epoch:  777 loss:  0.16976886987686157 test loss:  0.23744308948516846\n",
            "Epoch:  778 loss:  0.1838139295578003 test loss:  0.23735076189041138\n",
            "Epoch:  779 loss:  0.16626977920532227 test loss:  0.23726481199264526\n",
            "Epoch:  780 loss:  0.16563886404037476 test loss:  0.23745107650756836\n",
            "Epoch:  781 loss:  0.1402813196182251 test loss:  0.23746883869171143\n",
            "Epoch:  782 loss:  0.20255690813064575 test loss:  0.23648560047149658\n",
            "Epoch:  783 loss:  0.22321903705596924 test loss:  0.23569613695144653\n",
            "Epoch:  784 loss:  0.2530001997947693 test loss:  0.23573905229568481\n",
            "Epoch:  785 loss:  0.17560046911239624 test loss:  0.23557043075561523\n",
            "Epoch:  786 loss:  0.13319510221481323 test loss:  0.23535609245300293\n",
            "Epoch:  787 loss:  0.19585204124450684 test loss:  0.2357460856437683\n",
            "Epoch:  788 loss:  0.1264268159866333 test loss:  0.23682129383087158\n",
            "Epoch:  789 loss:  0.25710439682006836 test loss:  0.23616397380828857\n",
            "Epoch:  790 loss:  0.15269404649734497 test loss:  0.23703151941299438\n",
            "Epoch:  791 loss:  0.2381553053855896 test loss:  0.23529934883117676\n",
            "Epoch:  792 loss:  0.14700132608413696 test loss:  0.2352910041809082\n",
            "Epoch:  793 loss:  0.14536619186401367 test loss:  0.23507434129714966\n",
            "Epoch:  794 loss:  0.14655089378356934 test loss:  0.23499441146850586\n",
            "Epoch:  795 loss:  0.2588701844215393 test loss:  0.23485064506530762\n",
            "Epoch:  796 loss:  0.28428322076797485 test loss:  0.23448747396469116\n",
            "Epoch:  797 loss:  0.13836312294006348 test loss:  0.23413509130477905\n",
            "Epoch:  798 loss:  0.24945521354675293 test loss:  0.23404186964035034\n",
            "Epoch:  799 loss:  0.1615844964981079 test loss:  0.23356956243515015\n",
            "sigma tensor([[1.7025e+00, 1.7822e+00, 1.8408e+00,  ..., 1.8893e+00, 1.8885e+00,\n",
            "         1.9993e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [1.1380e+00, 1.3267e+00, 1.4204e+00,  ..., 1.4788e+00, 1.4786e+00,\n",
            "         1.3850e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.3626e+00, 2.0667e+00, 2.2023e+00,  ..., 2.2761e+00, 2.2764e+00,\n",
            "         2.3808e+00],\n",
            "        [1.4286e+01, 5.3631e+00, 3.6760e+01,  ..., 1.3226e+01, 3.6759e+01,\n",
            "         1.3935e+01]])\n",
            "fixed effects tensor([[1.0597e-02, 6.7609e-03, 6.8311e-03,  ..., 1.9718e-02, 1.9856e-02,\n",
            "         3.7962e-02],\n",
            "        [6.0937e+00, 2.5915e+00, 2.6560e+00,  ..., 4.4499e+00, 4.5152e+00,\n",
            "         1.8279e+01],\n",
            "        [1.5046e-02, 1.0848e-02, 1.0962e-02,  ..., 1.4597e-02, 1.4714e-02,\n",
            "         3.3596e-02],\n",
            "        ...,\n",
            "        [3.3250e-02, 1.3539e-02, 1.3839e-02,  ..., 2.2673e-02, 2.2979e-02,\n",
            "         1.0372e-01],\n",
            "        [1.8812e-02, 1.5017e-02, 1.5149e-02,  ..., 1.9137e-02, 1.9270e-02,\n",
            "         3.8623e-02],\n",
            "        [8.1622e-02, 7.7582e-03, 8.6714e-03,  ..., 3.7412e-02, 3.8349e-02,\n",
            "         3.1211e-01]])\n",
            "Epoch:  800 loss:  0.1455320119857788 test loss:  0.2337290644645691\n",
            "Epoch:  801 loss:  0.12545502185821533 test loss:  0.2341039776802063\n",
            "Epoch:  802 loss:  0.14383220672607422 test loss:  0.23473268747329712\n",
            "Epoch:  803 loss:  0.1323763132095337 test loss:  0.23479819297790527\n",
            "Epoch:  804 loss:  0.1686268448829651 test loss:  0.23401564359664917\n",
            "Epoch:  805 loss:  0.13739502429962158 test loss:  0.23353278636932373\n",
            "Epoch:  806 loss:  0.1435922384262085 test loss:  0.2333226203918457\n",
            "Epoch:  807 loss:  0.1245962381362915 test loss:  0.23364710807800293\n",
            "Epoch:  808 loss:  0.1670069694519043 test loss:  0.23341059684753418\n",
            "Epoch:  809 loss:  0.14453721046447754 test loss:  0.23432302474975586\n",
            "Epoch:  810 loss:  0.09262043237686157 test loss:  0.23469096422195435\n",
            "Epoch:  811 loss:  0.14915645122528076 test loss:  0.23359668254852295\n",
            "Epoch:  812 loss:  0.20033901929855347 test loss:  0.23303145170211792\n",
            "Epoch:  813 loss:  0.17806148529052734 test loss:  0.2328084111213684\n",
            "Epoch:  814 loss:  0.15407007932662964 test loss:  0.2322726845741272\n",
            "Epoch:  815 loss:  0.1365618109703064 test loss:  0.23190099000930786\n",
            "Epoch:  816 loss:  0.10978853702545166 test loss:  0.2321861982345581\n",
            "Epoch:  817 loss:  0.10470527410507202 test loss:  0.2331370711326599\n",
            "Epoch:  818 loss:  0.14284944534301758 test loss:  0.23268425464630127\n",
            "Epoch:  819 loss:  0.1443883776664734 test loss:  0.23257780075073242\n",
            "Epoch:  820 loss:  0.1420670747756958 test loss:  0.2327708601951599\n",
            "Epoch:  821 loss:  0.15484750270843506 test loss:  0.23333615064620972\n",
            "Epoch:  822 loss:  0.20040357112884521 test loss:  0.2327074408531189\n",
            "Epoch:  823 loss:  0.17415815591812134 test loss:  0.23200082778930664\n",
            "Epoch:  824 loss:  0.14071506261825562 test loss:  0.2325119972229004\n",
            "Epoch:  825 loss:  0.1766534447669983 test loss:  0.23098671436309814\n",
            "Epoch:  826 loss:  0.09916198253631592 test loss:  0.23210155963897705\n",
            "Epoch:  827 loss:  0.14619964361190796 test loss:  0.23262101411819458\n",
            "Epoch:  828 loss:  0.24590176343917847 test loss:  0.23190975189208984\n",
            "Epoch:  829 loss:  0.25212913751602173 test loss:  0.23148614168167114\n",
            "Epoch:  830 loss:  0.09818917512893677 test loss:  0.23245090246200562\n",
            "Epoch:  831 loss:  0.1969779133796692 test loss:  0.2308332920074463\n",
            "Epoch:  832 loss:  0.1622302532196045 test loss:  0.23014456033706665\n",
            "Epoch:  833 loss:  0.15752756595611572 test loss:  0.2301713228225708\n",
            "Epoch:  834 loss:  0.24918711185455322 test loss:  0.2295054793357849\n",
            "Epoch:  835 loss:  0.1393512487411499 test loss:  0.2295657992362976\n",
            "Epoch:  836 loss:  0.13908129930496216 test loss:  0.22956329584121704\n",
            "Epoch:  837 loss:  0.12904292345046997 test loss:  0.22893303632736206\n",
            "Epoch:  838 loss:  0.19683247804641724 test loss:  0.22861957550048828\n",
            "Epoch:  839 loss:  0.14521640539169312 test loss:  0.22932404279708862\n",
            "Epoch:  840 loss:  0.15950340032577515 test loss:  0.22876518964767456\n",
            "Epoch:  841 loss:  0.19571220874786377 test loss:  0.22856318950653076\n",
            "Epoch:  842 loss:  0.14644575119018555 test loss:  0.22936421632766724\n",
            "Epoch:  843 loss:  0.14582324028015137 test loss:  0.22832238674163818\n",
            "Epoch:  844 loss:  0.22170114517211914 test loss:  0.22744596004486084\n",
            "Epoch:  845 loss:  0.15868020057678223 test loss:  0.22693395614624023\n",
            "Epoch:  846 loss:  0.16055083274841309 test loss:  0.22750335931777954\n",
            "Epoch:  847 loss:  0.2030354142189026 test loss:  0.22696644067764282\n",
            "Epoch:  848 loss:  0.12393319606781006 test loss:  0.2268204689025879\n",
            "Epoch:  849 loss:  0.1595747470855713 test loss:  0.22657865285873413\n",
            "Epoch:  850 loss:  0.1443498134613037 test loss:  0.22594422101974487\n",
            "Epoch:  851 loss:  0.13791626691818237 test loss:  0.22614169120788574\n",
            "Epoch:  852 loss:  0.24489867687225342 test loss:  0.22569137811660767\n",
            "Epoch:  853 loss:  0.09282857179641724 test loss:  0.2264162302017212\n",
            "Epoch:  854 loss:  0.16451793909072876 test loss:  0.22605633735656738\n",
            "Epoch:  855 loss:  0.1354759931564331 test loss:  0.22662943601608276\n",
            "Epoch:  856 loss:  0.16423022747039795 test loss:  0.22615879774093628\n",
            "Epoch:  857 loss:  0.11227291822433472 test loss:  0.226759672164917\n",
            "Epoch:  858 loss:  0.15722668170928955 test loss:  0.22601133584976196\n",
            "Epoch:  859 loss:  0.13704514503479004 test loss:  0.22650891542434692\n",
            "Epoch:  860 loss:  0.1443324089050293 test loss:  0.22716909646987915\n",
            "Epoch:  861 loss:  0.1231270432472229 test loss:  0.22658586502075195\n",
            "Epoch:  862 loss:  0.15609639883041382 test loss:  0.22585642337799072\n",
            "Epoch:  863 loss:  0.168515145778656 test loss:  0.22489696741104126\n",
            "Epoch:  864 loss:  0.1144486665725708 test loss:  0.22514480352401733\n",
            "Epoch:  865 loss:  0.11612993478775024 test loss:  0.22490131855010986\n",
            "Epoch:  866 loss:  0.1876799464225769 test loss:  0.22437447309494019\n",
            "Epoch:  867 loss:  0.1381930708885193 test loss:  0.22521615028381348\n",
            "Epoch:  868 loss:  0.13409000635147095 test loss:  0.22439855337142944\n",
            "Epoch:  869 loss:  0.16281205415725708 test loss:  0.22550362348556519\n",
            "Epoch:  870 loss:  0.13951700925827026 test loss:  0.22500163316726685\n",
            "Epoch:  871 loss:  0.1135973334312439 test loss:  0.22508013248443604\n",
            "Epoch:  872 loss:  0.19314587116241455 test loss:  0.22459328174591064\n",
            "Epoch:  873 loss:  0.11809653043746948 test loss:  0.22449064254760742\n",
            "Epoch:  874 loss:  0.15433108806610107 test loss:  0.2237229347229004\n",
            "Epoch:  875 loss:  0.18362301588058472 test loss:  0.22372257709503174\n",
            "Epoch:  876 loss:  0.13530731201171875 test loss:  0.22370952367782593\n",
            "Epoch:  877 loss:  0.23999804258346558 test loss:  0.22317731380462646\n",
            "Epoch:  878 loss:  0.1269141435623169 test loss:  0.2231961488723755\n",
            "Epoch:  879 loss:  0.17153245210647583 test loss:  0.22286295890808105\n",
            "Epoch:  880 loss:  0.15987247228622437 test loss:  0.22271102666854858\n",
            "Epoch:  881 loss:  0.1374455690383911 test loss:  0.22355401515960693\n",
            "Epoch:  882 loss:  0.27182406187057495 test loss:  0.2222500443458557\n",
            "Epoch:  883 loss:  0.17237186431884766 test loss:  0.22081148624420166\n",
            "Epoch:  884 loss:  0.18559163808822632 test loss:  0.2205972671508789\n",
            "Epoch:  885 loss:  0.18108737468719482 test loss:  0.22044432163238525\n",
            "Epoch:  886 loss:  0.23820847272872925 test loss:  0.22026365995407104\n",
            "Epoch:  887 loss:  0.26853716373443604 test loss:  0.21949100494384766\n",
            "Epoch:  888 loss:  0.12045294046401978 test loss:  0.21957147121429443\n",
            "Epoch:  889 loss:  0.10757577419281006 test loss:  0.22011178731918335\n",
            "Epoch:  890 loss:  0.17056894302368164 test loss:  0.2214553952217102\n",
            "Epoch:  891 loss:  0.21842294931411743 test loss:  0.22039520740509033\n",
            "Epoch:  892 loss:  0.1198989748954773 test loss:  0.22017842531204224\n",
            "Epoch:  893 loss:  0.24256020784378052 test loss:  0.21973693370819092\n",
            "Epoch:  894 loss:  0.15376436710357666 test loss:  0.21922409534454346\n",
            "Epoch:  895 loss:  0.14041638374328613 test loss:  0.21993547677993774\n",
            "Epoch:  896 loss:  0.13113129138946533 test loss:  0.22040945291519165\n",
            "Epoch:  897 loss:  0.2367318868637085 test loss:  0.2196308970451355\n",
            "Epoch:  898 loss:  0.12494486570358276 test loss:  0.219618558883667\n",
            "Epoch:  899 loss:  0.13944649696350098 test loss:  0.22016900777816772\n",
            "sigma tensor([[1.7581e+00, 1.8482e+00, 1.9135e+00,  ..., 1.9666e+00, 1.9658e+00,\n",
            "         2.0776e+00],\n",
            "        [3.3099e+04, 3.3099e+04, 3.3099e+04,  ..., 3.3099e+04, 3.3099e+04,\n",
            "         3.3099e+04],\n",
            "        [1.1642e+00, 1.3612e+00, 1.4572e+00,  ..., 1.5169e+00, 1.5167e+00,\n",
            "         1.4234e+00],\n",
            "        ...,\n",
            "        [1.4866e+01, 2.8155e+01, 2.8155e+01,  ..., 2.8155e+01, 2.8155e+01,\n",
            "         2.8155e+01],\n",
            "        [1.4099e+00, 2.1296e+00, 2.2653e+00,  ..., 2.3433e+00, 2.3437e+00,\n",
            "         2.4474e+00],\n",
            "        [1.4285e+01, 5.3663e+00, 3.6759e+01,  ..., 1.3227e+01, 3.6759e+01,\n",
            "         1.3937e+01]])\n",
            "fixed effects tensor([[ 1.0655e-02,  6.4166e-03,  6.4898e-03,  ...,  1.9107e-02,\n",
            "          1.9249e-02,  3.8803e-02],\n",
            "        [ 5.8491e+00,  2.1138e+00,  2.1799e+00,  ...,  4.0591e+00,\n",
            "          4.1261e+00,  1.8672e+01],\n",
            "        [ 1.4516e-02,  9.8063e-03,  9.9240e-03,  ...,  1.3741e-02,\n",
            "          1.3861e-02,  3.4420e-02],\n",
            "        ...,\n",
            "        [ 3.1781e-02,  1.0724e-02,  1.1032e-02,  ...,  2.0364e-02,\n",
            "          2.0679e-02,  1.0593e-01],\n",
            "        [ 1.8302e-02,  1.3988e-02,  1.4123e-02,  ...,  1.8317e-02,\n",
            "          1.8454e-02,  3.9583e-02],\n",
            "        [ 7.7625e-02, -7.2988e-04,  2.1097e-04,  ...,  3.0608e-02,\n",
            "          3.1574e-02,  3.2035e-01]])\n",
            "Epoch:  900 loss:  0.15542370080947876 test loss:  0.21955400705337524\n",
            "Epoch:  901 loss:  0.21168547868728638 test loss:  0.21864575147628784\n",
            "Epoch:  902 loss:  0.13598579168319702 test loss:  0.21880024671554565\n",
            "Epoch:  903 loss:  0.1863498091697693 test loss:  0.2184348702430725\n",
            "Epoch:  904 loss:  0.14593958854675293 test loss:  0.21785342693328857\n",
            "Epoch:  905 loss:  0.15050238370895386 test loss:  0.21785634756088257\n",
            "Epoch:  906 loss:  0.13904482126235962 test loss:  0.21851998567581177\n",
            "Epoch:  907 loss:  0.15752965211868286 test loss:  0.2182977795600891\n",
            "Epoch:  908 loss:  0.18833273649215698 test loss:  0.21778106689453125\n",
            "Epoch:  909 loss:  0.22010445594787598 test loss:  0.21642553806304932\n",
            "Epoch:  910 loss:  0.14470970630645752 test loss:  0.21619969606399536\n",
            "Epoch:  911 loss:  0.2699936628341675 test loss:  0.21535730361938477\n",
            "Epoch:  912 loss:  0.13615453243255615 test loss:  0.21511012315750122\n",
            "Epoch:  913 loss:  0.18475282192230225 test loss:  0.21466118097305298\n",
            "Epoch:  914 loss:  0.16318196058273315 test loss:  0.2146892547607422\n",
            "Epoch:  915 loss:  0.14907866716384888 test loss:  0.21454203128814697\n",
            "Epoch:  916 loss:  0.14208966493606567 test loss:  0.21462160348892212\n",
            "Epoch:  917 loss:  0.11879241466522217 test loss:  0.21483957767486572\n",
            "Epoch:  918 loss:  0.11186999082565308 test loss:  0.21551334857940674\n",
            "Epoch:  919 loss:  0.11633366346359253 test loss:  0.21582800149917603\n",
            "Epoch:  920 loss:  0.11586970090866089 test loss:  0.21611255407333374\n",
            "Epoch:  921 loss:  0.1514139175415039 test loss:  0.2156628966331482\n",
            "Epoch:  922 loss:  0.20053082704544067 test loss:  0.2150852084159851\n",
            "Epoch:  923 loss:  0.18111157417297363 test loss:  0.21493852138519287\n",
            "Epoch:  924 loss:  0.10260206460952759 test loss:  0.2152341604232788\n",
            "Epoch:  925 loss:  0.11154842376708984 test loss:  0.2152712345123291\n",
            "Epoch:  926 loss:  0.17774152755737305 test loss:  0.21547025442123413\n",
            "Epoch:  927 loss:  0.1665637493133545 test loss:  0.21424520015716553\n",
            "Epoch:  928 loss:  0.16544032096862793 test loss:  0.21326905488967896\n",
            "Epoch:  929 loss:  0.10175836086273193 test loss:  0.2144017219543457\n",
            "Epoch:  930 loss:  0.14746534824371338 test loss:  0.21459418535232544\n",
            "Epoch:  931 loss:  0.14353996515274048 test loss:  0.21431893110275269\n",
            "Epoch:  932 loss:  0.13183802366256714 test loss:  0.21445155143737793\n",
            "Epoch:  933 loss:  0.2305275797843933 test loss:  0.21419847011566162\n",
            "Epoch:  934 loss:  0.145371675491333 test loss:  0.2148621678352356\n",
            "Epoch:  935 loss:  0.1337573528289795 test loss:  0.2144675850868225\n",
            "Epoch:  936 loss:  0.2133394479751587 test loss:  0.21336013078689575\n",
            "Epoch:  937 loss:  0.2056347131729126 test loss:  0.21292829513549805\n",
            "Epoch:  938 loss:  0.13650590181350708 test loss:  0.21256083250045776\n",
            "Epoch:  939 loss:  0.13249564170837402 test loss:  0.21255850791931152\n",
            "Epoch:  940 loss:  0.26544827222824097 test loss:  0.2117900848388672\n",
            "Epoch:  941 loss:  0.13782477378845215 test loss:  0.2126268744468689\n",
            "Epoch:  942 loss:  0.09265369176864624 test loss:  0.2137281894683838\n",
            "Epoch:  943 loss:  0.10969674587249756 test loss:  0.21360290050506592\n",
            "Epoch:  944 loss:  0.14921659231185913 test loss:  0.21309924125671387\n",
            "Epoch:  945 loss:  0.13054704666137695 test loss:  0.21367931365966797\n",
            "Epoch:  946 loss:  0.13965535163879395 test loss:  0.21319043636322021\n",
            "Epoch:  947 loss:  0.183061420917511 test loss:  0.21289128065109253\n",
            "Epoch:  948 loss:  0.1753104329109192 test loss:  0.21298295259475708\n",
            "Epoch:  949 loss:  0.08753752708435059 test loss:  0.21355760097503662\n",
            "Epoch:  950 loss:  0.10347270965576172 test loss:  0.21376073360443115\n",
            "Epoch:  951 loss:  0.15291458368301392 test loss:  0.21344757080078125\n",
            "Epoch:  952 loss:  0.13398009538650513 test loss:  0.21250879764556885\n",
            "Epoch:  953 loss:  0.12283039093017578 test loss:  0.21294772624969482\n",
            "Epoch:  954 loss:  0.1268167495727539 test loss:  0.21339058876037598\n",
            "Epoch:  955 loss:  0.13887298107147217 test loss:  0.2127450704574585\n",
            "Epoch:  956 loss:  0.16321223974227905 test loss:  0.21398860216140747\n",
            "Epoch:  957 loss:  0.10816031694412231 test loss:  0.2140083909034729\n",
            "Epoch:  958 loss:  0.1343865990638733 test loss:  0.21428072452545166\n",
            "Epoch:  959 loss:  0.12781792879104614 test loss:  0.2139056921005249\n",
            "Epoch:  960 loss:  0.10717910528182983 test loss:  0.21374410390853882\n",
            "Epoch:  961 loss:  0.26904749870300293 test loss:  0.21155577898025513\n",
            "Epoch:  962 loss:  0.16555970907211304 test loss:  0.21085983514785767\n",
            "Epoch:  963 loss:  0.1816158890724182 test loss:  0.21085864305496216\n",
            "Epoch:  964 loss:  0.16285449266433716 test loss:  0.21072298288345337\n",
            "Epoch:  965 loss:  0.14500141143798828 test loss:  0.21075332164764404\n",
            "Epoch:  966 loss:  0.11817038059234619 test loss:  0.21096140146255493\n",
            "Epoch:  967 loss:  0.10757339000701904 test loss:  0.21135032176971436\n",
            "Epoch:  968 loss:  0.145330548286438 test loss:  0.21059250831604004\n",
            "Epoch:  969 loss:  0.2095562219619751 test loss:  0.2095479965209961\n",
            "Epoch:  970 loss:  0.10816049575805664 test loss:  0.20970171689987183\n",
            "Epoch:  971 loss:  0.2319832444190979 test loss:  0.20965760946273804\n",
            "Epoch:  972 loss:  0.15605539083480835 test loss:  0.20940911769866943\n",
            "Epoch:  973 loss:  0.2641568183898926 test loss:  0.20821654796600342\n",
            "Epoch:  974 loss:  0.17276442050933838 test loss:  0.20863163471221924\n",
            "Epoch:  975 loss:  0.17969882488250732 test loss:  0.2086176872253418\n",
            "Epoch:  976 loss:  0.22176921367645264 test loss:  0.2075951099395752\n",
            "Epoch:  977 loss:  0.11326748132705688 test loss:  0.2080674171447754\n",
            "Epoch:  978 loss:  0.12966716289520264 test loss:  0.2085106372833252\n",
            "Epoch:  979 loss:  0.15716761350631714 test loss:  0.2080860137939453\n",
            "Epoch:  980 loss:  0.1385815143585205 test loss:  0.2078830599784851\n",
            "Epoch:  981 loss:  0.10006481409072876 test loss:  0.2082204818725586\n",
            "Epoch:  982 loss:  0.12802237272262573 test loss:  0.20886194705963135\n",
            "Epoch:  983 loss:  0.14162200689315796 test loss:  0.20945268869400024\n",
            "Epoch:  984 loss:  0.14519351720809937 test loss:  0.2093866467475891\n",
            "Epoch:  985 loss:  0.1935586929321289 test loss:  0.20853501558303833\n",
            "Epoch:  986 loss:  0.08944195508956909 test loss:  0.20950466394424438\n",
            "Epoch:  987 loss:  0.17044544219970703 test loss:  0.20870697498321533\n",
            "Epoch:  988 loss:  0.1302524209022522 test loss:  0.2085985541343689\n",
            "Epoch:  989 loss:  0.13383954763412476 test loss:  0.2093629240989685\n",
            "Epoch:  990 loss:  0.11175644397735596 test loss:  0.2102677822113037\n",
            "Epoch:  991 loss:  0.1423298716545105 test loss:  0.2099388837814331\n",
            "Epoch:  992 loss:  0.11809176206588745 test loss:  0.2089289426803589\n",
            "Epoch:  993 loss:  0.08844393491744995 test loss:  0.2098138928413391\n",
            "Epoch:  994 loss:  0.12623989582061768 test loss:  0.21007120609283447\n",
            "Epoch:  995 loss:  0.12871140241622925 test loss:  0.2094738483428955\n",
            "Epoch:  996 loss:  0.13112419843673706 test loss:  0.20981889963150024\n",
            "Epoch:  997 loss:  0.10718381404876709 test loss:  0.20926964282989502\n",
            "Epoch:  998 loss:  0.11108362674713135 test loss:  0.2091294527053833\n",
            "Epoch:  999 loss:  0.205081045627594 test loss:  0.20807260274887085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efe5a925-27be-4d84-98e0-29ed1fc36024",
        "id": "ITTS-hEfXfqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(train_loss[2:])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6637eccf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XdcFGfiBvDnpVvAgohd7EZjjF2j\nMcaYxJaeXy7JpZ53yeUud0nucjm9u/R6l15NTPHSq97FUxNLYm+IDUERQRBBpEoTWNjd9/fHzCyz\nu7MFBHYWn+/nw0d2dnZ5h8Fn3n3nLUJKCSIiCh4hgS4AERE1DoObiCjIMLiJiIIMg5uIKMgwuImI\nggyDm4goyDC4iYiCDIObiCjIMLiJiIJMWEu8abdu3WRCQkJLvDURUZu0Z8+eYillnD/7tkhwJyQk\nICkpqSXemoioTRJCHPd3XzaVEBEFGQY3EVGQYXATEQUZBjcRUZBhcBMRBRkGNxFRkGFwExEFGVMF\n9xs/HcWm9KJAF4OIyNRMFdzvbMzAtoziQBeDiMjUTBXcAgJcvJiIyDtzBbcAmNtERN6ZK7gDXQAi\noiBgquAGAFa4iYi8M1VwCyHYVEJE5IO5ghuAZJ2biMgrUwU3eHOSiMgnUwU3b04SEfnmd3ALIUKF\nEPuEECtbqjBKGzer3ERE3jSmxv0AgMMtVRBA7cfdkj+AiKgN8Cu4hRB9AMwD8EFLFoZNJUREvvlb\n434NwCMA7J52EELcI4RIEkIkFRU1faIotpQQEXnnM7iFEPMBFEop93jbT0q5REo5Xko5Pi7OrxXm\njX4WuwMSEfngT417KoCrhRDZAL4CMFMI8VlLFEaANW4iIl98BreUcpGUso+UMgHAzQB+llLe1hKF\n4c1JIiLfTNWPG+CQdyIiX8Ias7OUciOAjS1SEig1bta5iYi8M1WNm23cRES+mSu4OVcJEZFP5gpu\nCPxnXx4KK2oDXRQiItMyVXCX19SjzmbHHR8lBrooRESmZargtqntJIWVlgCXhIjIvEwV3JyrhIjI\nN1MFt4YBTkTkmTmDm8lNROSRqYKbgU1E5Ju5gpuNJEREPpkruJnbREQ+mSq4iYjIN5MGN6veRESe\nmCq4GddERL6ZK7jZyE1E5JOpglvD/CYi8sycwR3oAhARmZipgpuBTUTkm6mCm2soEBH5ZqrgJiIi\n3xjcRERBxpTBzV4lRESemTK4iYjIM1MFt+QS70REPpkquDWc3pWIyDNzBjdzm4jII1MFNxtKiIh8\nM1VwExGRbwxuIqIgw+AmIgoypgxu3pskIvLMlMFNRESeMbiJiIKMqYKbAyeJiHwzV3CrPbm59iQR\nkWemCm4iIvKNwU1EFGQY3EREQcZncAshooQQiUKIA0KIVCHEk61RMCIiMhbmxz4WADOllFVCiHAA\nW4UQP0gpd7ZUoXhvkojIM5/BLZXVDarUh+HqFzvuEREFiF9t3EKIUCHEfgCFANZJKXe1bLGIiMgT\nv4JbSmmTUl4IoA+AiUKI8133EULcI4RIEkIkFRUVNakwHIBDRORbo3qVSCnLAGwAMNvguSVSyvFS\nyvFxcXFNKoyW22zjJiLyzJ9eJXFCiM7q9+0AXA4grSULxTUniYg886dXSU8AHwshQqEE/TdSypUt\nWywiIvLEn14lyQDGtEJZiIjIDxw5SUQUZEwZ3Lw5SUTkmSmDm4iIPGNwExEFGXMFNwfgEBH5ZKrg\ndqyAE+ByEBGZmamCW8Oly4iIPDNlcBMRkWcMbiKiIMPgJiIKMqYMbrZwExF5ZsrgJiIiz0wV3FxI\ngYjIN1MFNxER+Waq4HZUuNnITUTkkamCW8PcJiLyzJTBTUREnjG4iYiCDIObiCjImDK4OckUEZFn\npgpuyY7cREQ+mSq4iYjINwY3EVGQYXATEQUZUwV3iHpTMqOwCnllNQEuDRGROZkquLt2iHB8/8h3\nBwJYEiIi8zJVcHfrGOn4nh1MiIiMmSq4Jw+MdXzPrtxERMZMFdx/mzvc8X0Ik5uIyJCpgjsstKE4\nHD1JRGTMVMGtx9gmIjJm2uAOYXITERkycXAzuYmIjJg2uJnbRETGTBvcbOUmIjJm2uBmGzcRkTHT\nBjebSoiIjJk2uHlzkojIGIObiCjI+AxuIURfIcQGIcQhIUSqEOKB1igY700SERkL82MfK4A/Syn3\nCiGiAewRQqyTUh5qyYIxt4mIjPmscUsp86WUe9XvKwEcBtC7xQvGphIiIkONauMWQiQAGANgl8Fz\n9wghkoQQSUVFRWdfMOY2EZEhv4NbCNERwDIAD0opK1yfl1IukVKOl1KOj4uLO+uCcXZAIiJjfgW3\nECIcSmh/LqVc3rJF0n5ma/wUIqLg40+vEgHgQwCHpZSvtHyRFGzjJiIy5k+NeyqA2wHMFELsV7/m\ntnC52KuEiMgDn90BpZRbEYAcZY2biMiYaUdOMreJiIyZNrgjw0xbNCKigDJtOoaHmrZoREQBZdp0\nlIEuABGRSZk2uO2S0U1EZMS0wc3cJiIyZuLgdk7uZ1cdwlVvbg1QaYiIzMOfaV0Dwu5S435/S1Zg\nCkJEZDKmq3FfOkyZoIpt3ERExkwX3EvvnohuHSPdatxERKQwXXAD2lzcTG4iIiMmDW4Buz3QpSAi\nMieTBjfbuImIPDFlrxIhhKONO6ekmhNOERHpmDS4Aam2cU9/cUOAS0NEZC4mbSoRHDlJROSBSYOb\nbdxERJ6YMrj1bdxEROTMnMEN1riJiDwxZXAfKz6DVcn5bhNNERGRSYNbU1NvC3QRiIhMx9TBXVFj\nDXQRiIhMx5TB/dQ1IwEA5TX1AS4JEZH5mDK4B3brCMA4uNnuTUTnOlMGd0w7ZUBnhWFwK/9arDZU\n17EphYjOPaYM7vYRSnBXG9yc1LoJXvnqZox4bE2rlouIyAxMGdwdIkMBANUW9xq1XQKZRVXILqlu\n7WIREZmCKYNbq3F/suO423N2KXHZy5tau0hERKZh0uBWatyH8ivcniuqtLR2cYiITMWUwR0e6rlY\nF/+L07wS0bnNlMFNRESemTa4w0K47A0RkRHTBndMu/BAF4GIyJRMG9ydGNxERIZMG9wXDYoNdBGI\niEzJtMH96PwRgS4CEZEpmTa4o8JDccPYPoEuBhGR6Zg2uIGGyaaaw9sbMpCwcBVq6rg4AxEFN5/B\nLYT4SAhRKIRIaY0C6cVE+XeDcsORQrz181Gv+3y8PRsAUFHLOb6JKLj5U+P+N4DZLVwOQ5cO7+7X\nfncv3Y2X1qYjq/hMC5eIiCjwfAa3lHIzgNJWKIubC/t2RreOkV730S+scP0723y+J9dhIKJgZ+o2\nboX3pLXrnj5d7bkZRHAgJhG1Ec0W3EKIe4QQSUKIpKKiouZ6W59sdudgP3KqEt/tyfW4v/RxISAi\nMrtmC24p5RIp5Xgp5fi4uLjmeluf7C5tH1e+thkPf3sAZyxWbM8sdmwXUKrcrkFPRBRsgqCpxDtP\nQfzEilTc+v4utxuWdntrlIqIqOX40x3wSwA7AAwTQuQKIRa0fLEa+LqZ6Frj1pwsrwEAZJc4B7eN\ndyeJKMj5HOEipbylNQrSVJ5q0PExUQCAj7Zm4dJh3R03J9lUQkTBLvibSjzUoLPVJhLX1XQ81dCJ\niIKF6YNbi9m3bh1j+LynGvTenDIAgFV9XvjYn4goWJg/uNUa8qQBxtO8Sh81aJtLW0pzBHdNnQ25\np6vP+n2IiJrC9MGtcV3JbHTfzgB832y02pyfb46mkgUf78a0f3LRYiIKjKAJbuEy9FGrSfuqQdul\nREVtPU6W1wJoaDrxV3GVBfU251r79sySRr0HEVFzCprgdlVvVQLYV83XapdYuCzZ8diuBvfOYyWo\nrbdh17ESFFbUGr62zmrH+GfWY9Hyg4bP+2qmISJqCaYPbk/R6FoL9sRml8gqrnZ6fKK0Gjcv2YlF\nyw/iF0t24uq3jCen0n7GquR8j+9NRNTamm+lghbmOkeUv23VybnlTo9tUqLKYgUAHDpZAQA45aHG\nrTWreJrfxCZl8PwCiajNMH2N+3czBgEA2keGOm1val33H/9JQbW6Co7RjU0pJf75Yxqyi8/A6qNW\nzxo3EQWC6YP7numDkP3CPESGhfre2Q/His/g/c3HACht2Jo6qx0lVRYcL6nG4o2Z+PUnSai3+epq\nyOAmotZn+uD25LoxvZ0ej+rdye/XajVti7Vh/ckHvtqHcc+sd9Tk62127Dl+2ul1KXnl2Hik0PGY\nE1YRUSAEZXBnvzAPlw2Pd9rWLtz/Grl0BHdD8v6QcgpAQy1aAPj9F3udXjf/za24a+lux+PGTFhV\nUVuPhIWrsMzLXOFERP4IyuAGgMhw56J3iPQ/uHceU1Zis9S7V5m1HiT6SJbSuOuf1aXKXV5Tjx/V\nC4CrU2o/8sWbMv0uJxGRkaAK7n5d2yMyTCmy9q8mLjoSb95iPJ+JK61Xib6pRPPq+nQAwPES5yHt\ny/bmue3r2lTyp6/347ef7cGJUvfh8CHqACJ9u7qrk2U12JTe/KsH7c05zfZ4ojYkqIJ7w8MzkPLk\nlQDgdrPyuz25uGp0L/xq6gC/368xWXbgRJnbNtemkuNqYNfUN1wQMgqrkHaqAgVql0NvwT3vjS24\n86NE/wvlh8SsUlz/zna8y5o+UZsRVN2QQ0MEQtUe3aEuk5doQf7o/PMwf3RPXP/O9mb7uTa7NKyd\n23S9TlJPliOjsApAQx/zhIWr3F5T56WLobbYsZTSbYh/U50sUxaUOHKqslnej4gCL6hq3HqxHSJw\n2+R+jser/jgNgDKnydh+XXDgsSswc3j3ZvlZVrtErUF7uFbjrq23Yd4bWx3bvfU28Vbjdryv+lHA\narPj26QTjmH6TaENHuIq90RtR9AGd0iIwDPXjsK90wcCAAZ06+D0fKf24c3681YcOOm2zWaXyCyq\nwvBHf3Ta7m04vj/BrdXKP9qWhb98l+xx1frUk+UoPVNn+Nzj36dgxosbHEu/hTC5idqMoGoqMbJo\n7nlYNPc8w+dq6tybN5qTzS6RdqrCbbvFavc4MZVRU0lSdimWbs9u2MdqR/sIoKRKCeUSD+E8742t\n6B/bHpv+cqnbcx/vOA6gYc1OxjZR2xH0we1Nt+jIFn1/m10a1qDzyqrxZWKO3+9z47s7nB7XWe2w\nWG14Tx3haTQvi9Z84tr7xVVz9iUpr65HTLuwZmt/J6KmCdqmEn88fc3IFn1/u5QornKvDafkudfC\nG8NitTvNSCilxKnyWmxIK8RN7+7AquR8p54rrrYeLXZ6LQDDKvep8lp8vdv4AlNcZcHyvblYd6gA\nGYWVOFpQidFPrcW3SUqzTXpBpVtPFX9nbGxNKXnluOrNraiuswa6KETNpk3XuDu3j3B8/829U/DQ\n1/tx1ehe+Hh7NmrqbegeHYnCSovX9+gRE+Vx9kCbXaLGIBAKPOyvsdslQlyX9NGps9mdVu6xS+CG\nxduRp/YQScwuReLfLzN87YETZbjtw12Ox/o27iqLFVJKREcp7f93LU1E2qlKXD6iB7p2aPhdGfWG\nefvWsQCAjemFuGlCX1z/znZUWaxYMG0AwkNDkJxbhqvf2oZPF0zExUPivB5/a3p65SEczCvH/hNl\nuGhQt0AXh6hZtOkat97EAV2xbeFMLJwz3DHq8tMFk3y+7pKhnkPIapeoNWgqKTGohetV1jaE/Z++\n2e/2/NajxU7NI1LCEdqatHzj7n0lZ5wvRI+oi0gIAGOfWodRT6x1PFdcpeybXXJG97OMG1fOqBco\noVbdtUFMtWrNPylbmdfl9g8TccWrmwzfA4DPGRebW8MHjtZr3lm2JxcJC1c5RssSNbdzJrj1tFGX\nEWEh6NUpyuu+Rv23NTcs3o4laju0XkGl9/+w+nBdbjAi8/EVqU7Loxm1cd/RyIE6QrjfGNXaqq9/\nZzteXnsEt76/E5UW4yaFR75LdrwP0LAGqNZkE6EbyZpeUGX4Hh9sOYbBf/8B5Wp/9aaqsljxVWKO\n4yJz4EQZbnp3h+Mioqd1h/w5rcDruWxOXyedAAAcKzb+PbSGnJJqZBRWIr2gkis1tUFtPrhfuH4U\nZo/s4bQtSp2QSkqJmHZKs0F0ZEOrUd+u7XCfOg+4v2tUTh3csAr9saIzXvZUJrRSmlk8B8kJ3Sry\nvkrw9oYMn+Uz6g6ob6158+cMbM8swSe63i1GtLDX/tXme4kIc/9TOlbkHFzPrDoMACj0cmFLPVmO\n93yM8nxyRSoWLj+IAYtWIzGrFIuWH0RidqljAJSellnvb8nC86vTkJLXsLDGwdxyXPLiBpTXnN2F\nxJV24zgsJHD/vaa/uAGzXtmMK17djA+2ZAWsHNQy2nxw3zyxH969fZzTNq3GXWezO4L7vTvG4aFZ\nQ/HvuydgyyMzEau2+cbq2n41S1zeDwCuHt3L7zK9uOYIzn98DX79yW6P++jbuH3VmF5ccwQ/puTj\n0MkKj4N/vtp9wvF9Za0SVKEGYf7S2nSvP0u4/KvVuMNc2uw3pBVi5subsPqg+7JvFpfmpZS8csdN\n0nlvbMXzP6Q5jvlwfoVbDx2tiQcAnlqZ6qhJh4e6/znrf3P/3p6N+W9uxc9pBQCAV9YdwfGSaryy\n9ohhbb2ptIu96+jepsgrq0FeWc1ZXVy2ZBT73omCSpu+OenJHVMS8I//piA+Ogo3je+LxKxS9O3S\n3unm1fVj+2BbRjF+f+lg1NkkYjtE4C21ZmvUr9ooNLypqbdhW4bn1eIP6mqGrkFn5LefKVPQ3jml\nv899n1hxCC/fNLpJ3fq0LNJeqn1qcC3jwuVK08q7mzJx6bDuTnObu/aImf+mMur0FxMaRsLW2yQi\nwgTmvL4FAHDLxIbnQnU1WX0PHtfZGgHji97PaYWYOTwe2rXx4x3HIYTAE1d77oVUUmVBrdWOjhFh\neHb1ISycc57TDV29hqats2+imPrCz47v37t9HGKiwhERFoJx/bv4/R6nymvwze4T+L/xfRp1zi1W\nG8JCQprlAkTN65wM7tsm98dtk5WAu3FcH1w1uqfbpFVdO0Rg6d0TAQDPXz8KABzBPff8nm4DbPyZ\nDzwuOhKxHSKQ1sh5Q4za0T3RBt54c6pCudHZlO7YjqYSCAAS17y9DVnPz4XFJYwLKpRacXJuOR78\neh/WpBY4ntPXbpNzGybv0s9gOP/NLbhUN2VBndWO4yVnMCQ+2q12rzG6wBlF5zdJuTicX+l0zoxm\ndNyeUYyDeeXo1bkd/vDlPgDKhfGbpFwM6xGDBdOMJzTTPi3pV1DKLj6DGS9txMe/mmh4w/uNn44i\nLjoS117YG8m5ZZg0MNZtn7WpBVi2V+2O+cwcWO12tI9w/y98zydJTo/TC6rwyLJkHMgtw5FTlfju\nvosMy+1q2D9+xGXDu+PDuyb4tb/GarOjzmZcNmoebb6pxB/+LovWPToS/5h3Hjq1D0f2C/OcntPX\nvkb17oQHLhsCQOnNsvah6Xj2uvPx7b1TcDb3ieKiI/FUM/RNl1JZ2CH3dI3vnV0I17YSKMGQVey5\nXd/1k0VtvR1fJuZg4bJkR28UAKjS9bZJL6jCe5saLliPr0jF5a9uxt6c00jNd14AWmM0v7rRLYo6\nq7K6kf5GbPtI55A5Y7Hi1g924fkf0hyhDQBFajPN0ysPIfe0c9iX19Tj1vd34lC+8imgps6GD7Yc\ng8VqQ2K2Mgf89/uVm9GJWaWwWG34fn8eTpRW45V16Vi0/CAeX5GCXyzZieMl7r/PitqG5pIbFm/H\niMfWGP4e1h4qMNz++a4cJB1XpvjNKKzEK2uP+GyG+ymt0OvzRn79SZLHsjWn6jorPthyDEdOVSLb\nw99f6Zk6rPPw+9BUWawoNOjCK6XEmtRTjp5QdVY7TnsYxdzaeElshMS/zzLc3q9re8R2VEZpdusY\nif/9YRqWbFZusI3u0wlD46MxND4agHLj80iBcY37Xzde4Oi9YWTBtAG4Y0oChsZH4+YlO5t8HNsz\nS/BXLz/Hm+V78/DgZUMR1zHS0UXx7qWJOOml61uVS0+VT3cex2Z13vGbxvdxbNcHk6tN6pJx3mZ9\n1Nq6S6osGPfMevz+0kGG0/FqKnXtxu11N6zXpBZgYFwHw9fou2E+sSIVN0/oh0kDuyI6KhxLt2U5\n9Qb6fFcO1h8uQHWdMmYAUO4r7M4uxU3v7cD9lw7GWxsy0LtzO8drDpxQLkrFVXXoH+tcBn0A6ZvS\nGstiteHOj3Yjr6wGd16UAJtdwmqX6KUrh6dAl1Ligy1ZuH5sb6xJLUBhZS1+c/FAvLw2HeGhAhar\nHRuPKOc293Q1+nRp77Ec+3JOY3tmCUb0jMGwHtFOP7+23ob88lq3OYj0Xlt/VP00qtz0PvjEFYgK\nD3VqtrznkyQkHT+NA49d4XH+omve2orMojNulbENRwpx76d78NCsoXhg1hA8+PU+rD54ClnPzw34\n6GEGdzNYcf9UR81Ou/E5vEcMAGBErxinfR+dPwLTBnfD3pwyt4mr/m9cH6fgnn9BT6zUjaCckKC0\na+r/Tw3s1gHHvNR2Q0OE4SIKP3hYqccf01/cAAAYGt8R6QVVXkPbyGbdYhHfJDVMoHWJ+r5G/PkZ\nK5PzERUe6qi5v73Be+8Ufc+dvTmnMef1LbhoUCw+3Oq5F4b+d73+cCHWH1YuKKlPXunUHAQ03AQu\nrrI4PpEl55YjXe39ojW96fvoaxef+7/Yiz+qn9q8cZ0C+GSZ709RtfV2R7/8spp6XPay0u/+yatH\n4pukE1j1x4s93lcZsGg1AOC9zcccN4ntUpkQzdXs17Y45s83cp3uIhwfE4ldf5uFitp6RIaF4M/f\nHMCqg/lIe3q2oxeY3pin1jqmQdZoYxRundQPz12nNG86Pv3U29AJzsG9Ob0IdimR6aEXWJn6/tkl\nZ2C12bH6oPJ/pqjSgu4x3rsRtzQG91nY++jlqLfZ0bl9BKSUeGjWUMwdpXQ9nD40zvCPrn9sB9w1\ndQDumgpcNCgWizdl4nhJNRbOGQ4hBLJfmIcJz65HUaUFC6YNcAT3lIGxOF9dEFlfC/norgmY8dJG\nx+PsF+Y5jXwc3iMas86Lx+s/HQUAHH5qNjYfLcK9n+5x7DNpQFfsyir1eqwZz87B4L//4LStT5f2\nHvtsN8XZLtLz3Z5cjzMpGtG3QR9Vw/RwftOmK/gyMcfttdrv1FJvxz/+mwIAHj9tabTAzC+v9ThR\nmZ4WpACw6S8zcPmrm32+ZvHGDEco6WeXfHxFKgClycfXfVV9z55DJ41r//pPWrX1NljtEh0jw2Cx\n2tzm+NHuiVzwxFr07BSFfPVCXV1nMwxu19DW+2JXDrp1iMBdUwegWr15rl2oiqssiO0QASGE21gI\n1xHNYaENvc9eXHvEsX3icz+51c4BYOexEuSdrsEN4/q4PdfcGNxnQd+uLYTAA7Oca0hGf3B6N0/s\nh5t1vSU00VFhKKq0oH1EGL6+ZzIKKy24StfdsEenKKc/nGX3TcGK/Sfxj/kjAAA/PngxdmefRnx0\nJEb37Yz4mCjcP3MwbHaJqPBQXDmyh9NQ/q/vnQK7XeLE6Wpc8uJGx/umPT0bVrvEGYsVYaEh6N25\nnVPtMJAfFuec3+OsPjWcjRnD4hzNARqjbo8abUCOPyrOotuf/tx5876uX7fRKN/0gkqn5ptH/5uC\nx68a4QgyV9oart48+t8UpBdU4vv7p+HupbudmpQ0WoUjX/fpSuuBZLXZ8cHWLEweGIun/pfq8+e9\n8XOG032LQycr0KldOMY/sx73zRiEh68Y5vaawkoL8sqqMa5/VwAN3WUzC6uc5g7SLFp+EBf27eTo\nDfWfvXnYcKSwVYKbNydNaPEvx+GaC3thYFwHTBoY6xTaRsb174onrznf0bY3vEcMbp/cH1eM7IF4\n9SNdeGiI04Vk7Z+mA2jofx0SItBDN4p02X1TEBUeio6RYY73uGViX8fzN0/o67X73Be/mYQ4D7Mz\nbv3rpX71wtG7fkxvTBvc0F1z8W3jsO6h6Y16D836P13i9776n6H11Y+Pdv+YvDenDF2aYQ74My08\nFbGr3362x23bukMFTrXRT3cex9pDBR5nvHS9h6H33OrDeHtDBr7dk4sDueU4WVZjGNqePPW/VJRV\n12HGSxvxwg9puPbtbdib4/m+hd4LP6Q5vv/Dl/scNzAXb8w0bJb715o03LB4B5KyS5FZVIXkPOXn\nGPUCq6mz4cvEHPx12UGUVSsXv/KaenRu5nUAPGGN24SG9YjG6zf7t/BxU8VEhSP5iSucas1a75oO\nEaGOWoeRP8wcjD+rNZbPFkxCUVUtHvr6AAAg87m5KKioRa/O7bD6jxejymLFsj25eGtDBn5z8QBc\nObIH+nRpj8NPz8bs1zYj7VQl5o3qiVVqjfXR+SPw9MpDAJRPNFMHd8P/DpzEoO4d8fjVI5GaV44E\ntaloSHw0JiR0wbxRPREfE4XKWqtjbhZXEaEhjiH/g7t3dGxfetcETB3cDbmnq/Hg1/uRnOv8sX+I\nelMZUG4sK9saXv/cdaPwt/8oTRp3Tx2AV9Z5H8Dkzajenc7qpqPePdMHNqobqZ7R6373+d5mea8n\n/agt661JLcCa1HVe9xncvaPhqFlX+t42Rj2qtOknXKdZNnLeYw2Lp9z+YSI+WzAJZTV16NSudYJb\ntMQ8BuPHj5dJSUm+dyTTSckrR9cOEU53+DXlNfV4YkUqnrhqpNsd+mV7ctE9JrJRMwNW11mx5Wgx\nLhkah8P5FSiqtGDWefH4bm8urrmwF8JDQmC1SyzdloW7pib41W3zWFEVenVuh4raevz1u2SM7dcF\nL69Lxz9vGIXuMVEIDwnBtCHdUF1nRXhoiFMPhPzyGny64zjunznY0Z0t+4V5+DHlFJKyS3HLpH74\n97ZsPHzlMIx+UrkRlvncXAz6m9LOnPX8XPxrzREMiO3gdAHp17U9clz6icfHRGJofDRChMCm9CL8\n5cphuOqCXnjtp3RMHhCLR5YlY9Gc4bh+bB9MeHa923HeMaU/PlH77N87fSBG9IrBA18pE5Zde2Ev\nPHbVSFz79jbklFbjm3un4Kb3PIfRmgen452NGfh+v/sqT758umAibv+w+Ra4bhce6nXKYiP3Th/o\nmLu+pV09upfhaliapvR71wh1n7YCAAAIG0lEQVQh9kgpx/u1L4ObyF3CwlW4aFAsvvjNZMPnt2cW\no7LWiitH9kDCwlUY178LlukGtlisNqw+mI8tR4vxwGVD8NnO44625aV3TcBFg2MRGRYKu11i89Ei\nTBoQi3YRDRemlLxyjOgZg5AQgX05px09MD751UTszi513Liusljx20sGobbehtFPrsXjV43ErZOU\nNteaOhsyi6pwfu9OOHCiDLuzSx3zxdwysS++TFTa3jOfm4sfUvJx/xdKf/WLBsXCovZ1N3LXRQmY\nNKAr5ozqCUC5oBdVWnDr+zvxxi1jMHlgLDIKK3H/F/tQVl3vNi3yw1cMxcrkfEcTxKXD4tCrczvc\nMSUBw3pE458/pmHxRu89ggBg3gU9sXD2cHyZmIN31P27dYxAaIjAs9eOwsjeMejaIQIHc8vxRWKO\n4YRuC+cMR97pGny60/PAtWHx0Y6byn++fChe9vKpaurgWHz+a+O/GV8Y3ERnqajSguioMJ83mAGl\nC17n9uE+RwruOlaC7jFRXvsme7L/RBmyiqtw3Zim3/iSUmJ7ZgmmDIxFSIjArmMliAgLwZh+SjfT\nhIWrcPGQbo7pjrdlFOOXH+xS7wlI3PnRbsy7oCcWqT2g/LVkcyaeW52Gv1w5DDsyS/DkNSOxPbME\nj6o9bd64ZYzbXD9J2aW48d0dGN4jGu/fMR419TZU19nQpX04jhWdwfShcY6h+JW19Xhu9WHcd8lg\n9Is17jd++kwdlu/Lg81uxzdJuThRWo0HZw3FfTMGoabOhvMe+xF9u7bDiVKlCWXjwzPw12XJGNW7\nE+6YkoCFy5NxQZ/OeOjyIfjP3jwsNOjxM7ZfZzxz7Si3LsD+avbgFkLMBvA6gFAAH0gpX/C2P4Ob\nKPhU1tYjIizE75HE/rLZJX5OK8Ss87o7Al9KiXqbhMVqcyzs4WrDkUJMG9yt0fMANcX2zGIM7xGD\ntamn0LNzO6/z8ANK+TOLqnAovxJj+3XG9/tP4nczBp3VwJxmDW4hRCiAdACXA8gFsBvALVLKQ55e\nw+AmImqcxgS3P5eyiQAypJTHpJR1AL4CcM3ZFJCIiJrOn+DuDUA/giBX3UZERAHQbI1HQoh7hBBJ\nQoikoqIi3y8gIqIm8Se48wD01T3uo25zIqVcIqUcL6UcHxdnnlW+iYjaGn+CezeAIUKIAUKICAA3\nA1jRssUiIiJPfA55l1JahRD3A1gDpTvgR1LKxo1bJSKiZuPXXCVSytUAVvvckYiIWhxnByQiCjIt\nMuRdCFEEwPeqtca6AShuxuIEAx7zuYHHfG5o6jH3l1L61bOjRYL7bAghkvwdPdRW8JjPDTzmc0Nr\nHDObSoiIggyDm4goyJgxuJcEugABwGM+N/CYzw0tfsyma+MmIiLvzFjjJiIiL0wT3EKI2UKII0KI\nDCHEwkCXp7kIIfoKITYIIQ4JIVKFEA+o27sKIdYJIY6q/3ZRtwshxBvq7yFZCDE2sEfQdEKIUCHE\nPiHESvXxACHELvXYvlanUIAQIlJ9nKE+nxDIcjeVEKKzEOI7IUSaEOKwEGJKWz/PQoiH1L/rFCHE\nl0KIqLZ4noUQHwkhCoUQKbptjT63Qog71f2PCiHubGp5TBHc6mINbwOYA2AEgFuEECMCW6pmYwXw\nZynlCACTAfxePbaFAH6SUg4B8JP6GFB+B0PUr3sALG79IjebBwAc1j3+J4BXpZSDAZwGsEDdvgDA\naXX7q+p+weh1AD9KKYcDGA3l2NvseRZC9AbwRwDjpZTnQ5kS42a0zfP8bwCzXbY16twKIboCeBzA\nJCjrHDyuhX2jSSkD/gVgCoA1useLACwKdLla6Fi/h7Ka0BEAPdVtPQEcUb9/D8oKQ9r+jv2C6QvK\nLJI/AZgJYCUAAWVQQpjrOYcyD84U9fswdT8R6GNo5PF2ApDlWu62fJ7RMFd/V/W8rQRwZVs9zwAS\nAKQ09dwCuAXAe7rtTvs15ssUNW6cI4s1qB8NxwDYBSBeSpmvPnUKQLz6fVv5XbwG4BEAdvVxLIAy\nKaVVfaw/Lscxq8+Xq/sHkwEAigAsVZuHPhBCdEAbPs9SyjwALwHIAZAP5bztQds+z3qNPbfNds7N\nEtxtnhCiI4BlAB6UUlbon5PK5bfNdO8RQswHUCil3BPosrSiMABjASyWUo4BcAYNH50BtMnz3AXK\nMoYDAPQC0AHuzQnnhNY+t2YJbr8WawhWQohwKKH9uZRyubq5QAjRU32+J4BCdXtb+F1MBXC1ECIb\nyhqlM6G0/3YWQmgzUuqPy3HM6vOdAJS0ZoGbQS6AXCnlLvXxd1CCvC2f51kAsqSURVLKegDLoZz7\ntnye9Rp7bpvtnJsluNvsYg1CCAHgQwCHpZSv6J5aAUC7q3wnlLZvbfsd6p3pyQDKdR/HgoKUcpGU\nso+UMgHKufxZSvlLABsA3Kju5nrM2u/iRnX/oKqZSilPATghhBimbroMwCG04fMMpYlkshCivfp3\nrh1zmz3PLhp7btcAuEII0UX9tHKFuq3xAt3gr2uonwsgHUAmgL8HujzNeFzToHyESgawX/2aC6Vt\n7ycARwGsB9BV3V9A6WGTCeAglDv2AT+Oszj+GQBWqt8PBJAIIAPAtwAi1e1R6uMM9fmBgS53E4/1\nQgBJ6rn+L4Aubf08A3gSQBqAFACfAohsi+cZwJdQ2vHroXy6WtCUcwvgV+rxZwC4u6nl4chJIqIg\nY5amEiIi8hODm4goyDC4iYiCDIObiCjIMLiJiIIMg5uIKMgwuImIggyDm4goyPw/NcAET1tUS0wA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBiAyg9zksxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ea92bed8-176a-4907-f6d4-e49d6e33a339"
      },
      "source": [
        "plt.plot(test_loss[2:])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6637b7fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hbUW-WJyPZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_paths = 10000\n",
        "pred_length = 64 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1eZV6ovsj3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_vol = test_vols[0:number_series].reshape((number_series,-1))\n",
        "\n",
        "norm_test_vols = np.zeros(test_vol.shape)\n",
        "for i in range(number_series): \n",
        "  norm_test_vols[i] = test_vol[i]/np.amax(test_vols[i])\n",
        "  \n",
        "new_test_data = norm_test_vols[:,:pred_length]\n",
        "\n",
        "covars_test_data = new_create_covariate_data(new_test_data, 64, [0,31,32,63])\n",
        "\n",
        "covars_test_data = torch.FloatTensor(covars_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_itPTSux6ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## PREDICTION ##\n",
        "paths = np.zeros((number_series, num_paths, pred_length))\n",
        "\n",
        "with torch.no_grad(): \n",
        "  \n",
        "  test_data = covars_test_data\n",
        "  \n",
        "  for n in range(num_paths): \n",
        "    \n",
        "    fixed_effects = global_model(test_data, global_hidden)\n",
        "    sigma = local_model(test_data, local_hidden, fixed_effects, gaussian_likelihood = True, prediction = True)\n",
        "    \n",
        "    for i in range(number_series):\n",
        "      z = torch.zeros(sigma.shape[1])\n",
        "      for t in range(sigma.shape[1]): \n",
        "        z[t] = torch.distributions.normal.Normal(fixed_effects[i,t], sigma[i,t]).sample() \n",
        "\n",
        "      paths[i,n] = z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl48IeZGAO9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "418da874-f8e5-418f-f1bd-0390afd3ce79"
      },
      "source": [
        "plt.plot(new_test_data[0])\n",
        "#plt.plot(paths[1,0])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6636840b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuL4Kvv_A16L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "bbf6d863-7733-4d94-ee08-5aaddd9ef9e6"
      },
      "source": [
        "plt.plot(paths[10].mean(0))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6633e3ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7FkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntPNDd_K5YLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a334605d-2016-4cd4-9a4e-ed3c39a87926"
      },
      "source": [
        "plt.plot(fixed_effects[0].numpy()) #this is sort of the right behaviour but the linear increases seem strange and also this isn't really reflected in the estimates themselves "
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6631fffd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W_8B3c05v8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c7994775-e2a3-4806-bc57-2c97b7e73043"
      },
      "source": [
        "paths[0].mean(0)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00049976, -0.03239671, -0.01350039,  0.02024259, -0.00518761,\n",
              "        0.02420265, -0.0039236 , -0.01430491,  0.02655447,  0.00642082,\n",
              "       -0.00175647,  0.01571183,  0.00355058,  0.00361022,  0.03944783,\n",
              "        0.01367937, -0.01481334, -0.02928832,  0.01844477,  0.00973043,\n",
              "        0.00841626,  0.05258188,  0.01435105,  0.00845323,  0.01671772,\n",
              "        0.02352473,  0.02934061,  0.00641784, -0.00682119, -0.02509015,\n",
              "        0.02782221,  0.03079351,  0.01826043,  0.00627361,  0.01708162,\n",
              "       -0.00394783,  0.02465892,  0.00931524,  0.00884748, -0.00991178,\n",
              "        0.03348924,  0.01748769,  0.03030849,  0.02427111,  0.02202151,\n",
              "       -0.01406428,  0.03627779,  0.02799858, -0.00915679,  0.05077866,\n",
              "       -0.00789345,  0.05023419, -0.00433758,  0.0394172 ,  0.02550632,\n",
              "        0.00968601, -0.01056902,  0.03379284,  0.02134198,  0.01643704,\n",
              "        0.02321576,  0.00046401,  0.01103493,  0.04584948])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWbcMtlYBYPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9f02deef-6872-484a-d6e1-a853a22c853b"
      },
      "source": [
        "sigma[0]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7989, 1.8968, 1.9668, 1.9837, 1.9919, 1.9967, 2.0000, 2.0024, 2.0045,\n",
              "        2.0062, 2.0078, 2.0093, 2.0107, 2.0120, 2.0133, 2.0145, 2.0157, 2.0168,\n",
              "        2.0179, 2.0189, 2.0198, 2.0208, 2.0216, 2.0225, 2.0232, 2.0240, 2.0247,\n",
              "        2.0253, 2.0259, 2.0264, 2.0269, 1.9031, 1.9509, 1.9747, 2.0284, 2.0300,\n",
              "        2.0302, 2.0299, 2.0297, 2.0297, 2.0297, 2.0298, 2.0298, 2.0297, 2.0297,\n",
              "        2.0295, 2.0294, 2.0292, 2.0290, 2.0287, 2.0284, 2.0281, 2.0277, 2.0273,\n",
              "        2.0269, 2.0264, 2.0259, 2.0254, 2.0248, 2.0242, 2.0235, 2.0228, 2.0221,\n",
              "        2.1348])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    }
  ]
}