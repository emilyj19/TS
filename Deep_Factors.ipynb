{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Factors.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyj19/TS/blob/master/Deep_Factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxHpi6CjWlg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a79e8565-3b47-4d86-dc19-eeef619bbfab"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63MFgpVHUb5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_-DYtEUfH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a7536a24-bbe6-4969-9775-918fd00b9cc9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAw0rtMUhZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71c6fe17-9639-4d7f-94ff-9e503b843888"
      },
      "source": [
        "root_path = 'gdrive/My Drive/FinancialTS/JPmarket_dataset.npz' \n",
        "data = np.load(root_path)\n",
        "data.files"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_ratios', 'test_ratios', 'train_volumes', 'test_volumes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIcj78GVk8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratios = data['train_ratios']\n",
        "test_ratios = data['test_ratios']\n",
        "train_vols = data['train_volumes']\n",
        "test_vols = data['test_volumes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyk_YlK6VrE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "av_vols = np.mean(train_vols[3], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKkWxWhOkne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0e7b75fa-3854-4246-b6f6-c4ba32d18ca5"
      },
      "source": [
        "plt.plot(av_vols)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff571ed5cc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4XPV97/H3d0a7ZFmSLS9IBhtw\nAOOw2AacJmkIEDBJGpOEpFAS3JQnZCE3pDdtCu3t5WahTZo2NDSBlgAJZHN4yIJvAnF8WRpowSBj\nAl4wFjbeF9mSJVvLaJbv/WN+ksdGtgbbaObIn9fzzKNzvud35vyOPdJ3fss5x9wdERGRfMQKXQER\nEYkOJQ0REcmbkoaIiORNSUNERPKmpCEiInlT0hARkbwpaYiISN6UNEREJG9KGiIikreSQlfgWBs/\nfrxPnTq10NUQEYmUZcuW7XL3xuHKjbqkMXXqVFpaWgpdDRGRSDGzDfmUU/eUiIjkTUlDRETypqQh\nIiJ5U9IQEZG8KWmIiEjelDRERCRvShoiIpK3YZOGmd1rZjvNbMUQ275oZm5m48O6mdntZtZqZi+a\n2aycsgvMbG14LciJzzazl8I+t5uZhXiDmS0J5ZeYWf2xOWURkdFlW2cv//K7Nazf1f2mHyuflsYP\ngHkHB81sCnApsDEnfDkwPbyuB+4MZRuAW4ALgPOBW3KSwJ3AJ3P2GzjWTcCj7j4deDSsi4jIQbZ0\n9PJvj7Wyqb3nTT/WsEnD3X8PtA+x6TbgS4DnxOYD93vWM0CdmU0GLgOWuHu7u3cAS4B5YVutuz/j\n7g7cD1yR8173heX7cuIiIpIjkcoAUFEaf9OPdURjGmY2H9ji7n84aFMTsClnfXOIHS6+eYg4wER3\n3xaWtwMTj6SuIiKjXSKVBqC85M0fpn7D954ysyrgb8l2TY0Id3cz80NtN7PryXaHceKJJ45UtURE\nikIimW1plJe++UnjSI5wCjAN+IOZvQY0A8+b2SRgCzAlp2xziB0u3jxEHGBH6L4i/Nx5qAq5+13u\nPsfd5zQ2DnuTRhGRUWWge6q8pAi7p9z9JXef4O5T3X0q2S6lWe6+HVgEXBtmUc0FOkMX02LgUjOr\nDwPglwKLw7YuM5sbZk1dCzwUDrUIGJhltSAnLiIiOUayeyqfKbc/BZ4GTjOzzWZ23WGKPwysA1qB\n7wGfBXD3duCrwHPh9ZUQI5S5O+zzKvBIiH8deI+ZrQUuCesiInKQvoHuqWIY03D3q4fZPjVn2YEb\nDlHuXuDeIeItwMwh4ruBi4ern4jI8W6wpVGss6dERKR4JEawpaGkISIScYlUhphBScze9GMpaYiI\nRFwilaaiNE64C9ObSklDRCTiEqnMiHRNgZKGiEjkJZKZEblGA5Q0REQiL5FKj8jV4KCkISISeX1J\ndU+JiEieEqm0uqdERCQ/GggXEZG8JVIZjWmIiEh+1D0lIiJ5SyQzVKilISIi+ciOaailISIiech2\nT6mlISIiedDsKRERyVtfMj0iz9IAJQ0RkUhzd7U0REQkP8m04z4yD2ACJQ0RkUgbfNRrscyeMrN7\nzWynma3IiX3TzF42sxfN7JdmVpez7WYzazWzNWZ2WU58Xoi1mtlNOfFpZrY0xH9mZmUhXh7WW8P2\nqcfqpEVERotEKvuo12K6TuMHwLyDYkuAme5+FvAKcDOAmc0ArgLODPvcYWZxM4sD3wUuB2YAV4ey\nAN8AbnP3U4EO4LoQvw7oCPHbQjkREckxkDSKpqXh7r8H2g+K/c7dU2H1GaA5LM8HFrp7wt3XA63A\n+eHV6u7r3L0fWAjMt+yzCS8CHgz73wdckfNe94XlB4GLbSSeZSgiEiGJZOieKqKWxnD+AngkLDcB\nm3K2bQ6xQ8XHAXtyEtBA/ID3Cts7Q3kREQn2tzQikDTM7O+AFPDjY1OdI67H9WbWYmYtbW1thayK\niMiIKrruqUMxsz8H3g9c4+4ewluAKTnFmkPsUPHdQJ2ZlRwUP+C9wvaxofzruPtd7j7H3ec0NjYe\n6SmJiERO30D3VDG3NMxsHvAl4APu3pOzaRFwVZj5NA2YDjwLPAdMDzOlysgOli8KyeZx4Mqw/wLg\noZz3WhCWrwQey0lOIiJCTktjhMY0SoYrYGY/BS4ExpvZZuAWsrOlyoElYWz6GXf/tLuvNLMHgFVk\nu61ucPd0eJ/PAYuBOHCvu68Mh/gbYKGZfQ1YDtwT4vcAPzSzVrID8Vcdg/MVERlVBgfCR6h7atik\n4e5XDxG+Z4jYQPlbgVuHiD8MPDxEfB3Z2VUHx/uAjwxXPxGR41mkBsJFRKSw9l/cV+QD4SIiUnj7\nbyOiloaIiAwjkYzIlFsRESm8kZ49paQhIhJhA91TZXElDRERGUZfMkNZPEYsNjK35lPSEBGJsEQq\nPWKD4KCkISISaYlUZsTGM0BJQ0Qk0hLJzIjNnAIlDRGRSEuk0mppiIhIfhIptTRERCRP2aShloaI\niOQhkdTsKRERyVNfKkP5CN2sEJQ0REQiTS0NERHJW7/GNEREJF+aPSUiInlLpNJU6DoNERHJR9Fd\nEW5m95rZTjNbkRNrMLMlZrY2/KwPcTOz282s1cxeNLNZOfssCOXXmtmCnPhsM3sp7HO7mdnhjiEi\nIvsV472nfgDMOyh2E/Cou08HHg3rAJcD08PreuBOyCYA4BbgAuB84JacJHAn8Mmc/eYNcwwREQEy\nGac/XWQD4e7+e6D9oPB84L6wfB9wRU78fs96Bqgzs8nAZcASd2939w5gCTAvbKt192fc3YH7D3qv\noY4hIiJAf3pkH/UKRz6mMdHdt4Xl7cDEsNwEbMoptznEDhffPET8cMcQERGgL5l9al9RtTSGE1oI\nfgzqcsTHMLPrzazFzFra2trezKqIiBSNkX4+OBx50tgRupYIP3eG+BZgSk655hA7XLx5iPjhjvE6\n7n6Xu89x9zmNjY1HeEoiItGSSEane2oRMDADagHwUE782jCLai7QGbqYFgOXmll9GAC/FFgctnWZ\n2dwwa+rag95rqGOIiAjZazRgZLunSoYrYGY/BS4ExpvZZrKzoL4OPGBm1wEbgI+G4g8D7wVagR7g\nEwDu3m5mXwWeC+W+4u4Dg+ufJTtDqxJ4JLw4zDFERIT93VMVI3jDwmGThrtffYhNFw9R1oEbDvE+\n9wL3DhFvAWYOEd891DFERCSrEC0NXREuIhJR+8c0lDRERGQY+2dPFf9AuIiIFJi6p0REJG996p4S\nEZF8DbY01D0lIiLDGRzTUEtDRESGMzB7aiSv01DSEBGJKA2Ei4hI3hKpDDGDkpiN2DGVNEREIiqR\nyj7qNTzwdEQoaYiIRFQimR7R26KDkoaISGRlWxpKGiIikoe+ZHpEn6UBShoiIpGlloaIiOQtkcpo\nTENERPKTSKWpUPeUiIjkI5FUS0NERPI0cJ3GSFLSEBGJqEQqHa2BcDP7SzNbaWYrzOynZlZhZtPM\nbKmZtZrZz8ysLJQtD+utYfvUnPe5OcTXmNllOfF5IdZqZjcdTV1FREabSM2eMrMm4PPAHHefCcSB\nq4BvALe5+6lAB3Bd2OU6oCPEbwvlMLMZYb8zgXnAHWYWN7M48F3gcmAGcHUoKyIihDGNiHVPlQCV\nZlYCVAHbgIuAB8P2+4ArwvL8sE7YfrFlb5gyH1jo7gl3Xw+0AueHV6u7r3P3fmBhKCsiIkBfKkK3\nEXH3LcA/AxvJJotOYBmwx91TodhmoCksNwGbwr6pUH5cbvygfQ4VFxERBloaEUkaZlZP9pv/NOAE\noJps99KIM7PrzazFzFra2toKUQURkRHl7mEgPDrdU5cA6929zd2TwC+AtwN1obsKoBnYEpa3AFMA\nwvaxwO7c+EH7HCr+Ou5+l7vPcfc5jY2NR3FKIiLRkMo4GYeKqHRPke2WmmtmVWFs4mJgFfA4cGUo\nswB4KCwvCuuE7Y+5u4f4VWF21TRgOvAs8BwwPczGKiM7WL7oKOorIjJq7H8++Mi2NEqGLzI0d19q\nZg8CzwMpYDlwF/AbYKGZfS3E7gm73AP80MxagXaySQB3X2lmD5BNOCngBndPA5jZ54DFZGdm3evu\nK4+0viIio0kiGR71OsItjSNOGgDufgtwy0HhdWRnPh1ctg/4yCHe51bg1iHiDwMPH00dRURGo/0t\njeh0T4mISIEUqntKSUNEJIL6Brqn1NIQEZHhDLY0IjR7SkRECmRwIFzdUyIiMpyBlkaUrtMQEZEC\n0UC4iIjkLZHSQLiIiOQpkVRLQ0RE8qTZUyIikjd1T4mISN761D0lIiL5GmhplKmlISIiw0mkMpTG\njXjMRvS4ShoiIhGUSGaoGOGuKVDSEBGJpEQqPeIzp0BJQ0QkkhKpzIgPgoOShohIJGWThloaIiKS\nh0QyPeIzp0BJQ0QkkhKpDOWl6p4SEZE89CXT0eueMrM6M3vQzF42s9Vm9jYzazCzJWa2NvysD2XN\nzG43s1Yze9HMZuW8z4JQfq2ZLciJzzazl8I+t5vZyE5IFhEpUlEd0/g28Ft3Px04G1gN3AQ86u7T\ngUfDOsDlwPTwuh64E8DMGoBbgAuA84FbBhJNKPPJnP3mHWV9RURGhcjNnjKzscAfA/cAuHu/u+8B\n5gP3hWL3AVeE5fnA/Z71DFBnZpOBy4Al7t7u7h3AEmBe2Fbr7s+4uwP357yXiMhxLZFKj/hT++Do\nWhrTgDbg+2a23MzuNrNqYKK7bwtltgMTw3ITsCln/80hdrj45iHir2Nm15tZi5m1tLW1HcUpiYhE\nQyIZsZYGUALMAu5093OBbvZ3RQEQWgh+FMfIi7vf5e5z3H1OY2Pjm304EZGCy86eilZLYzOw2d2X\nhvUHySaRHaFrifBzZ9i+BZiSs39ziB0u3jxEXETkuJdIRWz2lLtvBzaZ2WkhdDGwClgEDMyAWgA8\nFJYXAdeGWVRzgc7QjbUYuNTM6sMA+KXA4rCty8zmhllT1+a8l4jIca1QA+ElR7n//wB+bGZlwDrg\nE2QT0QNmdh2wAfhoKPsw8F6gFegJZXH3djP7KvBcKPcVd28Py58FfgBUAo+El4jIcc3d6S/QlNuj\nShru/gIwZ4hNFw9R1oEbDvE+9wL3DhFvAWYeTR1FREabQj0fHHRFuIhI5CQK9KhXUNIQEYmcgUe9\nRu06DRERKYDB7im1NEREZDgDLY1ITbkVEZHC6Bsc01DSEBGRYeyfPaXuKRERGYa6p0REJG8JdU+J\niEi+9rc01D0lIiLD0BXhIiKSt4HuqQoNhIuIyHA0EC4iInnbf0W4koaIiAxDtxEREZG8JZJpzKA0\nbiN+bCUNEZGISYQHMGUfajqylDRERCKmL5kuSNcUKGmIiEROokCPegUlDRGRyEmkMgW5RgOOQdIw\ns7iZLTezX4f1aWa21MxazexnZlYW4uVhvTVsn5rzHjeH+BozuywnPi/EWs3spqOtq4jIaJBIpSPd\n0rgRWJ2z/g3gNnc/FegArgvx64COEL8tlMPMZgBXAWcC84A7QiKKA98FLgdmAFeHsiIix7VEMlOQ\nW4jAUSYNM2sG3gfcHdYNuAh4MBS5D7giLM8P64TtF4fy84GF7p5w9/VAK3B+eLW6+zp37wcWhrIi\nIse17JhGNLun/hX4EpAJ6+OAPe6eCuubgaaw3ARsAgjbO0P5wfhB+xwqLiJyXItk95SZvR/Y6e7L\njmF9jrQu15tZi5m1tLW1Fbo6IiJvqqjOnno78AEze41s19FFwLeBOjMrCWWagS1heQswBSBsHwvs\nzo0ftM+h4q/j7ne5+xx3n9PY2HgUpyQiUvwSyQh2T7n7ze7e7O5TyQ5kP+bu1wCPA1eGYguAh8Ly\norBO2P6Yu3uIXxVmV00DpgPPAs8B08NsrLJwjEVHWl8RkdGiL5Uu2EB4yfBF3rC/ARaa2deA5cA9\nIX4P8EMzawXaySYB3H2lmT0ArAJSwA3ungYws88Bi4E4cK+7r3wT6isiEinZlkaEk4a7PwE8EZbX\nkZ35dHCZPuAjh9j/VuDWIeIPAw8fizqKiIwWiVQ6uhf3iYjIyIrqQLiIiBRAlK/TEBGREZRKZ0hn\nXC0NEREZ3t6+7LXTGtMQEZFhPftaOwBvbR5bkOMraYiIRMhTa3dRVRZn1on1BTm+koaISIQ81bqL\nuSePo0xjGiIicjib2ntYv6ubd5w6vmB1UNIQEYmIp1p3AfDO6UoaRWFfIjV8IRGRAnlybRuTais4\ndUJNweqgpBH8n0Ured/tT5K9h6KISHFJZ5z/at3NO6aPJ/v8usJQ0ghmNo1lw+4eWjZ0FLoqIiKv\n89KWTjp7kwXtmgIljUGXz5xEVVmcny/bXOiqiIi8zlNrsw+Ye3sBB8FBSWNQdXkJ82ZO4jcvbqMv\nmS50dUREDvDk2l2ceUIt42vKC1oPJY0cV85uZm8ixeKV2wtdFRGRQd2JFM9v7OAdBe6aAiWNA8yd\nNo6mukp+/vyQT5UVESmIpet3k0w7fzy98I+zVtLIEYsZH5rVxFNr29jR1Vfo6oiIAPD7V3ZRXhJj\n9kmFuXVILiWNg3xoVjMZh18uV2tDRIrDU627uODkcQW7s20uJY2DTBtfzeyT6vn5ss26ZkNECm5b\nZy+tO/fxzgLPmhpwxEnDzKaY2eNmtsrMVprZjSHeYGZLzGxt+Fkf4mZmt5tZq5m9aGazct5rQSi/\n1swW5MRnm9lLYZ/bbYSuaPnwrGbW7tzHi5s7R+JwIiKH9OTacOuQt0Q8aQAp4IvuPgOYC9xgZjOA\nm4BH3X068GhYB7gcmB5e1wN3QjbJALcAFwDnA7cMJJpQ5pM5+807ivrm7X1nTaa8JMbPn9c1GyJS\nWE+u3UXjmHJOmzim0FUBjiJpuPs2d38+LO8FVgNNwHzgvlDsPuCKsDwfuN+zngHqzGwycBmwxN3b\n3b0DWALMC9tq3f0Zz/YT3Z/zXm+qsZWlXHrmJBb9YSuJlK7ZEJHC2NuX5Ik1O3lngW8dkuuYjGmY\n2VTgXGApMNHdt4VN24GJYbkJ2JSz2+YQO1x88xDxEfHhWU3s6Uny+Ms7R+qQIiIH+PHSjeztS/Hn\nfzS10FUZdNRJw8xqgJ8DX3D3rtxtoYXwpo8mm9n1ZtZiZi1tbW3H5D3fOb2RCWPK+f5/vUYmowFx\nERlZfck0dz+5nndOH89ZzXWFrs6go0oaZlZKNmH82N1/EcI7QtcS4efAV/UtwJSc3ZtD7HDx5iHi\nr+Pud7n7HHef09h4bC5+iceMGy+ZztL17XzvyXXH5D1FRPL1QMsmdu1LcMO7Ty10VQ5wNLOnDLgH\nWO3u38rZtAgYmAG1AHgoJ35tmEU1F+gM3ViLgUvNrD4MgF8KLA7busxsbjjWtTnvNSL+7PwTuXzm\nJL65eA3Pb9Tdb0VkZCTTGf7jP9cx56R6LpjWUOjqHOBoWhpvBz4OXGRmL4TXe4GvA+8xs7XAJWEd\n4GFgHdAKfA/4LIC7twNfBZ4Lr6+EGKHM3WGfV4FHjqK+b5iZ8fUPn8WksRV8/qfL6exNjuThReQ4\n9avlW9iyp5cb3n1q0QyAD7DRdgHbnDlzvKWl5Zi+5/KNHXzk35/mPTMmcsc1s4ruP1FERo90xnnP\nt/6TitI4v/n8O0bs742ZLXP3OcOV0xXheTj3xHr++rLTeGTFdn60dGOhqyMio9hvV2xn3a7uomxl\ngJJG3j75zpO58LRGvvrrVaza2jX8DiJDcHe+sHA59z/9WqGrIkXI3fnO462c3FjNvJmTCl2dISlp\n5CkWM/7lI2dTX1XKp3+0jD09/YWukkRQ6859/OqFrfzvh1byz4vX6P5mcoAn1rSxelsXn3nXKcRj\nxdfKACWNN2RcTTl3fmw22zv7+NxPlpNKZwpdJYmYp9ftBuCyMyfyncdb+V+/WkFa1wEd93r6U3z3\n8VY+v3A5TXWVXHHuiF3H/IYpabxBs06s52sfnMlTrbv4x0deLnR1JGKefnU3TXWV/PvHZvOZC0/h\nx0s3cuPC5fSn9AXkeJRMZ/jRMxt41zef4JuL13DBtHHcf935lMaL909zSaErEEUfnTOFVVu7uOep\n9cyYXMuHZzcPv5Mc9zIZ55l1u7no9ImYGX8z73TqKkv5x0depqsvxX98bDaVZYV/XoKMjCfW7OTL\n/3cV63d1c97Ueu68ZhZzphbXNRlDUdI4Qn/3vjN4Zcdebv7lS5wyoYZzphx4mb+7F+XMBymcNTv2\n0tGT5G2njBuMfepdp1BXVcrNv3iJz/3kef7j47MpKeJvmXL0+pJpvv7Iy/zgv1/j1Ak13LNgDhed\nPiEyfy+UNI5QaTzGd/5sFh/4zlN86octXD5zMts6e9nW2cfWPX109SZ5+6njmH9OE++ZMZHqcv1T\nH++efjU7npGbNAD+9LwT6U87f/+rFfz9Qyv4hw++NTJ/QOSNWb2tixsXLueVHfu47h3T+OvLTiuK\np/G9EfpLdhQaqsv43rVz+Pg9z/Lgss1MHlvB5LpKZkyupbwkxpJVO/jCz16gojTGJWdM5MOzm7nw\nLY36g3Ccenrdbk5sqKKprvJ12z4+9yS27enljideZfLYSj5/8fQC1FCOlZ7+FN2JNMl0ZvD1xJo2\n/um3axhbVcp9f3E+73rLsblP3khT0jhKZ0yu5dm/vZjYENPjbvmTM1m2sYOHXtjCb17cxq9f3Ma8\nMydx6wdnMq6mvAC1lUJJh/GM986cfMgyf33ZaWzv6uNbS15hUm0FHz1vyiHLSnHasqeXb/+/V3hw\n2WaGmhR3yRkT+caH3xrp338ljWNgqIQxED9vagPnTW3glj85k3ufWs+//O4VLr3t9/zDh97KZWcW\n58U7cuyt2trF3r7U67qmcpkZX//QWbTtTXDzL1+isbacd582YQRrKUdq974EdzzxKj98egOQbTme\nOnEMZXGjNB6jNB5jXHUZbztlXOR7GpQ0RkhpPMan3nUKF542gf/5wAt86ofL+NCsJm6+/AziMaM3\nmaa3P01fMk1ZSYzxNeXUVZYeMiFJtDy9Lvuc58MlDYCykhh3fmw2H/33p/nMj5bxp3OmcNX5J3LG\n5NqRqKbkIZ1xdu7tY3NHL5vae3h5+15+snQjPf0prpzdzI2XvGXILsjRQjcsLID+VIbvPLaW7z7x\n6mEv7CqJGeNqyhhfU870CTWcPaWOc6bUMeOEWspLojV4drz7xPefZcPuHh77qwvzKr9zbx+3/mY1\nj7y0nf50hrOn1HH1eVO48LQJ7Nzbx6b2XjZ19LCxvYe+ZJrxNeWMryljXHU542rKmHFCLRPGVLy5\nJxUBfck0rTv3UV1ewviaMmrKS/L+pp/OOFv39PLy9r28vK2Ll3dkf25s7yGZ3v97awbzzpzEFy99\nC6dOKI7neB+JfG9YqKRRQCu2dPJU6y4qS+NUlsapKItTURKjP52hbW+CXfsStO1NsHNvgtXbutjR\nlQCgNG6cPqmWspLYYOukL5kmkcoQixll8RglcaMkZoypKOWcKXXMOqme2SfVc8LYikP+0mQyTl8q\nTV8yQyKVpr6qLHIzO4pRKp3hnK8s4QPnnMA/fPCtb2jfju5+frF8Cwuf3cjanftet72+qpTK0ji7\nuvsPuEDQDM6f2sD7zz6BeWdOonHM/j70RCrNpvYeNnf0UlVWQkN1GeOqyxg7Clq2bXsTLNvQwbIN\n7bRs6GDFls4D/sCXl8RoHFNOfVUZMcs+VnTgT2Aq43QnUvT0p9iXSNGXPPCCyxMbqjht0hhOaayh\nub6SKQ1VTKmv5IS6ylHxe6KkMQpt6+zlhY17eGHTHlZu7cLxbLIJSaesJEbGnWTaSaYzpNLOrn0J\nXtzcSW8yDcDE2nJOGldNXzJNT3+ankSK7v40vcn0kFclN9VVcnJjNdPGV3PSuGrSmQx7+1Ls7UvR\n1ZckmXbe2lTL3JPHMWNy7SGvMUilM2zvyjbps68eOnuTpNJOKpMhmfbB27LEYkbMjJhBSTzGpNoK\nThpXxZSGKk5qqKKuqowNu7sHvwGu3r6Xju5+zp5Sx3lT65kztYHxYaAxk3E2tPewelsXq7d1kXFn\nSn0VJzZk32/y2AriMSOZ9sEuwmQ6w8TaCspK3tj1Env7kpSXxF+33/KNHXzwjv/m364+lz85+4Q3\n9J4D3J3nN3bw0uZOJtdVMqW+iikNlYypKB3c3t2fZve+7JeM/2rdxa9f3Ebrzn3EDM6f1kBpPMb6\nXd1s3dM75CBtPGbUVZYypqKEmooSasqzr9qKUsbVlDGuppzxNdmWzPjqcuqrSxlXXX7ABYnu2X/H\n9u5+9vQkiceMqrI4VWUlVJfHqQgt5FTGybiTyjgxg6qy/HrK3Z2+ZIauviSdvUnWtXWzcmsnK7d2\nsXJr5+AXq7KSGGc1jWX21HrOaqojkUqza1+CXfv6aduboCPn3nFGdjwpZkZNeZyqcN5VZXEax5Rz\n+qRaTps0hppRPm1eSUMGpdIZXt6+l+c3dtDyWgfbO/uoKo8P/jJXlcX3J5/Q2ikvjdO2N8G6tn2s\n29XNurZu9iVSQPZb7MAfE8jOGIFs7Lyp9Zw2qZbO3uwv58Br594EqcyBTfqaspJsiygeozRmgwkn\n404m42Q8e5uF3d0H3hwyZgz+0YsZnNxYw9jKUlZs6SQREt/J46upqyplzfa9dPdnE+bADeByuwSH\nikG2NXdKYw1nTK7ljMljmD5hDNXlJZSXxCgriVFeEqOnP80Lm/bwh03ZRN7ato8JY8p58NN/xJSG\nqsH3uuOJVv7pt2t47u8uOeAb/5vN3Xllxz5+8+JWfrdqB+UlMaaG5D9tfBXN9VX09qfp6Oln975+\n2rv7ae/ppzuRYl9fir3hZ2dvkt3didd98x5QWRqnobqMjDvt3f2D/wdvxJiKEprqKmmqy35zH1NR\nQkdPkvbuBB3d2eN39ibp6k3Rf9A93+Ix49TGGs48oZYZJ9Ry7ol1zGwaqy7cN0hJQ44pd6ejJ0lp\n3KguKzmgG2NHVx9L17ezdN1unlm3m9d299BQXUZjTTmNY7KvibXlTKnP/qGa0lDJ5LGVeX+T70tm\nu1M27M724e/al2Da+GrOmFzLqRNqBrsGEqk0K7Z00fJaO8+91k5XX4oZk2uZMbmWMybXMn1iDSUx\nY1tnH5vae9jU0cOm9t7BFlt+sqw7AAAGJElEQVRlWQmVpXFK4sb6Xd3ZVsy2vWzv6jts/Rqqyzi7\neSwzm8Zy/9MbqK8q5cHP/NFga+fj9yxlR1cfv/vLdx3hv37huTs9/Wl27+tnV3ciJJkEu7v7aQ8J\nJx4zGqrLqK8uo6GqjLFVpdkWUCJNT38q27LtTxMzIx6DeCxGPJZtdezo7GPLnj627ulla2cve/tS\n1FeV0lBdNviqq8p2odVWlFJbWcKYilJObKji9EljRkX3UKEpaUjBjLZbqHR097NuV3cYN8p24yVS\nGUrjMd7aNJbm+srB8122oYNr7n6G6RPG8NPr51IWj3H2l3/HR+c08+X5Mwt8JtEx2j5DUZBv0hjd\nnXRSEKPtl72+uozZ1WV5lZ19Uj13XDOLT96/jE//cBmfffcp9CbTw061lQONts/QaFL0d0Yzs3lm\ntsbMWs3spkLXR2Q4F50+kW98+Cyeat3F536yHDO4YJqShowORZ00zCwOfBe4HJgBXG1mMwpbK5Hh\nXTm7mZsuP5327n5On1RLfZ4tFZFiV+zdU+cDre6+DsDMFgLzgVUFrZVIHj71xyczpqKE5vqq4QuL\nRESxJ40mYFPO+mbgggLVReQNMTOuueCkQldD5Jgq6u6pfJnZ9WbWYmYtbW1tha6OiMioVexJYwuQ\ne3/o5hA7gLvf5e5z3H1OY2M071EvIhIFxZ40ngOmm9k0MysDrgIWFbhOIiLHraIe03D3lJl9DlgM\nxIF73X1lgaslInLcKuqkAeDuDwMPF7oeIiJS/N1TIiJSRJQ0REQkb0oaIiKSt1F3l1szawM2HOHu\n44Fdx7A6Iy3q9Yfon4PqX3hRP4dC1f8kdx/2moVRlzSOhpm15HNr4GIV9fpD9M9B9S+8qJ9Dsddf\n3VMiIpI3JQ0REcmbksaB7ip0BY5S1OsP0T8H1b/won4ORV1/jWmIiEje1NIQEZG8KWkEUXusrJnd\na2Y7zWxFTqzBzJaY2drws76QdTwcM5tiZo+b2SozW2lmN4Z4lM6hwsyeNbM/hHP4cohPM7Ol4bP0\ns3CzzaJlZnEzW25mvw7rkam/mb1mZi+Z2Qtm1hJiUfoM1ZnZg2b2spmtNrO3FXv9lTSI7GNlfwDM\nOyh2E/Cou08HHg3rxSoFfNHdZwBzgRvCv3mUziEBXOTuZwPnAPPMbC7wDeA2dz8V6ACuK2Ad83Ej\nsDpnPWr1f7e7n5MzTTVKn6FvA79199OBs8n+PxR3/d39uH8BbwMW56zfDNxc6HrlUe+pwIqc9TXA\n5LA8GVhT6Dq+gXN5CHhPVM8BqAKeJ/tkyV1ASYgf8NkqthfZZ9Q8ClwE/BqwiNX/NWD8QbFIfIaA\nscB6wthyVOqvlkbWUI+VbSpQXY7GRHffFpa3AxMLWZl8mdlU4FxgKRE7h9C18wKwE1gCvArscfdU\nKFLsn6V/Bb4EZML6OKJVfwd+Z2bLzOz6EIvKZ2ga0AZ8P3QP3m1m1RR5/ZU0RinPfk0p+qlxZlYD\n/Bz4grt35W6Lwjm4e9rdzyH7jf184PQCVylvZvZ+YKe7Lyt0XY7CO9x9Ftmu5RvM7I9zNxb5Z6gE\nmAXc6e7nAt0c1BVVjPVX0sjK67GyEbDDzCYDhJ87C1yfwzKzUrIJ48fu/osQjtQ5DHD3PcDjZLtz\n6sxs4Fk1xfxZejvwATN7DVhItovq20Sn/rj7lvBzJ/BLsok7Kp+hzcBmd18a1h8km0SKuv5KGlmj\n5bGyi4AFYXkB2XGComRmBtwDrHb3b+VsitI5NJpZXViuJDsms5ps8rgyFCvac3D3m9292d2nkv3M\nP+bu1xCR+ptZtZmNGVgGLgVWEJHPkLtvBzaZ2WkhdDGwiiKvvy7uC8zsvWT7dwceK3trgat0WGb2\nU+BCsnfE3AHcAvwKeAA4keydfj/q7u2FquPhmNk7gCeBl9jfn/63ZMc1onIOZwH3kf3MxIAH3P0r\nZnYy2W/uDcBy4GPunihcTYdnZhcCf+Xu749K/UM9fxlWS4CfuPutZjaO6HyGzgHuBsqAdcAnCJ8l\nirT+ShoiIpI3dU+JiEjelDRERCRvShoiIpI3JQ0REcmbkoaIiORNSUNERPKmpCEiInlT0hARkbz9\nfzb9l0IoD6a0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2J6fvWqn8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create covariates - currently one hot vector 64 dims but experiment with different ideas \n",
        "def create_covariate_data(input_data, freq = 64): #this is assuming that data starts at beginning of day and ends at last bin of the day \n",
        "  num_series, len_series = input_data.shape\n",
        "  days = int(len_series/freq)\n",
        "  covariate_vectors = np.zeros((num_series, len_series, freq+1))\n",
        "  \n",
        "  for n in range(num_series):\n",
        "    for d in range(days): \n",
        "      for t in range(freq): \n",
        "        one_hot = np.zeros(freq)\n",
        "        one_hot[t] = 1\n",
        "        covariate_vectors[n, d*64 + t, 0] = input_data[n, d*64 + t]\n",
        "        covariate_vectors[n, d*64 + t, 1:] = one_hot\n",
        "        \n",
        "  return covariate_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMl5hXU41NDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_volume = train_vols[0:50].reshape((50,-1))\n",
        "\n",
        "norm_train_vols = np.zeros((50, 29568))\n",
        "for i in range(50): \n",
        "  norm_train_vols[i] = train_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "T = 64*3\n",
        "new_train_data = norm_train_vols[:,:T]\n",
        "\n",
        "covars_data = create_covariate_data(new_train_data)\n",
        "\n",
        "covars_data = torch.FloatTensor(covars_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1O5qrgbY_f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_volume = train_vols[50:100].reshape((50,-1))\n",
        "\n",
        "norm_test_vols = np.zeros((50, 29568))\n",
        "for i in range(50): \n",
        "  norm_test_vols[i] = test_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "T = 64*3\n",
        "new_test_data = norm_test_vols[:,:T]\n",
        "\n",
        "covars_test_data = create_covariate_data(new_test_data)\n",
        "\n",
        "covars_test_data = torch.FloatTensor(covars_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVqDKWpYzc9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalEffects(nn.Module): \n",
        "  def __init__(self, input_size, num_factors, hidden_size, batch_size = 1, output_size = 1, num_layers = 1): \n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_factors = num_factors\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.linears = nn.ModuleList([nn.Linear(self.hidden_size, self.output_size, bias = False) for i in range(self.num_factors)])\n",
        "    self.lstms = nn.ModuleList([nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers) for i in range(self.num_factors)])\n",
        "    \n",
        "    self.w = torch.nn.Parameter(torch.zeros(batch_size, num_factors))\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    hidden = [torch.zeros(self.num_layers, self.batch_size, self.hidden_size) for i in range(self.num_factors)]\n",
        "    return hidden\n",
        "    \n",
        "  def forward(self, input_data, hidden): \n",
        "    x = input_data[:,1:]\n",
        "    for i in range(self.num_factors): \n",
        "      lstm_out, hidden[i] = self.lstms[i](x.view(len(x), self.batch_size, -1))\n",
        "      g_i = self.linears[i](lstm_out).view(-1,1)\n",
        "      \n",
        "      if i == 0: \n",
        "        g = g_i\n",
        "      else:\n",
        "        g = torch.cat((g,g_i), dim=1)\n",
        "\n",
        "    fixed_effects = torch.zeros(g.shape[0])\n",
        "    for i in range(g.shape[0]): \n",
        "      fixed_effects[i] = torch.dot(self.w.view(-1), g[i])\n",
        "      \n",
        "    return fixed_effects\n",
        "     \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSSlj0dlw0pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DF_RNN(nn.Module): \n",
        "  def __init__(self, input_size, hidden_size, batch_size, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = 1)\n",
        "    self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
        "    \n",
        "  def init_hidden(self): \n",
        "      return torch.zeros(1, self.batch_size, self.hidden_size)\n",
        "    \n",
        "  def forward(self, input_data, hidden, fixed_effects, gaussian_likelihood): \n",
        "    z = input_data[:,0]\n",
        "    x = input_data[:,1:]\n",
        "    rnn_out, hidden = self.rnn(x.view(len(x), self.batch_size, -1))\n",
        "    sigma = self.linear(rnn_out).view(-1)\n",
        "    sigma = torch.abs(sigma)\n",
        "    r = torch.zeros(sigma.shape[0])\n",
        "    for i in range(sigma.shape[0]):\n",
        "      r[i] = torch.distributions.normal.Normal(0, sigma[i]).rsample()\n",
        "    u = fixed_effects + r\n",
        "    \n",
        "    if gaussian_likelihood == True: \n",
        "      log_lik = self.log_likelihood_Gaussian(z, fixed_effects, sigma)\n",
        "    \n",
        "    else: \n",
        "      log_lik = self.log_likelihood_nonGaussian()\n",
        "    \n",
        "    return log_lik\n",
        "   \n",
        "  def log_likelihood_Gaussian(self, z, f, sigma):\n",
        "    log_p = torch.zeros(len(z))\n",
        "    for i in range(len(z)): \n",
        "      log_pdf = torch.distributions.normal.Normal(0, sigma[i]).log_prob(z[i] - f[i])\n",
        "      #scale the likelihood to 0-1\n",
        "      log_norm_constant = torch.distributions.normal.Normal(0, sigma[i]).log_prob(0)\n",
        "      log_p[i] = log_pdf - log_norm_constant\n",
        "      \n",
        "    #set neg infinite values to -10 to avoid batch loss becoming infinite \n",
        "    log_p[log_p == -float(\"inf\")] = -10\n",
        "    \n",
        "    log_lik = torch.sum(log_p)\n",
        "\n",
        "    return log_lik\n",
        "  \n",
        "  \n",
        "  def log_likelihood_nonGaussian(self, ): #to do \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGd_qELTtqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0001\n",
        "batch_size = 50 #??????\n",
        "num_epochs = 200\n",
        "hidden_units_global = 50\n",
        "hidden_units_local = 5\n",
        "n_factors = 10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnaiB4RyWtVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_model = GlobalEffects(input_size = 64, num_factors = n_factors , hidden_size = hidden_units_global)  \n",
        "local_model = DF_RNN(64, hidden_size = hidden_units_local, batch_size = 1, output_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZumPtm7ZCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f874053-6add-4f08-eead-0a8e9b15680b"
      },
      "source": [
        "optimiser = torch.optim.SGD(list(global_model.parameters()) + list(local_model.parameters()), lr = learning_rate)\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for t in range(num_epochs): \n",
        "  global_model.zero_grad()\n",
        "  global_hidden = global_model.init_hidden()\n",
        "  \n",
        "  local_model.zero_grad()\n",
        "  local_hidden = local_model.init_hidden()\n",
        "  \n",
        "  data_batch = covars_data\n",
        "  \n",
        "  neg_batch_loss = 0 \n",
        "  fixed_effects = global_model(data_batch[0], global_hidden)\n",
        "  \n",
        "  for i in range(batch_size): \n",
        "    data = data_batch[i]\n",
        "    \n",
        "    #fixed_effects = global_model(data, global_hidden) # this could be taken out of the for loop as if we keep the same covariate structure for  every series then g will be the same for each TS\n",
        "    log_lik = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "    \n",
        "    neg_batch_loss += log_lik\n",
        "    \n",
        "  batch_loss = -1*neg_batch_loss\n",
        "    \n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "  batch_loss.backward()\n",
        "\n",
        "  optimiser.step()\n",
        "  \n",
        "  train_loss.append(batch_loss.item())\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    test_data_batch = covars_test_data\n",
        "    neg_test_batch_loss = 0\n",
        "    fixed_effects = global_model(test_data_batch[0], global_hidden)\n",
        "    \n",
        "    for i in range(batch_size): \n",
        "      data = test_data_batch[i]\n",
        "      log_lik = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "      neg_test_batch_loss += log_lik\n",
        "      \n",
        "    test_batch_loss = -1*neg_test_batch_loss\n",
        "      \n",
        "    test_loss.append(test_batch_loss.item())\n",
        "  \n",
        "  print(\"Epoch: \", t, \"loss: \", batch_loss.item(), \"test loss: \", test_batch_loss.item())"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 loss:  20.211185455322266 test loss:  555.57275390625\n",
            "Epoch:  1 loss:  18.09853744506836 test loss:  520.681884765625\n",
            "Epoch:  2 loss:  16.552371978759766 test loss:  492.9171142578125\n",
            "Epoch:  3 loss:  15.349940299987793 test loss:  469.98883056640625\n",
            "Epoch:  4 loss:  14.377050399780273 test loss:  450.5509338378906\n",
            "Epoch:  5 loss:  13.567485809326172 test loss:  433.7442321777344\n",
            "Epoch:  6 loss:  12.879396438598633 test loss:  418.9884948730469\n",
            "Epoch:  7 loss:  12.2850341796875 test loss:  405.8724060058594\n",
            "Epoch:  8 loss:  11.764684677124023 test loss:  394.0953369140625\n",
            "Epoch:  9 loss:  11.304254531860352 test loss:  383.4305114746094\n",
            "Epoch:  10 loss:  10.893139839172363 test loss:  373.7029113769531\n",
            "Epoch:  11 loss:  10.523167610168457 test loss:  364.77490234375\n",
            "Epoch:  12 loss:  10.188117980957031 test loss:  356.53619384765625\n",
            "Epoch:  13 loss:  9.882806777954102 test loss:  348.897216796875\n",
            "Epoch:  14 loss:  9.60323429107666 test loss:  341.7844543457031\n",
            "Epoch:  15 loss:  9.346062660217285 test loss:  335.13677978515625\n",
            "Epoch:  16 loss:  9.108511924743652 test loss:  328.9024658203125\n",
            "Epoch:  17 loss:  8.888306617736816 test loss:  323.03814697265625\n",
            "Epoch:  18 loss:  8.683527946472168 test loss:  317.50628662109375\n",
            "Epoch:  19 loss:  8.492444038391113 test loss:  312.2749328613281\n",
            "Epoch:  20 loss:  8.313645362854004 test loss:  307.31622314453125\n",
            "Epoch:  21 loss:  8.145944595336914 test loss:  302.60589599609375\n",
            "Epoch:  22 loss:  7.988293647766113 test loss:  298.12274169921875\n",
            "Epoch:  23 loss:  7.8397064208984375 test loss:  293.8479309082031\n",
            "Epoch:  24 loss:  7.699400901794434 test loss:  289.76507568359375\n",
            "Epoch:  25 loss:  7.5666728019714355 test loss:  285.8592834472656\n",
            "Epoch:  26 loss:  7.440812110900879 test loss:  282.1173095703125\n",
            "Epoch:  27 loss:  7.32138204574585 test loss:  278.52740478515625\n",
            "Epoch:  28 loss:  7.207693099975586 test loss:  275.07904052734375\n",
            "Epoch:  29 loss:  7.099461078643799 test loss:  271.7626647949219\n",
            "Epoch:  30 loss:  6.9962158203125 test loss:  268.5694580078125\n",
            "Epoch:  31 loss:  6.897555828094482 test loss:  265.4916076660156\n",
            "Epoch:  32 loss:  6.803218841552734 test loss:  262.5220642089844\n",
            "Epoch:  33 loss:  6.712849140167236 test loss:  259.65411376953125\n",
            "Epoch:  34 loss:  6.626180648803711 test loss:  256.8818664550781\n",
            "Epoch:  35 loss:  6.5429840087890625 test loss:  254.19969177246094\n",
            "Epoch:  36 loss:  6.462998867034912 test loss:  251.60287475585938\n",
            "Epoch:  37 loss:  6.386111736297607 test loss:  249.0864715576172\n",
            "Epoch:  38 loss:  6.311982154846191 test loss:  246.6462860107422\n",
            "Epoch:  39 loss:  6.240603923797607 test loss:  244.27833557128906\n",
            "Epoch:  40 loss:  6.171709060668945 test loss:  241.97906494140625\n",
            "Epoch:  41 loss:  6.1051506996154785 test loss:  239.74484252929688\n",
            "Epoch:  42 loss:  6.040867805480957 test loss:  237.5725860595703\n",
            "Epoch:  43 loss:  5.97861385345459 test loss:  235.45944213867188\n",
            "Epoch:  44 loss:  5.918407917022705 test loss:  233.40261840820312\n",
            "Epoch:  45 loss:  5.860057830810547 test loss:  231.39935302734375\n",
            "Epoch:  46 loss:  5.803474426269531 test loss:  229.44752502441406\n",
            "Epoch:  47 loss:  5.748581886291504 test loss:  227.5447235107422\n",
            "Epoch:  48 loss:  5.695324897766113 test loss:  225.68878173828125\n",
            "Epoch:  49 loss:  5.643499851226807 test loss:  223.87779235839844\n",
            "Epoch:  50 loss:  5.593207359313965 test loss:  222.1099395751953\n",
            "Epoch:  51 loss:  5.544276714324951 test loss:  220.38345336914062\n",
            "Epoch:  52 loss:  5.496619701385498 test loss:  218.69668579101562\n",
            "Epoch:  53 loss:  5.450254917144775 test loss:  217.04788208007812\n",
            "Epoch:  54 loss:  5.405014514923096 test loss:  215.43585205078125\n",
            "Epoch:  55 loss:  5.360994815826416 test loss:  213.859130859375\n",
            "Epoch:  56 loss:  5.318030834197998 test loss:  212.3162078857422\n",
            "Epoch:  57 loss:  5.276064872741699 test loss:  210.80601501464844\n",
            "Epoch:  58 loss:  5.2351579666137695 test loss:  209.32737731933594\n",
            "Epoch:  59 loss:  5.19514799118042 test loss:  207.879150390625\n",
            "Epoch:  60 loss:  5.156184673309326 test loss:  206.46014404296875\n",
            "Epoch:  61 loss:  5.117945671081543 test loss:  205.069580078125\n",
            "Epoch:  62 loss:  5.080661773681641 test loss:  203.7063446044922\n",
            "Epoch:  63 loss:  5.044127464294434 test loss:  202.3694305419922\n",
            "Epoch:  64 loss:  5.008395195007324 test loss:  201.05819702148438\n",
            "Epoch:  65 loss:  4.9734063148498535 test loss:  199.77174377441406\n",
            "Epoch:  66 loss:  4.939167022705078 test loss:  198.50909423828125\n",
            "Epoch:  67 loss:  4.905604362487793 test loss:  197.2697296142578\n",
            "Epoch:  68 loss:  4.872724533081055 test loss:  196.05279541015625\n",
            "Epoch:  69 loss:  4.840531349182129 test loss:  194.8575897216797\n",
            "Epoch:  70 loss:  4.808876991271973 test loss:  193.68350219726562\n",
            "Epoch:  71 loss:  4.777892112731934 test loss:  192.5299530029297\n",
            "Epoch:  72 loss:  4.747472286224365 test loss:  191.39617919921875\n",
            "Epoch:  73 loss:  4.717615127563477 test loss:  190.28175354003906\n",
            "Epoch:  74 loss:  4.688294410705566 test loss:  189.1861114501953\n",
            "Epoch:  75 loss:  4.659536361694336 test loss:  188.1086883544922\n",
            "Epoch:  76 loss:  4.631312847137451 test loss:  187.048828125\n",
            "Epoch:  77 loss:  4.603516101837158 test loss:  186.00625610351562\n",
            "Epoch:  78 loss:  4.576223850250244 test loss:  184.98037719726562\n",
            "Epoch:  79 loss:  4.549386501312256 test loss:  183.97076416015625\n",
            "Epoch:  80 loss:  4.523046493530273 test loss:  182.97706604003906\n",
            "Epoch:  81 loss:  4.497108459472656 test loss:  181.998779296875\n",
            "Epoch:  82 loss:  4.47162389755249 test loss:  181.0354766845703\n",
            "Epoch:  83 loss:  4.446585178375244 test loss:  180.08673095703125\n",
            "Epoch:  84 loss:  4.421856880187988 test loss:  179.15223693847656\n",
            "Epoch:  85 loss:  4.397526741027832 test loss:  178.2318115234375\n",
            "Epoch:  86 loss:  4.373711585998535 test loss:  177.32470703125\n",
            "Epoch:  87 loss:  4.350107669830322 test loss:  176.4309539794922\n",
            "Epoch:  88 loss:  4.326938152313232 test loss:  175.55003356933594\n",
            "Epoch:  89 loss:  4.304098606109619 test loss:  174.68170166015625\n",
            "Epoch:  90 loss:  4.281635284423828 test loss:  173.8256378173828\n",
            "Epoch:  91 loss:  4.259485721588135 test loss:  172.9815216064453\n",
            "Epoch:  92 loss:  4.237659454345703 test loss:  172.14903259277344\n",
            "Epoch:  93 loss:  4.216146945953369 test loss:  171.3280029296875\n",
            "Epoch:  94 loss:  4.194896697998047 test loss:  170.5182647705078\n",
            "Epoch:  95 loss:  4.174018383026123 test loss:  169.71926879882812\n",
            "Epoch:  96 loss:  4.153396129608154 test loss:  168.9310302734375\n",
            "Epoch:  97 loss:  4.133064270019531 test loss:  168.1531982421875\n",
            "Epoch:  98 loss:  4.113040447235107 test loss:  167.3854522705078\n",
            "Epoch:  99 loss:  4.093242168426514 test loss:  166.62771606445312\n",
            "Epoch:  100 loss:  4.073740005493164 test loss:  165.87979125976562\n",
            "Epoch:  101 loss:  4.054515361785889 test loss:  165.141357421875\n",
            "Epoch:  102 loss:  4.035547256469727 test loss:  164.41217041015625\n",
            "Epoch:  103 loss:  4.016714572906494 test loss:  163.6922149658203\n",
            "Epoch:  104 loss:  3.9982364177703857 test loss:  162.98114013671875\n",
            "Epoch:  105 loss:  3.9799692630767822 test loss:  162.2788848876953\n",
            "Epoch:  106 loss:  3.9619526863098145 test loss:  161.585205078125\n",
            "Epoch:  107 loss:  3.944182872772217 test loss:  160.89993286132812\n",
            "Epoch:  108 loss:  3.9265787601470947 test loss:  160.2227325439453\n",
            "Epoch:  109 loss:  3.9091804027557373 test loss:  159.5537872314453\n",
            "Epoch:  110 loss:  3.892054319381714 test loss:  158.89276123046875\n",
            "Epoch:  111 loss:  3.8751327991485596 test loss:  158.2393035888672\n",
            "Epoch:  112 loss:  3.8583736419677734 test loss:  157.5935516357422\n",
            "Epoch:  113 loss:  3.8418686389923096 test loss:  156.95521545410156\n",
            "Epoch:  114 loss:  3.8254849910736084 test loss:  156.3241424560547\n",
            "Epoch:  115 loss:  3.809333562850952 test loss:  155.70025634765625\n",
            "Epoch:  116 loss:  3.7933874130249023 test loss:  155.08346557617188\n",
            "Epoch:  117 loss:  3.7776074409484863 test loss:  154.4735107421875\n",
            "Epoch:  118 loss:  3.762040853500366 test loss:  153.8702850341797\n",
            "Epoch:  119 loss:  3.7466049194335938 test loss:  153.2737274169922\n",
            "Epoch:  120 loss:  3.731332778930664 test loss:  152.68373107910156\n",
            "Epoch:  121 loss:  3.7162926197052 test loss:  152.1000518798828\n",
            "Epoch:  122 loss:  3.7013602256774902 test loss:  151.52268981933594\n",
            "Epoch:  123 loss:  3.6866157054901123 test loss:  150.9514923095703\n",
            "Epoch:  124 loss:  3.6720473766326904 test loss:  150.38638305664062\n",
            "Epoch:  125 loss:  3.657578706741333 test loss:  149.82725524902344\n",
            "Epoch:  126 loss:  3.64337420463562 test loss:  149.2738494873047\n",
            "Epoch:  127 loss:  3.6292009353637695 test loss:  148.72625732421875\n",
            "Epoch:  128 loss:  3.6152849197387695 test loss:  148.18434143066406\n",
            "Epoch:  129 loss:  3.601433753967285 test loss:  147.64801025390625\n",
            "Epoch:  130 loss:  3.5878069400787354 test loss:  147.11700439453125\n",
            "Epoch:  131 loss:  3.574242115020752 test loss:  146.5914306640625\n",
            "Epoch:  132 loss:  3.5608410835266113 test loss:  146.07110595703125\n",
            "Epoch:  133 loss:  3.5475587844848633 test loss:  145.55599975585938\n",
            "Epoch:  134 loss:  3.534459352493286 test loss:  145.04595947265625\n",
            "Epoch:  135 loss:  3.5214548110961914 test loss:  144.54092407226562\n",
            "Epoch:  136 loss:  3.508618116378784 test loss:  144.0408935546875\n",
            "Epoch:  137 loss:  3.495889663696289 test loss:  143.54559326171875\n",
            "Epoch:  138 loss:  3.4832844734191895 test loss:  143.05514526367188\n",
            "Epoch:  139 loss:  3.4708168506622314 test loss:  142.56932067871094\n",
            "Epoch:  140 loss:  3.4584076404571533 test loss:  142.0882568359375\n",
            "Epoch:  141 loss:  3.4462461471557617 test loss:  141.61158752441406\n",
            "Epoch:  142 loss:  3.434047222137451 test loss:  141.1395721435547\n",
            "Epoch:  143 loss:  3.4221394062042236 test loss:  140.67178344726562\n",
            "Epoch:  144 loss:  3.410200834274292 test loss:  140.20834350585938\n",
            "Epoch:  145 loss:  3.3983893394470215 test loss:  139.74928283691406\n",
            "Epoch:  146 loss:  3.3867831230163574 test loss:  139.2943572998047\n",
            "Epoch:  147 loss:  3.375187635421753 test loss:  138.84365844726562\n",
            "Epoch:  148 loss:  3.363799810409546 test loss:  138.39686584472656\n",
            "Epoch:  149 loss:  3.352398633956909 test loss:  137.9542236328125\n",
            "Epoch:  150 loss:  3.3411965370178223 test loss:  137.5155487060547\n",
            "Epoch:  151 loss:  3.330078125 test loss:  137.0806884765625\n",
            "Epoch:  152 loss:  3.3190131187438965 test loss:  136.64967346191406\n",
            "Epoch:  153 loss:  3.30808162689209 test loss:  136.22242736816406\n",
            "Epoch:  154 loss:  3.2971928119659424 test loss:  135.7989501953125\n",
            "Epoch:  155 loss:  3.286426067352295 test loss:  135.37905883789062\n",
            "Epoch:  156 loss:  3.275707244873047 test loss:  134.96295166015625\n",
            "Epoch:  157 loss:  3.265263080596924 test loss:  134.55035400390625\n",
            "Epoch:  158 loss:  3.2548210620880127 test loss:  134.14114379882812\n",
            "Epoch:  159 loss:  3.2443673610687256 test loss:  133.73553466796875\n",
            "Epoch:  160 loss:  3.234128952026367 test loss:  133.33334350585938\n",
            "Epoch:  161 loss:  3.223978042602539 test loss:  132.93453979492188\n",
            "Epoch:  162 loss:  3.213869571685791 test loss:  132.53904724121094\n",
            "Epoch:  163 loss:  3.2038612365722656 test loss:  132.14669799804688\n",
            "Epoch:  164 loss:  3.193847179412842 test loss:  131.7577667236328\n",
            "Epoch:  165 loss:  3.184032440185547 test loss:  131.37191772460938\n",
            "Epoch:  166 loss:  3.174217700958252 test loss:  130.98924255371094\n",
            "Epoch:  167 loss:  3.1645545959472656 test loss:  130.6096954345703\n",
            "Epoch:  168 loss:  3.154912233352661 test loss:  130.23316955566406\n",
            "Epoch:  169 loss:  3.145359754562378 test loss:  129.8596954345703\n",
            "Epoch:  170 loss:  3.1359708309173584 test loss:  129.48922729492188\n",
            "Epoch:  171 loss:  3.126612901687622 test loss:  129.1216583251953\n",
            "Epoch:  172 loss:  3.1173338890075684 test loss:  128.75692749023438\n",
            "Epoch:  173 loss:  3.1080169677734375 test loss:  128.3951416015625\n",
            "Epoch:  174 loss:  3.09889817237854 test loss:  128.0362091064453\n",
            "Epoch:  175 loss:  3.089846611022949 test loss:  127.68002319335938\n",
            "Epoch:  176 loss:  3.0808420181274414 test loss:  127.32655334472656\n",
            "Epoch:  177 loss:  3.0718674659729004 test loss:  126.97589111328125\n",
            "Epoch:  178 loss:  3.0630414485931396 test loss:  126.62779998779297\n",
            "Epoch:  179 loss:  3.0541954040527344 test loss:  126.282470703125\n",
            "Epoch:  180 loss:  3.0454986095428467 test loss:  125.93966674804688\n",
            "Epoch:  181 loss:  3.0368776321411133 test loss:  125.59947204589844\n",
            "Epoch:  182 loss:  3.0282483100891113 test loss:  125.26183319091797\n",
            "Epoch:  183 loss:  3.01967716217041 test loss:  124.92669677734375\n",
            "Epoch:  184 loss:  3.011230230331421 test loss:  124.59402465820312\n",
            "Epoch:  185 loss:  3.002765655517578 test loss:  124.26385498046875\n",
            "Epoch:  186 loss:  2.9944658279418945 test loss:  123.93617248535156\n",
            "Epoch:  187 loss:  2.98625111579895 test loss:  123.61080932617188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-2b74ca5ef0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mlog_lik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m       \u001b[0mneg_test_batch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog_lik\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-5181c4a207aa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data, hidden, fixed_effects, gaussian_likelihood)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgaussian_likelihood\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mlog_lik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood_Gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-5181c4a207aa>\u001b[0m in \u001b[0;36mlog_likelihood_Gaussian\u001b[0;34m(self, z, f, sigma)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mlog_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0;31m#scale the likelihood to 0-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mlog_norm_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input arguments must all be instances of numbers.Number or torch.tensor.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input arguments must all be instances of numbers.Number or torch.tensor.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9111929b-657e-48eb-e7d2-94a841fbea72",
        "id": "ITTS-hEfXfqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(train_loss[1:])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff56e012978>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBiAyg9zksxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "bcf5edba-4649-43ec-c2a1-6ac81b26cea8"
      },
      "source": [
        "plt.plot(test_loss)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff56df732b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}