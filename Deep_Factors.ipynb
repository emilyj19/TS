{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Factors.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyj19/TS/blob/master/Deep_Factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxHpi6CjWlg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49c3c1f0-4f5f-428d-93a4-1c86c17101a7"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63MFgpVHUb5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_-DYtEUfH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7733b7c0-f995-4708-ca31-9814a078aa98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAw0rtMUhZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f63f88fd-3706-43ac-b38d-5e9f17c34fd6"
      },
      "source": [
        "root_path = 'gdrive/My Drive/FinancialTS/JPmarket_dataset.npz' \n",
        "data = np.load(root_path)\n",
        "data.files"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_ratios', 'test_ratios', 'train_volumes', 'test_volumes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIcj78GVk8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratios = data['train_ratios']\n",
        "test_ratios = data['test_ratios']\n",
        "train_vols = data['train_volumes']\n",
        "test_vols = data['test_volumes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyk_YlK6VrE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "av_vols = np.mean(train_vols[3], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKkWxWhOkne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b6a8a3bf-8356-4a40-968c-16c074756af7"
      },
      "source": [
        "plt.plot(av_vols)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa1964edc50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfzb9l0IoD6a0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2J6fvWqn8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create covariates - currently one hot vector 64 dims but experiment with different ideas \n",
        "def create_covariate_data(input_data, freq = 64): #this is assuming that data starts at beginning of day and ends at last bin of the day \n",
        "  num_series, len_series = input_data.shape\n",
        "  days = int(len_series/freq)\n",
        "  covariate_vectors = np.zeros((num_series, len_series, freq+1))\n",
        "  \n",
        "  for n in range(num_series):\n",
        "    for d in range(days): \n",
        "      for t in range(freq): \n",
        "        one_hot = np.zeros(freq)\n",
        "        one_hot[t] = 1\n",
        "        covariate_vectors[n, d*64 + t, 0] = input_data[n, d*64 + t]\n",
        "        covariate_vectors[n, d*64 + t, 1:] = one_hot\n",
        "        \n",
        "  return covariate_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2QboAB2rmn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22e243d8-2e35-4b69-fe19-a1b081ce5659"
      },
      "source": [
        "64*3"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMl5hXU41NDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_volume = train_vols[0:10].reshape((10,-1))\n",
        "\n",
        "norm_train_vols = np.zeros((10, 29568))\n",
        "for i in range(10): \n",
        "  norm_train_vols[i] = train_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "T = 64*3\n",
        "new_train_data = norm_train_vols[:,:T]\n",
        "\n",
        "covars_data = create_covariate_data(new_train_data)\n",
        "\n",
        "covars_data = torch.FloatTensor(covars_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBv4MeQbt9mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalEffects(nn.Module): \n",
        "  def __init__(self, input_size, num_factors, hidden_size = 1, batch_size = 1, output_size = 1, num_layers = 1): \n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.lstm1 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm2 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm3 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm4 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm5 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm6 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm7 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm8 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm9 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    self.lstm10 = nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers)\n",
        "    \n",
        "    self.w = torch.nn.Parameter(torch.zeros(batch_size, num_factors))\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "  def forward(self, input_data, hidden): \n",
        "    x = input_data[:,1:]\n",
        "    g1, hidden = self.lstm1(x.view(len(x), self.batch_size, -1))\n",
        "    g2, hidden = self.lstm2(x.view(len(x), self.batch_size, -1))\n",
        "    g3, hidden = self.lstm3(x.view(len(x), self.batch_size, -1))\n",
        "    g4, hidden = self.lstm4(x.view(len(x), self.batch_size, -1))\n",
        "    g5, hidden = self.lstm5(x.view(len(x), self.batch_size, -1))\n",
        "    g6, hidden = self.lstm6(x.view(len(x), self.batch_size, -1))\n",
        "    g7, hidden = self.lstm7(x.view(len(x), self.batch_size, -1))\n",
        "    g8, hidden = self.lstm8(x.view(len(x), self.batch_size, -1))\n",
        "    g9, hidden = self.lstm9(x.view(len(x), self.batch_size, -1))\n",
        "    g10, hidden = self.lstm10(x.view(len(x), self.batch_size, -1))\n",
        "\n",
        "    g = torch.cat((g1.view(-1,1), g2.view(-1,1), g3.view(-1,1), g4.view(-1,1), g5.view(-1,1), g6.view(-1,1), g7.view(-1,1), g8.view(-1,1), g9.view(-1,1), g10.view(-1,1)), dim=1)\n",
        "    #fixed_effects = torch.sum(g.view(-1, 1) * self.w)\n",
        "    #print('f', fixed_effects.shape)\n",
        "    \n",
        "    fixed_effects = torch.zeros(g.shape[0])\n",
        "    for i in range(g.shape[0]): \n",
        "      fixed_effects[i] = torch.dot(self.w.view(-1), g[i])\n",
        "\n",
        "    return fixed_effects\n",
        "    \n",
        "    #NEED TO ADD AN ATTENTION LAYER HERE \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSSlj0dlw0pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DF_RNN(nn.Module): \n",
        "  def __init__(self, input_size, hidden_size, batch_size, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = 1)\n",
        "    \n",
        "  def init_hidden(self): \n",
        "      return torch.zeros(1, self.batch_size, self.hidden_size)\n",
        "    \n",
        "  def forward(self, input_data, hidden, fixed_effects, gaussian_likelihood): \n",
        "    z = input_data[:,0]\n",
        "    x = input_data[:,1:]\n",
        "    rnn_out, hidden = self.rnn(x.view(len(x), self.batch_size, -1))\n",
        "    sigma = rnn_out.view(-1) #might need to separate all this out as sigma will be a vecotr?\n",
        "    r = torch.zeros(sigma.shape[0])\n",
        "    for i in range(sigma.shape[0]):\n",
        "      r[i] = torch.distributions.normal.Normal(0, sigma[i]).rsample()\n",
        "    u = fixed_effects + r\n",
        "    \n",
        "    if gaussian_likelihood == True: \n",
        "      likelihood = self.likelihood_Gaussian(z, fixed_effects, sigma)#????\n",
        "    \n",
        "    else: \n",
        "      likelihood = self.likelihood_nonGaussian()\n",
        "    \n",
        "    return likelihood\n",
        "   \n",
        "  def likelihood_Gaussian(self, z, f, sigma):\n",
        "    log_p = torch.zeros(len(z))\n",
        "    for i in range(len(z)): \n",
        "      print('doff', z[i] - f[i])\n",
        "      log_p[i] = torch.distributions.normal.Normal(0, sigma[i]).log_prob(z[i] - f[i])\n",
        "      print('sigma', sigma[i])\n",
        "      print('logp', log_p[i])\n",
        "     \n",
        "    p = torch.exp(log_p)\n",
        "    likelihood = torch.prod(p)\n",
        "      \n",
        "    return likelihood \n",
        "  \n",
        "  \n",
        "  def likelihood_nonGaussian(self, ):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KpePhAU974O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_model = GlobalEffects(64, 10)\n",
        "local_model = DF_RNN(64, hidden_size = 1, batch_size = 1, output_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGd_qELTtqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZumPtm7ZCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = torch.nn.NLLLoss()\n",
        "optimiser = torch.optim.SGD(list(global_model.parameters()) + list(local_model.parameters()), lr = learning_rate)\n",
        "\n",
        "#optimiser_global = torch.optim.SGD(global_model.parameters(), lr = learning_rate)\n",
        "#optimiser_local = torch.optim.SGD(local_model.parameters(), lr = learning_rate)\n",
        "\n",
        "train_loss = []\n",
        "\n",
        "for t in range(num_epochs): \n",
        "  global_model.zero_grad()\n",
        "  global_hidden = global_model.init_hidden()\n",
        "  \n",
        "  local_model.zero_grad()\n",
        "  local_hidden = local_model.init_hidden()\n",
        "  \n",
        "  data_batch = covars_data\n",
        "  \n",
        "  batch_loss = 0 \n",
        "  \n",
        "  for i in range(batch_size): \n",
        "    data = data_batch[i]\n",
        "    \n",
        "    fixed_effects = global_model(data, global_hidden)\n",
        "    print('f', fixed_effects.shape)\n",
        "    likelihood = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "    print('lik', likelihood.shape)\n",
        "    \n",
        "    batch_loss += loss_function(likelihood, data)\n",
        "    \n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "  batch_loss.backward()\n",
        "\n",
        "  optimiser.step()\n",
        "\n",
        "  train_loss.append(batch_loss.item())\n",
        "  \n",
        "    \n",
        "  print(\"Epoch: \", t, \"loss: \", batch_loss.item())\n",
        "    \n",
        "    \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}