{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Factors.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilyj19/TS/blob/master/Deep_Factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxHpi6CjWlg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c5b5ea94-2baa-4359-bd28-4061fc7c367a"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63MFgpVHUb5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_-DYtEUfH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a27dd762-77f9-42ee-848c-41f7a170e422"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAw0rtMUhZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a46857af-9666-4fcd-a30e-c9cf0ea35f11"
      },
      "source": [
        "root_path = 'gdrive/My Drive/FinancialTS/JPmarket_dataset.npz' \n",
        "data = np.load(root_path)\n",
        "data.files"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_ratios', 'test_ratios', 'train_volumes', 'test_volumes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIcj78GVk8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratios = data['train_ratios']\n",
        "test_ratios = data['test_ratios']\n",
        "train_vols = data['train_volumes']\n",
        "test_vols = data['test_volumes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyk_YlK6VrE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "av_vols = np.mean(train_vols[3], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKkWxWhOkne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "363e69dd-2638-48fe-8fa6-41821d37cb31"
      },
      "source": [
        "plt.plot(av_vols)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efc69682400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfzb9l0IoD6a0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2J6fvWqn8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create covariates - currently one hot vector 64 dims but experiment with different ideas \n",
        "def create_covariate_data(input_data, freq = 64): #this is assuming that data starts at beginning of day and ends at last bin of the day \n",
        "  num_series, len_series = input_data.shape\n",
        "  days = int(len_series/freq)\n",
        "  covariate_vectors = np.zeros((num_series, len_series, freq+1))\n",
        "  \n",
        "  for n in range(num_series):\n",
        "    for d in range(days): \n",
        "      for t in range(freq): \n",
        "        one_hot = np.zeros(freq)\n",
        "        one_hot[t] = 1\n",
        "        covariate_vectors[n, d*freq + t, 0] = input_data[n, d*freq + t]\n",
        "        covariate_vectors[n, d*freq + t, 1:] = one_hot\n",
        "        \n",
        "  return covariate_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOQe6RfNOx7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#alternative covariate function \n",
        "#inputs - input_data of shape [number of time series, length of each time series], freq of data i.e. number of bins per day, and position of special bins as a vector\n",
        "#returns - data and covariate vector of shape [number of series, length of series, number of special bins + 2] where covariate_vectors[:,:,0] is the input data, \n",
        "#covariate_vectors[:,:,1] is the scaled time of day and covariate_vectors[:,:,2:] is the one hot vector for the special bins\n",
        "#therefore covariate_vectors[:,:,0] is the data and covariate_vectors[:,:,1:] is the actual covariate vector \n",
        "\n",
        "def new_create_covariate_data(input_data, freq, pos_of_special_bins): \n",
        "  num_series, len_series = input_data.shape\n",
        "  days = int(len_series/freq)\n",
        "  num_special_bins = len(pos_of_special_bins)\n",
        "  covariate_vectors = np.zeros((num_series, len_series, num_special_bins+2))\n",
        "  \n",
        "  for n in range(num_series): \n",
        "    for d in range(days): \n",
        "      for t in range(freq): \n",
        "        x = np.zeros(num_special_bins + 1)\n",
        "        #x[0] is the scaled time of day \n",
        "        x[0] = t/freq\n",
        "        \n",
        "        check = t in pos_of_special_bins\n",
        "        \n",
        "        if check == True: \n",
        "          index = pos_of_special_bins.index(t)\n",
        "          x[index+1] = 1\n",
        "          \n",
        "        covariate_vectors[n, d*freq + t, 0] = input_data[n, d*freq + t]\n",
        "        covariate_vectors[n, d*freq + t, 1:] = x\n",
        "        \n",
        "  return covariate_vectors\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMl5hXU41NDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_volume = train_vols[0:50].reshape((50,-1))\n",
        "\n",
        "norm_train_vols = np.zeros(train_volume.shape)\n",
        "for i in range(50): \n",
        "  norm_train_vols[i] = train_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "T = 64*3\n",
        "new_train_data = norm_train_vols[:,:T]\n",
        "\n",
        "covars_data = new_create_covariate_data(new_train_data, 64, [0,31,32,63])\n",
        "\n",
        "covars_data = torch.FloatTensor(covars_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1O5qrgbY_f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_volume = train_vols[50:100].reshape((50,-1))\n",
        "\n",
        "norm_test_vols = np.zeros(test_volume.shape)\n",
        "for i in range(50): \n",
        "  norm_test_vols[i] = test_volume[i]/np.amax(train_vols[i])\n",
        "  \n",
        "T = 64*3\n",
        "new_test_data = norm_test_vols[:,:T]\n",
        "\n",
        "covars_test_data = new_create_covariate_data(new_test_data, 64, [0,31,32,63])\n",
        "\n",
        "covars_test_data = torch.FloatTensor(covars_test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKdgN_J2QQq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class for the global model \n",
        "#forward pass - input data of shape []\n",
        "#forward pass outputs fixed effects of shape []\n",
        "\n",
        "class GlobalEffects(nn.Module): \n",
        "  def __init__(self, input_size, num_factors, hidden_size, batch_size, output_size = 1, num_layers = 1): \n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_factors = num_factors\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.linears = nn.ModuleList([nn.Linear(self.hidden_size, self.output_size, bias = False) for i in range(self.num_factors)])\n",
        "    self.lstms = nn.ModuleList([nn.LSTM(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers) for i in range(self.num_factors)])\n",
        "    \n",
        "    self.w = torch.nn.Parameter(torch.zeros(batch_size, num_factors))\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    hidden = [torch.zeros(self.num_layers, self.batch_size, self.hidden_size) for i in range(self.num_factors)]\n",
        "    return hidden\n",
        "    \n",
        "  def forward(self, input_data, hidden): \n",
        "    x = input_data[:,:,1:]\n",
        "    for i in range(self.num_factors): \n",
        "      lstm_out, hidden[i] = self.lstms[i](x.view(x.shape[1], self.batch_size, -1))\n",
        "      g_i = self.linears[i](lstm_out).view(1, self.batch_size, -1) #shape of g_i = [1, batch_size, seq_len]\n",
        "      \n",
        "      if i == 0: \n",
        "        g = g_i\n",
        "      else:\n",
        "        g = torch.cat((g,g_i), dim=0)\n",
        "\n",
        "    fixed_effects = torch.zeros((self.batch_size, g.shape[2]))\n",
        "    \n",
        "    for i in range(self.batch_size): \n",
        "      for j in range(g.shape[2]): \n",
        "        fixed_effects[i,j] = torch.dot(self.w[i], g[:,i,j])\n",
        "      \n",
        "    return fixed_effects\n",
        "     \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ZvLZ9aUqw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#class for the DF-RNN local model \n",
        "#forward pass inputs: fixed effects output from global model, input data of shape [] and whether or not to assume a gaussian likelihood \n",
        "#forward pass outputs log likelihood for the given data\n",
        "\n",
        "class DF_RNN(nn.Module): \n",
        "  def __init__(self, input_size, hidden_size, batch_size, num_series, output_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.output_size = output_size\n",
        "    self.num_series = num_series\n",
        "    \n",
        "    self.rnns = nn.ModuleList([nn.RNN(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = 1) for i in range(self.num_series)])\n",
        "    self.linears = nn.ModuleList([nn.Linear(self.hidden_size, self.output_size) for i in range(self.num_series)])\n",
        "    \n",
        "  def init_hidden(self): \n",
        "    hidden = [torch.zeros(1, self.batch_size, self.hidden_size) for i in range(self.num_series)]\n",
        "    return hidden\n",
        "    \n",
        "  def forward(self, input_data, hidden, fixed_effects, gaussian_likelihood): \n",
        "    z = input_data[:,:,0]\n",
        "    x = input_data[:,:,1:]\n",
        "    \n",
        "    sigma = torch.zeros((self.num_series, x.shape[1]))\n",
        "    r = torch.zeros(sigma.shape)\n",
        "    \n",
        "    #log_lik = torch.zeros(self.num_series)\n",
        "    \n",
        "    for i in range(self.num_series): \n",
        "      data = x[i]\n",
        "      rnn_out, hidden[i] = self.rnns[i](data.view(data.shape[0], self.batch_size, -1))\n",
        "      sig = self.linears[i](rnn_out).view(-1)\n",
        "      \n",
        "      sigma[i] = torch.abs(sig)\n",
        "      \n",
        "      for j in range(sigma.shape[1]):\n",
        "        r[i,j] = torch.distributions.normal.Normal(0, sigma[i,j]).rsample()\n",
        "    \n",
        "    if gaussian_likelihood == True: \n",
        "      log_lik = self.log_likelihood_Gaussian(z, fixed_effects, sigma)\n",
        "\n",
        "    else: \n",
        "      pass\n",
        "\n",
        "      #log_lik[i] = log_likelihood\n",
        "      \n",
        "    u = fixed_effects + r\n",
        "    \n",
        "    return log_lik, sigma\n",
        "   \n",
        "  def log_likelihood_Gaussian(self, z, f, sigma):\n",
        "    log_p = torch.zeros(sigma.shape)\n",
        "    \n",
        "    for i in range(sigma.shape[0]):\n",
        "      for j in range(sigma.shape[1]): \n",
        "        log_pdf = torch.distributions.normal.Normal(0, sigma[i,j]).log_prob(z[i,j] - f[i,j])\n",
        "        #scale the likelihood to 0-1\n",
        "        log_norm_constant = torch.distributions.normal.Normal(0, sigma[i,j]).log_prob(0)\n",
        "        log_p[i,j] = log_pdf - log_norm_constant\n",
        "    \n",
        "    log_lik = torch.sum(log_p)\n",
        "\n",
        "    return log_lik\n",
        "  \n",
        "  \n",
        "  \n",
        "  def log_likelihood_nonGaussian(self, ): #to do \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGd_qELTtqx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 50 #??????\n",
        "num_epochs = 200\n",
        "hidden_units_global = 50\n",
        "hidden_units_local = 5\n",
        "n_factors = 10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiQ17VDHigR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d31e3b4-bceb-4a4d-f965-5773b8addbe4"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(False)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7efc69605b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnaiB4RyWtVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_model = GlobalEffects(input_size = 5, num_factors = n_factors , hidden_size = hidden_units_global, batch_size= 50)  \n",
        "local_model = DF_RNN(5, hidden_size = hidden_units_local, batch_size = 1, num_series = 50, output_size = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWZumPtm7ZCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7ee2fa4-d113-4a82-9836-eadac3cf8d5f"
      },
      "source": [
        "## TRAINING ##\n",
        "\n",
        "optimiser = torch.optim.SGD(list(global_model.parameters()) + list(local_model.parameters()), lr = learning_rate)\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []\n",
        " \n",
        "for t in range(num_epochs): \n",
        "  global_model.zero_grad()\n",
        "  global_hidden = global_model.init_hidden()\n",
        "  \n",
        "  local_model.zero_grad()\n",
        "  local_hidden = local_model.init_hidden()\n",
        "  \n",
        "  data_batch = covars_data\n",
        "  \n",
        "  fixed_effects = global_model(data_batch, global_hidden)\n",
        "\n",
        "  log_lik, sigma = local_model(data_batch, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "\n",
        "  batch_loss = -1*log_lik\n",
        "    \n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "  batch_loss.backward()\n",
        "\n",
        "  optimiser.step()\n",
        "  \n",
        "  train_loss.append(batch_loss.item())\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    test_data_batch = covars_test_data\n",
        "    fixed_effects = global_model(test_data_batch, global_hidden)\n",
        "    \n",
        "    data = test_data_batch\n",
        "    log_lik, sigma = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "      \n",
        "    test_batch_loss = -1*log_lik\n",
        "      \n",
        "    test_loss.append(test_batch_loss.item())\n",
        "  \n",
        "  print(\"Epoch: \", t, \"loss: \", batch_loss.item(), \"test loss: \", test_batch_loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 loss:  368373.9375 test loss:  6421.89501953125\n",
            "Epoch:  1 loss:  511.3743591308594 test loss:  771.5874633789062\n",
            "Epoch:  2 loss:  16.113447189331055 test loss:  750.0118408203125\n",
            "Epoch:  3 loss:  14.33482551574707 test loss:  737.8549194335938\n",
            "Epoch:  4 loss:  13.268628120422363 test loss:  734.8265991210938\n",
            "Epoch:  5 loss:  12.432352066040039 test loss:  741.7972412109375\n",
            "Epoch:  6 loss:  11.741040229797363 test loss:  761.1307983398438\n",
            "Epoch:  7 loss:  11.155841827392578 test loss:  797.894287109375\n",
            "Epoch:  8 loss:  10.652003288269043 test loss:  862.6184692382812\n",
            "Epoch:  9 loss:  10.212528228759766 test loss:  978.7911376953125\n",
            "Epoch:  10 loss:  9.825209617614746 test loss:  1206.7852783203125\n",
            "Epoch:  11 loss:  9.481022834777832 test loss:  1744.0838623046875\n",
            "Epoch:  12 loss:  9.173032760620117 test loss:  3587.584716796875\n",
            "Epoch:  13 loss:  8.895734786987305 test loss:  21177.689453125\n",
            "Epoch:  14 loss:  8.644830703735352 test loss:  94487.4296875\n",
            "Epoch:  15 loss:  8.435237884521484 test loss:  566.3483276367188\n",
            "Epoch:  16 loss:  8.42359733581543 test loss:  525.77587890625\n",
            "Epoch:  17 loss:  8.054119110107422 test loss:  518.5778198242188\n",
            "Epoch:  18 loss:  7.852956295013428 test loss:  512.8525390625\n",
            "Epoch:  19 loss:  7.673341751098633 test loss:  507.8206787109375\n",
            "Epoch:  20 loss:  7.510156154632568 test loss:  503.20233154296875\n",
            "Epoch:  21 loss:  7.360471725463867 test loss:  498.8708801269531\n",
            "Epoch:  22 loss:  7.222269535064697 test loss:  494.7609558105469\n",
            "Epoch:  23 loss:  7.0940961837768555 test loss:  490.8333740234375\n",
            "Epoch:  24 loss:  6.974669933319092 test loss:  487.06439208984375\n",
            "Epoch:  25 loss:  6.863004207611084 test loss:  483.4382019042969\n",
            "Epoch:  26 loss:  6.758194923400879 test loss:  479.943359375\n",
            "Epoch:  27 loss:  6.659552574157715 test loss:  476.5716857910156\n",
            "Epoch:  28 loss:  6.566478252410889 test loss:  473.31591796875\n",
            "Epoch:  29 loss:  6.478366374969482 test loss:  470.1700439453125\n",
            "Epoch:  30 loss:  6.394743919372559 test loss:  467.1293640136719\n",
            "Epoch:  31 loss:  6.315224647521973 test loss:  464.1874694824219\n",
            "Epoch:  32 loss:  6.239457130432129 test loss:  461.3406677246094\n",
            "Epoch:  33 loss:  6.167089462280273 test loss:  458.58428955078125\n",
            "Epoch:  34 loss:  6.09785270690918 test loss:  455.91363525390625\n",
            "Epoch:  35 loss:  6.03154182434082 test loss:  453.324951171875\n",
            "Epoch:  36 loss:  5.967861175537109 test loss:  450.81414794921875\n",
            "Epoch:  37 loss:  5.906684875488281 test loss:  448.37786865234375\n",
            "Epoch:  38 loss:  5.847749710083008 test loss:  446.0118713378906\n",
            "Epoch:  39 loss:  5.790960311889648 test loss:  443.7132263183594\n",
            "Epoch:  40 loss:  5.7361040115356445 test loss:  441.4785461425781\n",
            "Epoch:  41 loss:  5.683187961578369 test loss:  439.30450439453125\n",
            "Epoch:  42 loss:  5.631964683532715 test loss:  437.18896484375\n",
            "Epoch:  43 loss:  5.582359313964844 test loss:  435.1288757324219\n",
            "Epoch:  44 loss:  5.53427791595459 test loss:  433.12139892578125\n",
            "Epoch:  45 loss:  5.487639427185059 test loss:  431.1645202636719\n",
            "Epoch:  46 loss:  5.442384719848633 test loss:  429.2555847167969\n",
            "Epoch:  47 loss:  5.398469924926758 test loss:  427.3929138183594\n",
            "Epoch:  48 loss:  5.355716705322266 test loss:  425.5741271972656\n",
            "Epoch:  49 loss:  5.314121723175049 test loss:  423.7970275878906\n",
            "Epoch:  50 loss:  5.273629188537598 test loss:  422.06048583984375\n",
            "Epoch:  51 loss:  5.234172821044922 test loss:  420.36279296875\n",
            "Epoch:  52 loss:  5.195725440979004 test loss:  418.7019958496094\n",
            "Epoch:  53 loss:  5.158230781555176 test loss:  417.0767517089844\n",
            "Epoch:  54 loss:  5.121644973754883 test loss:  415.4854736328125\n",
            "Epoch:  55 loss:  5.085878849029541 test loss:  413.9271545410156\n",
            "Epoch:  56 loss:  5.050982475280762 test loss:  412.4002380371094\n",
            "Epoch:  57 loss:  5.016875267028809 test loss:  410.90399169921875\n",
            "Epoch:  58 loss:  4.9835638999938965 test loss:  409.4365234375\n",
            "Epoch:  59 loss:  4.950944423675537 test loss:  407.99761962890625\n",
            "Epoch:  60 loss:  4.9189958572387695 test loss:  406.5858154296875\n",
            "Epoch:  61 loss:  4.88776969909668 test loss:  405.19976806640625\n",
            "Epoch:  62 loss:  4.857180118560791 test loss:  403.83935546875\n",
            "Epoch:  63 loss:  4.827188491821289 test loss:  402.5034484863281\n",
            "Epoch:  64 loss:  4.797857284545898 test loss:  401.1908874511719\n",
            "Epoch:  65 loss:  4.7690205574035645 test loss:  399.9012145996094\n",
            "Epoch:  66 loss:  4.740807056427002 test loss:  398.63336181640625\n",
            "Epoch:  67 loss:  4.7130632400512695 test loss:  397.38726806640625\n",
            "Epoch:  68 loss:  4.685911178588867 test loss:  396.16180419921875\n",
            "Epoch:  69 loss:  4.659191608428955 test loss:  394.956298828125\n",
            "Epoch:  70 loss:  4.63301420211792 test loss:  393.7701721191406\n",
            "Epoch:  71 loss:  4.607264518737793 test loss:  392.60296630859375\n",
            "Epoch:  72 loss:  4.582019805908203 test loss:  391.4539794921875\n",
            "Epoch:  73 loss:  4.5572099685668945 test loss:  390.3227233886719\n",
            "Epoch:  74 loss:  4.532793045043945 test loss:  389.20867919921875\n",
            "Epoch:  75 loss:  4.508817672729492 test loss:  388.1114807128906\n",
            "Epoch:  76 loss:  4.485184669494629 test loss:  387.0303955078125\n",
            "Epoch:  77 loss:  4.461970806121826 test loss:  385.9652099609375\n",
            "Epoch:  78 loss:  4.439191818237305 test loss:  384.9156799316406\n",
            "Epoch:  79 loss:  4.4166998863220215 test loss:  383.8807373046875\n",
            "Epoch:  80 loss:  4.3946003913879395 test loss:  382.86029052734375\n",
            "Epoch:  81 loss:  4.3728790283203125 test loss:  381.854248046875\n",
            "Epoch:  82 loss:  4.351443290710449 test loss:  380.8619689941406\n",
            "Epoch:  83 loss:  4.3303632736206055 test loss:  379.8832092285156\n",
            "Epoch:  84 loss:  4.3095808029174805 test loss:  378.9173889160156\n",
            "Epoch:  85 loss:  4.28908634185791 test loss:  377.964599609375\n",
            "Epoch:  86 loss:  4.268927097320557 test loss:  377.0241394042969\n",
            "Epoch:  87 loss:  4.249059677124023 test loss:  376.0959167480469\n",
            "Epoch:  88 loss:  4.229516983032227 test loss:  375.179443359375\n",
            "Epoch:  89 loss:  4.210208415985107 test loss:  374.2748718261719\n",
            "Epoch:  90 loss:  4.191137790679932 test loss:  373.38116455078125\n",
            "Epoch:  91 loss:  4.172368049621582 test loss:  372.49871826171875\n",
            "Epoch:  92 loss:  4.153879165649414 test loss:  371.62701416015625\n",
            "Epoch:  93 loss:  4.1356201171875 test loss:  370.7660827636719\n",
            "Epoch:  94 loss:  4.117608070373535 test loss:  369.9153137207031\n",
            "Epoch:  95 loss:  4.099849700927734 test loss:  369.07452392578125\n",
            "Epoch:  96 loss:  4.082301139831543 test loss:  368.2435302734375\n",
            "Epoch:  97 loss:  4.0649943351745605 test loss:  367.4225158691406\n",
            "Epoch:  98 loss:  4.047924041748047 test loss:  366.61053466796875\n",
            "Epoch:  99 loss:  4.031023025512695 test loss:  365.8080139160156\n",
            "Epoch:  100 loss:  4.014378070831299 test loss:  365.01446533203125\n",
            "Epoch:  101 loss:  3.9979429244995117 test loss:  364.2296142578125\n",
            "Epoch:  102 loss:  3.9817371368408203 test loss:  363.4536437988281\n",
            "Epoch:  103 loss:  3.9656972885131836 test loss:  362.68603515625\n",
            "Epoch:  104 loss:  3.9498291015625 test loss:  361.9266357421875\n",
            "Epoch:  105 loss:  3.9342236518859863 test loss:  361.17547607421875\n",
            "Epoch:  106 loss:  3.9187581539154053 test loss:  360.43218994140625\n",
            "Epoch:  107 loss:  3.903454065322876 test loss:  359.6968688964844\n",
            "Epoch:  108 loss:  3.8883872032165527 test loss:  358.9691467285156\n",
            "Epoch:  109 loss:  3.873448371887207 test loss:  358.2487487792969\n",
            "Epoch:  110 loss:  3.8586997985839844 test loss:  357.535888671875\n",
            "Epoch:  111 loss:  3.84413480758667 test loss:  356.8300476074219\n",
            "Epoch:  112 loss:  3.8297057151794434 test loss:  356.1315612792969\n",
            "Epoch:  113 loss:  3.8154850006103516 test loss:  355.43975830078125\n",
            "Epoch:  114 loss:  3.801356792449951 test loss:  354.7549743652344\n",
            "Epoch:  115 loss:  3.7874183654785156 test loss:  354.07659912109375\n",
            "Epoch:  116 loss:  3.773624897003174 test loss:  353.40509033203125\n",
            "Epoch:  117 loss:  3.759986400604248 test loss:  352.73968505859375\n",
            "Epoch:  118 loss:  3.7464959621429443 test loss:  352.08087158203125\n",
            "Epoch:  119 loss:  3.7331767082214355 test loss:  351.4280700683594\n",
            "Epoch:  120 loss:  3.719965696334839 test loss:  350.7816162109375\n",
            "Epoch:  121 loss:  3.7068867683410645 test loss:  350.140869140625\n",
            "Epoch:  122 loss:  3.69400954246521 test loss:  349.5060119628906\n",
            "Epoch:  123 loss:  3.681175708770752 test loss:  348.87713623046875\n",
            "Epoch:  124 loss:  3.668555736541748 test loss:  348.2537536621094\n",
            "Epoch:  125 loss:  3.6559860706329346 test loss:  347.6360778808594\n",
            "Epoch:  126 loss:  3.6435739994049072 test loss:  347.0238952636719\n",
            "Epoch:  127 loss:  3.6313300132751465 test loss:  346.417236328125\n",
            "Epoch:  128 loss:  3.6191420555114746 test loss:  345.8156433105469\n",
            "Epoch:  129 loss:  3.6071324348449707 test loss:  345.2193908691406\n",
            "Epoch:  130 loss:  3.5951907634735107 test loss:  344.628173828125\n",
            "Epoch:  131 loss:  3.58339786529541 test loss:  344.0420227050781\n",
            "Epoch:  132 loss:  3.5717244148254395 test loss:  343.4610290527344\n",
            "Epoch:  133 loss:  3.5601611137390137 test loss:  342.8848571777344\n",
            "Epoch:  134 loss:  3.5486559867858887 test loss:  342.31329345703125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ITTS-hEfXfqA",
        "colab": {}
      },
      "source": [
        "plt.plot(train_loss[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBiAyg9zksxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a4c33141-b2e5-4083-bed2-eb4d7a42f565"
      },
      "source": [
        "plt.plot(test_loss)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efc68502080>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8lOW99/HPLztbIGSBkBASIAgB\nlCWCbIq4oSK49SkuVayVat1a6+Op9Zza2vbpsadP1R5X6obWqhW1KlqtK7LIkrBDAAMJYSdhCQEk\nkOQ6f8zoSWMCIds9y/f9euVlZuaeme/rlnznmmuuuW9zziEiIqEvwusAIiLSNlT4IiJhQoUvIhIm\nVPgiImFChS8iEiZU+CIiYUKFLyISJlT4IiJhQoUvIhImorx64qSkJJeZmenV04uIBKX8/Pwy51xy\nU+7rWeFnZmaSl5fn1dOLiAQlM9vc1PtqSkdEJEyo8EVEwoQKX0QkTKjwRUTChApfRCRMqPBFRMKE\nCl9EJEwEXeFvKj3Ir95Zw7HqGq+jiIgElaAr/OI9h3hufjGzV273OoqISFAJusIf3y+F7JSOPDVn\nEzoBu4hI4wVd4UdEGDed2Zt1OyuY+2WZ13FERIJG0BU+wJQhPUjpFMuMzzd5HUVEJGgEZeHHRkVy\nw5gs5hWWsXpbuddxRESCQlAWPsDVIzPoEBPJn+dqlC8i0hhBW/id20Vz1YgMZq/cwdZ9h72OIyIS\n8IK28AG+PzYLA56dV+x1FBGRgBfUhd+jSzsuOa0HrywpofzwMa/jiIgEtKAufICbxvXm8NFq/rKo\nySeBEREJC40ufDOLNLNlZja7ntummVmpmS33//ygZWM2LKdHPGf1S+bZeUUcPlrVVk8rIhJ0TmaE\nfydQcJzbX3XODfH/PN3MXCfljnP6sufQUV5aWNKWTysiElQaVfhmlg5cDLRpkTfW8F5dGZedxFOf\nb+Sro9VexxERCUiNHeE/DNwDHO8QlVeY2Uozm2VmPZsf7eTceU42ZQeP8pLm8kVE6nXCwjezScBu\n51z+cTZ7B8h0zp0KfAjMbOCxpptZnpnllZaWNilwQ3IzuzK2bxJPztEoX0SkPo0Z4Y8BJptZMfAK\nMMHM/lJ7A+fcHudcpf/i08Dw+h7IOTfDOZfrnMtNTk5uRuz63XmuRvkiIg05YeE75+51zqU75zKB\nqcAnzrlra29jZqm1Lk7m+B/utprTM7sypm8iT87ZpFG+iEgdTV6Hb2YPmNlk/8U7zGyNma0A7gCm\ntUS4prjznH6UHazkr4u1YkdEpDbz6iQiubm5Li8vr1Ue+6oZCyksPcjce84mLjqyVZ5DRMQLZpbv\nnMttyn2D/pu29fnxudmUVlQyc0Gx11FERAJGSBb+yN6JnH1KMo99Wqhj7IiI+IVk4QPcM7E/FZVV\nPD6n0OsoIiIBIWQLf0BqPJcNTeO5+cVs3/+V13FERDwXsoUPcNd5/cDBQx9u8DqKiIjnQrrw0xPa\nc92oXry+dCvrd1Z4HUdExFMhXfgAt57dlw6xUfzXB+u8jiIi4qmQL/yEDjHcMr4PHxXsZnHRXq/j\niIh4JuQLH+CG0Vl0i4/l/71XQE2NN180ExHxWlgUfruYSO4+/xSWb9nPm8u2eR1HRMQTYVH4AFcM\nS+e0nl34z/fXcbBSp0IUkfATNoUfEWH88pIcSisqefQTfRlLRMJP2BQ+wNCMBC4flsaz84ooLjvk\ndRwRkTYVVoUP8LOJ/YmONH7z7lqvo4iItKmwK/yU+Dhum5DNRwW7mbOhZU+zKCISyMKu8AG+PzaT\nzMT2PPDOGo5VH++87CIioSMsCz82KpJ/vziHjaWHeHZekddxRETaRFgWPsA5A1I4d0A3Hv7oS7bs\nPex1HBGRVhe2hW9m/GrKQMzgF2+txqtTPYqItJWwLXyAtC7tuOu8fny6vpR/rN7pdRwRkVYV1oUP\nMG10JgN7xPPLt9dw4IhOhygioSvsCz8qMoLfXT6YsoOV/OGD9V7HERFpNWFf+ACnpnfhulGZvLhw\nM8tK9nkdR0SkVajw/X56fj+6dYrj3jdWcbRKa/NFJPSo8P06xUXz60sHsW5nBY9+qoOriUjoUeHX\ncl5ONy4bmsbjnxayelu513FERFqUCr+O+y/JIaFDDHe/tkJTOyISUlT4dXRpH8PvLhvsm9r55Euv\n44iItJhGF76ZRZrZMjObXc9tsWb2qpkVmtkiM8tsyZBt7dycblw+NI3HPtuoqR0RCRknM8K/Eyho\n4LYbgX3Oub7AQ8CDzQ3mtfsvGUiipnZEJIQ0qvDNLB24GHi6gU2mADP9v88CzjEza34873RuH83v\nLvdN7Tz00Qav44iINFtjR/gPA/cADQ1104AtAM65KqAcSGx2Oo+dM6AbU0/vyZNzNvLFxj1exxER\naZYTFr6ZTQJ2O+fym/tkZjbdzPLMLK+0NDjONvWLS3LISuzAXX9bTvlhHWtHRIJXY0b4Y4DJZlYM\nvAJMMLO/1NlmG9ATwMyigM7At4bEzrkZzrlc51xucnJys4K3lfYxUTw8dQilFZX8/M1VOoyyiASt\nExa+c+5e51y6cy4TmAp84py7ts5mbwPX+3+/0r9NyDTjqelduOv8fry7agevL93mdRwRkSZp8jp8\nM3vAzCb7Lz4DJJpZIXAX8LOWCBdIfnhmH87o3ZX731pNcdkhr+OIiJw082ognpub6/Ly8jx57qba\nvv8rJj78OVnJHXnth6OIidL31kSkbZlZvnMutyn3VWOdhB5d2vHgFaeyYst+fv/+Oq/jiIicFBX+\nSbpwcCrTRmfy9LwiPlij0yKKSPBQ4TfBvRf157T0ztz92gpK9hz2Oo6ISKOo8JsgNiqSR68ehgG3\n/nUplVXVXkcSETkhFX4T9ezanj985zRWbSvnt+82dIghEZHAocJvhvMHducHY7N44YvNvLNiu9dx\nRESOS4XfTP92YX+G90rgnlkrKdhxwOs4IiINUuE3U3RkBE9cM4z4dlFMfzGP/YePeh1JRKReKvwW\nkBIfxxPXDmdXeSW3v7yM6pqQOaqEiIQQFX4LGZaRwANTBjL3yzJ+/4G+lCUigSfK6wChZOqIDFZt\nK+epOZsY2KMzk0/r4XUkEZFvaITfwu6/ZCC5vRK4Z9YKVm3V+XBFJHCo8FtYTFQET1w7nMQOsfzg\nhSXsLD/idSQREUCF3yqSO8XyzLRcDh6p4saZSzhUWeV1JBERFX5r6d89nkevHkbBjgP8+NXl1Gjl\njoh4TIXfis7un8J/TMrhw7W7eFCHUxYRj2mVTiubNjqTTaWHeOrzTWQmdeCqERleRxKRMKXCb2Vm\nxv2X5FCy9zD//vfVpHSK5ZwB3byOJSJhSFM6bSAqMoLHrxnGwB7x3PrXpSwt2ed1JBEJQyr8NtIh\nNopnp51Ot/g4bnx+CRtLD3odSUTCjAq/DSV1jOWF748gwozrn13M7gNaoy8ibUeF38Z6JXbguRtO\nZ++ho0x7bgkHjhzzOpKIhAkVvgdOTe/C49cMY8OuCm58fglfHdUpEkWk9anwPTL+lBQe+u4Q8jbv\n4+a/5HO0qsbrSCIS4lT4HrrktB787rLBzNlQyk9eXa7j6ItIq9I6fI9NHZFBxZEqfvteAR1jo/jP\nKwZjZl7HEpEQpMIPADed2ZuKI8f40yeFtI+N5BeTclT6ItLiVPgB4ifn9eNgZTXPzi/CMP5j0gCV\nvoi0qBMWvpnFAZ8Dsf7tZznn7q+zzTTgv4Bt/qsedc493bJRQ5uZr+RrnOPZ+UUAKn0RaVGNGeFX\nAhOccwfNLBqYZ2b/cM4trLPdq86521o+Yvj4+rg7gEpfRFrcCQvfOeeAr48DEO3/0XKSVqLSF5HW\n0qg5fDOLBPKBvsBjzrlF9Wx2hZmdCWwAfuKc21LP40wHpgNkZOgwwQ1R6YtIa2jUOnznXLVzbgiQ\nDowws0F1NnkHyHTOnQp8CMxs4HFmOOdynXO5ycnJzckd8r4u/WmjM3l2fhG/nl2A782WiEjTnNQq\nHefcfjP7FJgIrK51/Z5amz0N/L5l4oW3uiP96poa7r9kIBERGumLyMlrzCqdZOCYv+zbAecBD9bZ\nJtU5t8N/cTJQ0OJJw9TXpR8VYTw9r4iDldU8eMVgoiL1JWkROTmNGeGnAjP98/gRwN+cc7PN7AEg\nzzn3NnCHmU0GqoC9wLTWChyOzIz7Lh5Ap7hoHvpoA4cqq3jkqiHERkV6HU1Egoh5NS+cm5vr8vLy\nPHnuYPbsvCIemL2WcdlJPPW94bSP0XfnRMKJmeU753Kbcl/NCwSZ74/N4vdXnMr8wjKue2Yx5Yd1\nPH0RaRwVfhD6P6f35NGrh7FyazlXPrmAbfu/8jqSiAQBFX6QumhwKjO/P4KdB45wxeMLWLfzgNeR\nRCTAqfCD2Kg+ibx28ygAvvPEF3yxcc8J7iEi4UyFH+T6d4/njR+NpnvnOK5/djHvrNjudSQRCVAq\n/BDQo0s7Zt08miE9u3D7y8t4eu4mryOJSABS4YeIzu2jeeHGEVw4qDu/ebeAX89eq1Mmisi/UOGH\nkLjoSB69ehjTRmfyzLwipr+QR8URLdsUER8VfoiJjDB+OXkgv54ykM82lHLlE1+wZe9hr2OJSABQ\n4Yeo743KZOYNI9hR/hVTHpvPkuK9XkcSEY+p8EPY2Owk/n7rGLq0i+bqPy/ktbxvnaJARMKICj/E\n9U7uyJs/GsPIrET+76yV/O69An2YKxKmVPhhoHP7aJ674XSuG9WLpz7fxA9mLtExeETCkAo/TERH\nRvDAlEH85tJBzCss45JH57Fme7nXsUSkDanww8y1Z/TilemjqKyq5vLHF/DG0q1eRxKRNqLCD0PD\neyUw+/ZxDM3owl1/W8F//H01R6tqvI4lIq1MhR+mkjvF8pcbRzL9zN68uHAzU2d8wc7yI17HEpFW\npMIPY1GREfz8ogE8fs0w1u+sYNJ/z2VBYZnXsUSklajwhYsGp/LWbWPo3C6aa55ZxB//uZ6qak3x\niIQaFb4A0DelE+/cPpYrhqXzp08KufrPi9hRrjNpiYQSFb58o31MFH/4zmk89N3TWL29nIsemcvH\nBbu8jiUiLUSFL99y2dB0Zt8+ltTO7bhxZh6/nr1Wq3hEQoAKX+rVO7kjb/xoNNeP6sUz84q48skF\nFJUd8jqWiDSDCl8aFBcdya+mDOLJa4ezec9hLnpkLi8t2oxzOhaPSDBS4csJTRzUnQ9+fCa5mQnc\n9+ZqbpyZx+4KrdkXCTYqfGmU7p3jmHnDCH55SQ7zC8uY+PBcPliz0+tYInISVPjSaBERxrQxWf4P\ndOP44Yv53DNrBQcrq7yOJiKNoMKXk5bdrRNv/mgMt53dl1n5W7nwkc9ZsFHf0BUJdCcsfDOLM7PF\nZrbCzNaY2a/q2SbWzF41s0IzW2Rmma0RVgJHTFQEd19wCn/74Sgizbj6z4u4781VOmm6SABrzAi/\nEpjgnDsNGAJMNLMz6mxzI7DPOdcXeAh4sGVjSqDKzezKP+48k5vGZfHy4hIueOhzPlu/2+tYIlKP\nExa+8znovxjt/6m7Lm8KMNP/+yzgHDOzFkspAa1dTCT3XZzDrFtG0z42imnPLeHu11borFoiAaZR\nc/hmFmlmy4HdwIfOuUV1NkkDtgA456qAciCxnseZbmZ5ZpZXWlravOQScIZlJPDuHWO57ey+vLls\nG+c+NId/aiWPSMBoVOE756qdc0OAdGCEmQ1qypM552Y453Kdc7nJyclNeQgJcLFRkdx9wSm8desY\nkjrGMv3FfH74Yp4OxCYSAE5qlY5zbj/wKTCxzk3bgJ4AZhYFdAb2tERACU6D0jrz9m1j+LeJ/Zmz\noZRz//8cnptfRHWNvqUr4pXGrNJJNrMu/t/bAecB6+ps9jZwvf/3K4FPnL5/H/aiIyO4ZXwf/vnj\nsxie2ZVfvbOWyx6fz+ptOnm6iBcaM8JPBT41s5XAEnxz+LPN7AEzm+zf5hkg0cwKgbuAn7VOXAlG\nGYntmXnD6fz3VUPZvv8Ikx+dx29mr+WQvrAl0qbMq4F4bm6uy8vL8+S5xTvlXx3j9++v46VFJaR2\njuPnFw1g0qmpaFGXSOOYWb5zLrcp99U3baVNdW4XzW8vG8zrt4wmsWMMt7+8jKv+vJB1Ow94HU0k\n5KnwxRPDeyXw1q1j+e1lg1i3s4KL/zSPX769hvKvtHZfpLWo8MUzkRHGNSN78dnd47l6RAYvfFHM\nhD98xqtLSqjRah6RFqfCF891aR/Dry8dxDu3jyUrqQP/9voqJj82j0WbtLJXpCWp8CVgDOzRmddu\nHsUjU4ew9+BRvjtjITe/mE+xTq0o0iKivA4gUpuZMWVIGufndOeZeZt4/LONfLxuF9ePyuT2Cdl0\nbh/tdUSRoKURvgSkdjGR3DYhm8/uHs/lQ9N5Zn4RZ/3hU56fX8Sx6hqv44kEJRW+BLSU+DgevPJU\n3r19HDmp8fzynbWc+8c5vLV8mz7YFTlJKnwJCjk94nnpByN5btrptIuO5M5XljPpv+fx2frd6Cge\nIo2jwpegYWac3T+F9+4Yx8PfHUJF5TGmPbeEqTMWkr95n9fxRAKeCl+CTkSEcenQND6+azwPTBnI\nxtKDXPHEAm56IY8Nuyq8jicSsHQsHQl6hyqreHZeETM+38Sho1VcPiydO8/JpmfX9l5HE2lxzTmW\njgpfQsbeQ0d54rNCZn6xmZoax5XD07n17L4qfgkpKnyRWnaUf8WTn23k5cVbqHEqfgktKnyReqj4\nJRSp8EWOQ8UvoUSFL9IIO8uP8MRnhd8U/6VD07j5rN70TenkdTSRRlPhi5yEneVHeHLORl5ZUkJl\nVQ3n53TjlvF9GdKzi9fRRE5IhS/SBHsOVvL8gmJmLijmwJEqRvdJ5JbxfRjbN0mnXJSApcIXaYaK\nI8d4eXEJT88tYndFJYPTOnPL+D5cMLA7kREqfgksKnyRFlBZVc0bS7fx1JyNFO85TFZSB24a15vL\nh6URFx3pdTwRQIUv0qKqaxzvr97JE3MKWb3tAF07xHDtyAyuHdWLlE5xXseTMKfCF2kFzjkWbtrL\nM/M28fG63URHRDBlSA9uHJdF/+7xXseTMNWcwtcZr0QaYGaM6pPIqD6JbCo9yHPzi5mVv5XX8rcy\ntm8SN47L4qzsZCI0zy9BQiN8kZOw//BR/rq4hJkLitl1oJK+KR25YUwmlw5Jo0Osxk/S+jSlI9LG\njlbV8N6qHTw9bxOrtx2gU2wUV+am870zetE7uaPX8SSEqfBFPOKcY2nJfl74opj3Vu3gWLVjXHYS\n143KZEL/FC3rlBbXqoVvZj2BF4BugANmOOceqbPNeOAtoMh/1RvOuQeO97gqfAk1pRWVvLqkhJcW\nlbCj/AhpXdpxzRkZTD09g64dYryOJyGitQs/FUh1zi01s05APnCpc25trW3GA3c75yY19olV+BKq\nqqpr+KhgFy98sZkFG/cQExXBpMGpXDUyg9xeCfoWrzRLq67Scc7tAHb4f68wswIgDVh73DuKhKmo\nyAgmDkpl4qBUvtxVwYsLN/Pm0m28sWwbfVM6ctWIDC4fmkaCRv3Sxk5qDt/MMoHPgUHOuQO1rh8P\nvA5sBbbjG+2vOd5jaYQv4eTw0Spmr9zBy4tLWFayn5ioCC4c1J2rRmQwMqurRv3SaG3yoa2ZdQTm\nAL91zr1R57Z4oMY5d9DMLgIecc5l1/MY04HpABkZGcM3b97clMwiQW3dzgO8sngLry/dSsWRKnon\ndWDqiJ5cMSydxI6xXseTANfqhW9m0cBs4APn3B8bsX0xkOucK2toG43wJdx9dbSa91b5Rv15m/cR\nFWFM6J/ClcPTObt/CtGREV5HlADUqnP45nuv+QxQ0FDZm1l3YJdzzpnZCCAC2NOUQCLhol1MJFcM\nT+eK4el8uauC1/K38sbSbfxz7S4SO8QwZUgaVw5PJ6eHDuMgLaMxq3TGAnOBVUCN/+qfAxkAzrkn\nzew24BagCvgKuMs5t+B4j6sRvsi3VVXX8PmXpczK38qHa3dxrNqRkxrPlcPTmTKkh6Z8RF+8EglF\n+w4d5Z2V25mVv5WVW8s15SOACl8k5K3fWcGs/C28uWw7ZQcrSewQw6RTU5k8JI1hGV20yieMqPBF\nwsSx6ho+31DKG0u38VHBLiqrakhPaMeUIT2YMiSNft10QvZQp8IXCUMVR47xzzW7eGvFduYXllFd\n4+jfvROTh/Rg8mk9SE9o73VEaQUqfJEwV3awkvdW7eCt5dvJ37wPgNxeCUwZ0oOLBqfqw94QosIX\nkW9s2XuYt1ds563l29iw6yCREcaYvklcPLg75+d01yEdgpwKX0TqtW7nAd5avp13V+6gZO9hoiKM\n0Sr/oKbCF5Hjcs6xetsB3l21g/dW/Wv5TxqcyvkDu9Glvco/GKjwRaTRGir/UX0SmTioO+fldCOl\nU5zXMaUBKnwRaZLa5f/+6h0U7zmMGQzPSGDioO5cMLA7PbtqtU8gUeGLSLM559iw6yDvr97J+2t2\nUrDDdwT0nNR4Jg7qzsRB3clO6agveXlMhS8iLa5kz2E+WOMr/6+XemYmtmdC/26cOyCF07O66vAO\nHlDhi0ir2n3gCB+s3cVHa3fxxcY9HK2uoVNcFGf1S+bcAd0Yf0qyPvRtIyp8EWkzhyqrmFdYxscF\nu/hk3W7KDh4lMsIY3iuBcwekcM6AbvRJ7uh1zJClwhcRT9TUOFZs3c/HBbv5qGAX63ZWAJCV1IEJ\n/VM4Z0AKp2dq6qclqfBFJCBs3XeYT9bt5qOC3Sz0T/3Ex0UxLjuZs05J5qx+yXSL15LP5lDhi0jA\nOVhZxbwvS/m4YDdzNpSyu6ISgP7dOzH+lBTO6pfM8F4JxERp9H8yVPgiEtCccxTsqGDOhlLmbNhN\nXvE+qmocHWOjGN0n8ZvRv47weWIqfBEJKhVHjrFg4x4+W1/KnPW72V5+BIC+KR05MzuZcdlJjMjq\nSofYE552O+yo8EUkaDnnKNx9kDkbSvlsfSmLi/dytKqG6EhjaEYCY/smMaZvEqeldyZKH/6q8EUk\ndBw5Vk1e8T7mFpYyv7CMNdsP4Bx0io3ijD6JjMv2vQD0TuoQlt/6bU7h6/2SiASUuOhIxmYnMTY7\nCYC9h46yYGMZ8wvLmPtlGR+u3QVAj85xjOnr225M3ySSdJKXE9IIX0SChnOOkr2Hmful7wVgwcY9\nlH91DIDslI6M7N2VkVmJjOzdNWSP+KkpHREJS9U1jtXbyplXWMaior3kF+/l0NFqAHondfiXF4DU\nzu08TtsyVPgiIkBVdQ2rtx9g0aY9LCray5KivVRUVgGQ0bU9I7O6MrJ3IiOzugbtYZ9V+CIi9aiu\ncRTsOMBC/wvA4qK930wBpXVp538B8L0L6JXYPig+BFbhi4g0Qk2NY/2uim/eASwu2sueQ0cB6BYf\ny8isREZkdeWM3l3pkxyYx/5X4YuINMHX3wFYVLTX97NpzzeHgEjqGMOILN/of3ivBAakxhMZ4f0L\ngJZliog0gZmR3a0T2d06ce0ZvXDOUbzn8DfvABZt2sN7q3YC0CEmkqEZCQzvlUBuZgJDMxLoGGTf\nBD7hCN/MegIvAN0AB8xwzj1SZxsDHgEuAg4D05xzS4/3uBrhi0igc86xdd9X5G/eR/7mfeRt3se6\nnb4vgkUY9O8e/80LwPBeCaR1adfq00CtOqVjZqlAqnNuqZl1AvKBS51za2ttcxFwO77CHwk84pwb\nebzHVeGLSDCqOHKMZSX7ydu8j/zNe1lWsp/D/qWg3ePjGNarC0N7JjA0owuD0joTFx3Zos/fqlM6\nzrkdwA7/7xVmVgCkAWtrbTYFeMH5Xj0WmlkXM0v131dEJGR0iovmzH7JnNkvGfAtBV23s+KbdwDL\nSvZ9Mw0UHWnkpMYzNMP3AjC0ZwI9u7b+u4CGnNQElJllAkOBRXVuSgO21Lq81X+dCl9EQlpUZASD\n0jozKK0z14/OBGB3xRGWl+xn2Zb9LCvZx9/ytvD8gmIAEjvEcPNZfbjpzN5tn7WxG5pZR+B14MfO\nuQNNeTIzmw5MB8jIyGjKQ4iIBLyUTnGcP7A75w/sDvjeBWzYdZBlW/axrGQ/KfHeHPenUYVvZtH4\nyv4l59wb9WyyDehZ63K6/7p/4ZybAcwA3xz+SacVEQlCUZER5PSIJ6dHPNeM7OVZjhMeXNq/AucZ\noMA598cGNnsbuM58zgDKNX8vIhJYGjPCHwN8D1hlZsv91/0cyABwzj0JvIdvhU4hvmWZN7R8VBER\naY7GrNKZBxz3I2X/6pxbWyqUiIi0PJ0vTEQkTKjwRUTChApfRCRMqPBFRMKECl9EJEx4djx8MysF\nNjfx7klAWQvGaSvBmDsYM0Nw5g7GzBCcuYM5cy/nXHJTHsCzwm8OM8tr6tHivBSMuYMxMwRn7mDM\nDMGZO1wza0pHRCRMqPBFRMJEsBb+DK8DNFEw5g7GzBCcuYMxMwRn7rDMHJRz+CIicvKCdYQvIiIn\nKegK38wmmtl6Mys0s595nac+ZtbTzD41s7VmtsbM7vRf39XMPjSzL/3/TfA6a11mFmlmy8xstv9y\nlpkt8u/vV80sxuuMdflPqTnLzNaZWYGZjQqSff0T/7+P1Wb2spnFBdr+NrNnzWy3ma2udV29+9Z/\nePQ/+bOvNLNhAZb7v/z/Rlaa2Ztm1qXWbff6c683swsCJXOt235qZs7MkvyXm7Svg6rwzSwSeAy4\nEMgBrjKzHG9T1asK+KlzLgc4A7jVn/NnwMfOuWzgY//lQHMnUFDr8oPAQ865vsA+4EZPUh3fI8D7\nzrn+wGn48gf0vjazNOAOINc5NwiIBKYSePv7eWBinesa2rcXAtn+n+nAE22UsT7P8+3cHwKDnHOn\nAhuAewH8f5tTgYH++zzu75q29jzfzoyZ9QTOB0pqXd20fe2cC5ofYBTwQa3L9wL3ep2rEbnfAs4D\n1gOp/utSgfVeZ6uTMx3fH/AEYDa+w2KXAVH17f9A+AE6A0X4P4+qdX2g7+uvzwPdFd9hymcDFwTi\n/gYygdUn2rfAU8BV9W0XCLnr3HYZvjP4fatHgA+AUYGSGZiFbyBTDCQ1Z18H1Qifhk+WHrDqnPi9\nm/vfM4HtBLp5FKshDwP3ADV+RmqmAAACfElEQVT+y4nAfudclf9yIO7vLKAUeM4/FfW0mXUgwPe1\nc24b8Ad8o7YdQDmQT+Dvb2h43wbT3+f3gX/4fw/Y3GY2BdjmnFtR56YmZQ62wg8qxzvxu/O9LAfM\nEikzmwTsds7le53lJEUBw4AnnHNDgUPUmb4JtH0N4J/3noLvBasH0IF63s4HukDctydiZvfhm3Z9\nyessx2Nm7fGdXfAXLfWYwVb4jTpZeiBo4MTvu8ws1X97KrDbq3z1GANMNrNi4BV80zqPAF3M7Osz\nowXi/t4KbHXOLfJfnoXvBSCQ9zXAuUCRc67UOXcMeAPf/4NA39/Q8L4N+L9PM5sGTAKu8b9YQeDm\n7oNvQLDC/3eZDiw1s+40MXOwFf4SINu/kiEG3wctb3uc6VvMGjzx+9vA9f7fr8c3tx8QnHP3OufS\nnXOZ+PbrJ865a4BPgSv9mwVUZgDn3E5gi5md4r/qHGAtAbyv/UqAM8ysvf/fy9e5A3p/+zW0b98G\nrvOvIDkDKK819eM5M5uIb8pysnPucK2b3gammlmsmWXh+yB0sRcZa3POrXLOpTjnMv1/l1uBYf5/\n803b1159oNKMDzUuwvcJ+0bgPq/zNJBxLL63uSuB5f6fi/DNiX8MfAl8BHT1OmsD+ccDs/2/98b3\nj78QeA2I9TpfPXmHAHn+/f13ICEY9jXwK2AdsBp4EYgNtP0NvIzvM4Zj/sK5saF9i+9D/sf8f5ur\n8K1ACqTchfjmvb/+m3yy1vb3+XOvBy4MlMx1bi/mfz+0bdK+1jdtRUTCRLBN6YiISBOp8EVEwoQK\nX0QkTKjwRUTChApfRCRMqPBFRMKECl9EJEyo8EVEwsT/AE3ssuAtnithAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hbUW-WJyPZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_paths = 100 \n",
        "pred_length = 64 \n",
        "T = ??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_itPTSux6ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## PREDICTION ## for one example\n",
        "paths = np.zeros((num_paths, T + pred_length))\n",
        "\n",
        "with torch.no_grad(): \n",
        "  \n",
        "  test_data = ...\n",
        "  \n",
        "  for n in range(num_paths): \n",
        "    \n",
        "    fixed_effects = global_model(test_data, global_hidden)\n",
        "    log_lik, sigma = local_model(data, local_hidden, fixed_effects, gaussian_likelihood = True)\n",
        "    \n",
        "    z = torch.zeros(sigma.shape[0])\n",
        "    for t in range(sigma.shape[0]):\n",
        "      z[t] = torch.distributions.normal.Normal(0, sigma[t]).rsample() #OR z = torch.distributions.normal.Normal(fixed_effects[t], sigma[t]).rsample() \n",
        "      \n",
        "    paths[n,:T] = input_test_data[:,0]\n",
        "    paths[n, T:] = z"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}